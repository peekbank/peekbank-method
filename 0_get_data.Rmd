---
title: "Data loading"
author: "Veronica"
date: "2/27/26"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    code_folding: hide

---


```{r}
library(here)
library(peekbankr)
source(here("helper","common.R"))

```


## Get data

```{r, eval=F}
con <- connect_to_peekbank(db_version = "2026.1")
all_aoi_timepoints <- get_aoi_timepoints(connection = con, rle=FALSE)
saveRDS(all_aoi_timepoints, here("all_aoi.rds"))
```


```{r, eval=F}
# reload connection in case it is stale
con <- connect_to_peekbank(db_version = "2026.1")
all_stimuli <- collect(get_stimuli(connection = con))
all_administrations <- collect(get_administrations(connection = con))
all_subjects <- unpack_aux_data(collect(get_subjects(connection = con)))
all_trial_types <- collect(get_trial_types(connection = con))
all_trials <- unpack_aux_data(collect(get_trials(connection = con)))
all_datasets <- get_datasets(connection=con) %>% collect()
```

Now do the joins. 

Veronica notes that in the interest of being kind to RAM, some filters and selects have been moved up. 

Filter criteria:
* no restriction on language
* vanilla trial only
* age 12-60 months inclusive 

```{r, eval=F}

all_aoi_timepoints <- readRDS(here("all_aoi.rds"))

all_administrations <- all_administrations |> select(administration_id, age, dataset_id, subject_id, dataset_name) |> filter(age <= 60, age>=12)

all_trials <- all_trials |> select(trial_id, trial_order, trial_type_id, dataset_id, dataset_name)

all_trial_types <- all_trial_types |> select(trial_type_id, dataset_id, dataset_name, distractor_id, target_id, target_side, vanilla_trial, full_phrase_language) |> filter(vanilla_trial == TRUE)

all_stimuli <- all_stimuli |> select(stimulus_id, stimulus_novelty, english_stimulus_label, dataset_id) |> mutate(english_stimulus_label=str_to_lower(english_stimulus_label))

aoi_data_joined <- all_aoi_timepoints |>
  inner_join(all_administrations) |>
  right_join(all_trials) |>
  inner_join(all_trial_types) |>
  mutate(stimulus_id = target_id) |>
  left_join(all_stimuli) |>
  select(dataset_name, subject_id, administration_id, trial_id, trial_order, dataset_id, 
         stimulus_id, distractor_id, t_norm, age, aoi, english_stimulus_label, 
         stimulus_novelty, target_side, vanilla_trial, full_phrase_language) %>%
  rename(target_label = english_stimulus_label, 
         target_id = stimulus_id) %>%
  left_join(all_stimuli %>%
              select(stimulus_id, dataset_id, 
                     stimulus_novelty, english_stimulus_label) %>%
              rename(distractor_id = stimulus_id, 
                     distractor_novelty = stimulus_novelty,
                     distractor_label = english_stimulus_label)) |> 
    select(dataset_name, subject_id, administration_id, trial_id, trial_order,
         dataset_id, target_id, distractor_id, t_norm, age, aoi, target_label, distractor_label, target_side, full_phrase_language)

saveRDS(aoi_data_joined, file= here("cached_intermediates","0_aoi_data_joined.Rds"))
```

Check on number of datasets. 

```{r}
aoi_data_joined <- readRDS(here("cached_intermediates", "0_aoi_data_joined.Rds"))
length(unique(aoi_data_joined$dataset_name))
unique(aoi_data_joined$dataset_name)
```
36 datasets -- dataset list checks on based on what we'd expect from vanillaness checks. 

Age distribution. 

```{r}
ggplot(aoi_data_joined, aes(x = age, fill = dataset_name)) + 
  geom_histogram() 
```


# Item cleanup

Do some further checks/cleanup of items. 

Output targets and distractors. 

```{r, eval=F}
all_items <- tibble(item = sort(unique(c(aoi_data_joined$target_label, aoi_data_joined$distractor_label))))
write_csv(all_items, here("metadata", "all_items_2026.1.csv"))
```

Rename and exclude in a more general way. This is a manual step by which we have gone through and merged items by hand when we thought they should have the same general form. 

```{r, eval=F}
included_items <- read_csv(here("metadata","included_items_2026.1.csv")) 

d_aoi <- aoi_data_joined |>
  left_join(included_items, by = join_by(target_label == item)) |>
  left_join(included_items, by = join_by(distractor_label == item), 
            suffix = c("_target","_distractor")) |>
  filter(include_target == 1, include_distractor == 1) |>
  mutate(target_label = ifelse(is.na(rename_to_target), 
                               target_label, rename_to_target), 
         distractor_label = ifelse(is.na(rename_to_distractor), 
                                   distractor_label, rename_to_distractor)) |>
  select(-include_target, -include_distractor, -rename_to_distractor, -rename_to_target)
```

# Timecourse cleanup

Note - there is a bit of a ramp down in terms of amount of data for many datasets towards the end. 
We clip at +/- 4000 because there is little data outside these windows. 


```{r, eval=F}
d_aoi <- d_aoi |>
  filter(t_norm >= -4000, t_norm <= 4000) |> 
    mutate(correct = case_when(
      aoi == "target"~ 1, 
      aoi == "distractor"~ 0,
      T ~ NA))

saveRDS(d_aoi, file = here("cached_intermediates","0_d_aoi.rds"))
```

## CDI data

Add instrument length and a CDI percent column.

TODO what are lengths of other instruments!!!
```{r}
admin_info <- all_administrations %>% 
  distinct(subject_id, dataset_id, administration_id, age) |>
  left_join(all_datasets %>% select(dataset_id, dataset_name)) # get dataset names

subjects <- admin_info |> distinct(subject_id, dataset_name) |> left_join(all_subjects)
cdi_admins <- subjects %>%
  unnest(subject_aux_data) %>% 
  filter(!is.na(cdi_responses)) %>%
  unnest(cdi_responses) |> 

# cdi lengths sourced from Alvin doing some wordbank magic

    mutate(instrument_length = case_when(
      language=="English (American)" & instrument_type=="ws" ~ 680,
      language=="English (American)" & instrument_type=="wg" ~ 396,
      language=="English (American)" & instrument_type=="wsshort" ~ 100,
      language=="English (American)" & instrument_type=="wgshort" ~ 100,
      language=="Spanish (Mexican)" & instrument_type=="ws" ~ 680,
      language=="Spanish (Mexican)" & instrument_type=="wg" ~ 428,
      language=="French (Quebecois)" & instrument_type=="ws" ~ 664,
      language=="French (Quebecois)" & instrument_type=="wg" ~ 408,
      language=="Dutch" & instrument_type=="wg" ~ 441,
      language=="Norwegian" & instrument_type=="wg" ~ 395,
       .default = NA),
         CDI_percent = rawscore / instrument_length) |>
  select(subject_id, age, measure, CDI_percent) |> 
  pivot_wider(names_from = "measure", values_from = "CDI_percent", 
              values_fill = NA, values_fn = mean)
```

Now we have one row per CDI administration. 

Let's try to join this with the administration data. 


Our principles:
* we want to join CDIs to LWLs, so that means that the LWL admins are our base data frame (e.g., `left_join(admins, cdis)` and not the reverse)
* we want only one CDI per LWL admin, but we could in principle average for extra precision. 

We average for extra precision. 

We do a hack where we multiply subject_id by 10 so we can do an up-to-off-by-one fuzzy join on age & subject id (creating an up to off-by-one join on age and an exact join on id) and then restore subject num.
We then average CDI for admins that matched multiple CDI. 


```{r}
cdi_data <- fuzzyjoin::difference_left_join(mutate(admin_info, subject_id = 10*subject_id),
                                            mutate(cdi_admins, subject_id = 10*subject_id),
                                            by = c("subject_id", "age"),
                                            max_dist = 1) |>
  select(-age.y, -subject_id.y) |>
  rename(age = age.x, subject_id = subject_id.x) |>
  mutate(subject_id = subject_id/10) |> # remove hack 
  group_by(subject_id, administration_id, dataset_name, age) |>
  summarise(prod = mean(prod, na.rm = TRUE), 
            comp = mean(comp, na.rm = TRUE)) |>
  mutate(across(c("prod","comp"), ~ifelse(is.nan(.x), NA, .x))) |>
  ungroup()                     

saveRDS(cdi_data, file=here("cached_intermediates", "0_cdi_subjects.Rds"))
```
