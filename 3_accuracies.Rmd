---
title: "Accuracies"
author: "Mike Frank"
date: "2022-1-19 updated 2025-04-16"
output: html_document
---

```{r}
source(here::here("helper/common.R"))
library(tictoc)

t_increment <- 200 
```

# Reliability

These simulations use ICCs as a way to understand how we summarize accuracy data. In particular, we're going to look at how ICCs change as a function of window size. 

```{r}
icc_window_sim <- function (t_start = -500, t_end = 4000, object) 
{
  print(paste(t_start, t_end))
  
  df <- d_aoi |>
    filter(t_norm > t_start, t_norm < t_end) |>
    group_by(dataset_name, dataset_id, administration_id, target_label, trial_id) |>
    summarise(accuracy = mean(correct, na.rm=TRUE),
              prop_data = mean(!is.na(correct)))
  
  # compute ICCs
  df |> 
    group_by(dataset_name) |> 
    nest() |>
    mutate(icc = unlist(map(data, ~get_icc(., "accuracy", object)))) |>
    select(-data) |>
    unnest(cols = c()) 
}
```

```{r}
acc_params <- expand_grid(t_start = seq(-1000, 1500, t_increment),
                          t_end = seq(2000, 4000, t_increment),
                          object = c("stimulus", "administration"))

# multidyplr attempt
cluster <- new_cluster(14) 
cluster_library(cluster, "tidyverse")
cluster_library(cluster, "agreement")
cluster_copy(cluster, "icc_window_sim")
cluster_copy(cluster, "get_icc")
cluster_copy(cluster, "d_aoi")
  
tic()
accs <- acc_params |> 
  partition(cluster) |>
  mutate(icc = pmap(list(t_start, t_end, object), icc_window_sim)) |>
  collect() |>
  unnest(col = icc)
toc()

save(file = "cached_intermediates/3_accs.Rds", accs)
```

```{r}
load(file = "cached_intermediates/3_accs.Rds")
```

Looks like for stimulus and administration you get consistent but modest gains if you take the longest window. BUT for stimuli, the early part of the trial adds reliability (probably because of bias due to stimulus-level preferences?). In contrast, for administrations, the early part of the trial is less informative. 500ms seems like a pretty good compromise. 

## Visualizations

Summary data frame. 

```{r}
accs_summary <- accs |>
  group_by(t_start,t_end,object) |>
  summarize(N = n(),
            mean_icc = mean(icc,na.rm=TRUE)) |>
  mutate(window_size = t_end-t_start)
```

Descriptive heatmap. 


```{r}
ggplot(accs_summary, aes(x=t_start,y=t_end,fill=mean_icc))+
  geom_tile(color="white")+
  scale_fill_viridis(name="Mean ICC",option="inferno")+
  scale_x_continuous(breaks=c(-1000,-500,0,500,1000,1500))+
  xlab("Window Start Time (in ms)")+
  ylab("Window End Time (in ms)")+
  facet_wrap(~object)
```

Window-by-window. 


```{r}
ggplot(accs_summary,
       aes(color=mean_icc))+
  geom_vline(xintercept=0,linetype="dashed")+
  geom_segment(aes(x=t_start,xend=t_end,y=mean_icc,yend=mean_icc))+
  geom_segment(aes(x=t_start,xend=t_start,y=mean_icc-0.005,yend=mean_icc+0.005))+
  geom_segment(aes(x=t_end,xend=t_end,y=mean_icc-0.005,yend=mean_icc+0.005))+
  scale_color_viridis(name="Mean ICC",direction=-1) + 
  theme(legend.position="none") +
  ylab("Mean ICC") +
  xlab("Analysis Window (in ms)") + 
  facet_wrap(~object)
```



# Window size by age

Let's do one more simulation where we check if this result holds across two ages. We'll break down age into > 24 months and < 24 months, which roughly splits the dataset. There are `r  length(unique(d_aoi$administration_id[d_aoi$age < 24]))` younger kids and `r length(unique(d_aoi$administration_id[d_aoi$age >= 24]))` older kids. 


```{r}
icc_window_sim_age <- function (t_start = -1000, t_end = 4000, object) 
{
  df <- d_aoi |>
    mutate(younger = age < 24) |>
    filter(t_norm > t_start, t_norm < t_end) |>
    group_by(dataset_name, dataset_id, younger, administration_id, 
             target_label, trial_id) |>
    summarise(accuracy = mean(correct, na.rm=TRUE),
              prop_data = mean(!is.na(correct)))
  
  # compute ICCs
  df |> 
    group_by(dataset_name, younger) |> 
    nest() |>
    mutate(icc = unlist(map(data, ~get_icc(., "accuracy", object)))) |>
    select(-data) |>
    unnest(cols = c()) 
}

cluster_copy(cluster, "icc_window_sim_age")

tic()
accs_byage <- acc_params |> 
  partition(cluster) |>
  mutate(icc = pmap(list(t_start, t_end, object), icc_window_sim_age)) |>
  collect() |>
  unnest(col = icc)
toc()

save(file = "cached_intermediates/2_accs_byage.Rds", accs_byage)
```
## Visualizations

Now plot. 

```{r}
load(file = "cached_intermediates/2_accs_byage.Rds")

accs_byage_summary <- accs_byage |>
  group_by(younger, t_start, t_end, object) |>
  summarize(N=n(),
            mean_icc = mean(icc, na.rm=TRUE)) |>
  mutate(window_size = t_end - t_start) |>
  mutate(age=ifelse(younger,">=24 months","<24 months"))
```


Here we see that the younger kids lose more reliability when the window is short, but otherwise the conclusions remain unchanged. 

```{r}
ggplot(accs_byage_summary,
       aes(color=mean_icc))+
  geom_vline(xintercept=0,linetype="dashed")+
  geom_segment(aes(x=t_start,xend=t_end,y=mean_icc,yend=mean_icc))+
  geom_segment(aes(x=t_start,xend=t_start,y=mean_icc-0.005,yend=mean_icc+0.005))+
  geom_segment(aes(x=t_end,xend=t_end,y=mean_icc-0.005,yend=mean_icc+0.005))+
  scale_color_viridis(name="Mean ICC",direction=-1) + 
  theme(legend.position="none") +
  ylab("Mean ICC") +
  xlab("Analysis Window (in ms)") + 
  facet_grid(age~object)
```


# Validity via experimental effect

We're going to use the size and significance of the Swingley & Aslin (2002) mispronunciation effect as our simulation target instead of ICCs. 

This is with younger kids. 

We have to reload data because our working dataframe is only "vanilla" familiar word trials. 


```{r}
library(peekbankr)
subjects <- get_subjects()
sa_administrations <- get_administrations(dataset_name = "swingley_aslin_2002")
sa_trial_types <- get_trial_types(dataset_name = "swingley_aslin_2002")
sa_trials <- get_trials(dataset_name = "swingley_aslin_2002")
sa_aoi_timepoints <- get_aoi_timepoints(dataset_name = "swingley_aslin_2002")

sa_data <- sa_aoi_timepoints |>
  left_join(sa_administrations) |>
  left_join(sa_trials) |>
  left_join(sa_trial_types) |>
  left_join(subjects) |>
  filter(condition != "filler") |>
  mutate(condition = if_else(condition == "cp", "Correct", "Mispronounced"))
```
visualize the curves:

```{r}

correct_accuracy <- sa_data |>
  group_by(t_norm, condition) |>
  summarise(correct = sum(aoi == "target") / 
              sum(aoi %in% c("target","distractor")))

ggplot(correct_accuracy, aes(x = t_norm, y = correct, col = condition)) + 
  geom_point() + 
  geom_smooth()
```


```{r }
sa_sim <- function (t_start = -500, t_end = 4000) 
{
  by_subject_accuracies <- sa_data  |>
    filter(t_norm >= t_start, t_norm <= t_end) |>
    group_by(condition, t_norm, administration_id) |> 
    summarize(correct = sum(aoi == "target") / 
                sum(aoi %in% c("target","distractor")))
  
  mean_accuracies <- by_subject_accuracies |>
    group_by(administration_id, condition) |> 
    summarize(mean_correct = mean(correct)) |>
    group_by(administration_id) |> 
    summarise(diff = mean_correct[condition == "Correct"] - 
                mean_correct[condition == "Mispronounced"])
  
  tibble(acc_diff = mean(mean_accuracies$diff), 
         p_val = t.test(mean_accuracies$diff)$p.value)
}
```

```{r}
sa_acc_params <- expand_grid(t_start = seq(-1000, 1500, 100),
                          t_end = seq(2000, 3000, 100))  
tic()
sa_accs <- sa_acc_params |> 
  # partition(cluster) |>
  mutate(icc = pmap(list(t_start, t_end), sa_sim)) |>
  # collect() |>
  unnest(col = icc)
toc()

save(file = "cached_intermediates/3_accs_sa.Rds", sa_accs)
```
Visualize.

```{r}
load(file = "cached_intermediates/3_accs_sa.Rds")

ggplot(sa_accs, aes(col = p_val)) + 
  geom_vline(xintercept=0, linetype="dashed")+
  geom_hline(yintercept=0.05, lty=3)+
  geom_segment(aes(x=t_start,xend=t_end,y=p_val,yend=p_val))+
  # geom_segment(aes(x=t_start,xend=t_start,y=mean_icc-0.005,yend=mean_icc+0.005))+
  # geom_segment(aes(x=t_end,xend=t_end,y=mean_icc-0.005,yend=mean_icc+0.005))+
  scale_color_viridis(name="Mean ICC",direction=-1) + 
  scale_y_log10() + 
  theme(legend.position="none") +
  ylab("Log p-value on key test") +
  xlab("Analysis Window (in ms)") 
```

Conclusion: if you cherry pick the window that has the biggest difference, you will get the lowest p-value. We should have known that before the simulation. 

So really the question is when this window is, A PRIORI. Because of course the issue is that this analysis has a horrible false positive problem. Hence permutation-based analyses. 


# Validity via MB-CDI

We have MB-CDI WS data for a number of datasets, at least two. 


```{r}
cdi_data <- readRDS(here("cached_intermediates","1_cdi_subjects.Rds"))


```

Now let's get our sim function. 

```{r}
cdi_sim <- function (t_start = -500, t_end = 4000) 
{
  # first average by trial then by subject
  by_trial_accuracies <- d_aoi  |>
    filter(t_norm >= t_start, t_norm <= t_end) |>
    group_by(dataset_name, subject_id, administration_id, trial_id) |> 
    summarize(correct = mean(correct, na.rm=TRUE)) 
  
  by_subject_accuracies <- by_trial_accuracies |>
    group_by(dataset_name, subject_id, administration_id) |> 
    summarize(mean_correct = mean(correct, na.rm=TRUE)) |>
    left_join(cdi_data) |> 
    filter(!(is.na(prod) & is.na(comp)) & !is.na(mean_correct))

  by_subject_accuracies |>
    group_by(dataset_name) |>
    summarise(cor_comp = ifelse(sum(!is.na(comp)) > 0, cor.test(mean_correct, comp)$estimate, NA), 
              cor_prod = ifelse(sum(!is.na(prod)) > 0, cor.test(mean_correct, prod)$estimate, NA), 
              n_comp = sum(!is.na(comp)),
              n_prod = sum(!is.na(prod)), 
              n_total = sum(!is.na(mean_correct)))
}
```

```{r}
cdi_params <- expand_grid(t_start = seq(-1000, 1500, 250),
                          t_end = seq(2000, 4000, 250))  

cluster_copy(cluster, "cdi_sim")
cluster_copy(cluster, "cdi_data")

tic()
cdi_corrs <- cdi_params |> 
  partition(cluster) |>
  mutate(icc = pmap(list(t_start, t_end), cdi_sim)) |>
  collect() |>
  unnest(col = icc)
toc()

save(file = here("cached_intermediates","3_cdi_corrs.Rds"), cdi_corrs)
```

```{r}
cdi_corrs_long <- cdi_corrs |>
  pivot_longer(names_to = "measure", values_to = "r", starts_with("cor"))
```

Visualize!


```{r}
ggplot(filter(cdi_corrs_wide, !is.na(r), dataset_name ==  "adams_marchman_2018"),
       aes(col = r)) + 
  geom_vline(xintercept=0, linetype="dashed")+
  geom_hline(yintercept=0.05, lty=3)+
  geom_segment(aes(x=t_start,xend=t_end,y=r,yend=r))+
  # geom_segment(aes(x=t_start,xend=t_start,y=mean_icc-0.005,yend=mean_icc+0.005))+
  # geom_segment(aes(x=t_end,xend=t_end,y=mean_icc-0.005,yend=mean_icc+0.005))+
  scale_color_viridis(name="Mean ICC",direction=-1) + 
  # scale_y_log10() + 
  theme(legend.position="none") +
  ylab("Correlation with MB-CDI sumscore") +
  xlab("Analysis Window (in ms)") +
  facet_grid(. ~ measure)
```

```{r}
ggplot(filter(cdi_corrs_long, measure == "cor_prod", n_prod > 50), 
       aes(col = r)) + 
  geom_vline(xintercept=0, linetype="dashed")+
  geom_hline(yintercept=0.05, lty=3)+
  geom_segment(aes(x=t_start,xend=t_end,y=r,yend=r))+
  scale_color_viridis(name="Mean ICC",direction=-1) + 
  theme(legend.position="none") +
  ylab("Correlation with MB-CDI sumscore") +
  xlab("Analysis Window (in ms)") +
  facet_wrap(~dataset_name) +
  ggtitle("Correlation with CDI production, n > 50")

```
```{r}
ggplot(filter(cdi_corrs_long, measure == "cor_comp", n_prod > 50), 
       aes(col = r)) + 
  geom_vline(xintercept=0, linetype="dashed")+
  geom_hline(yintercept=0.05, lty=3)+
  geom_segment(aes(x=t_start,xend=t_end,y=r,yend=r))+
  scale_color_viridis(name="Mean ICC",direction=-1) + 
  theme(legend.position="none") +
  ylab("Correlation with MB-CDI sumscore") +
  xlab("Analysis Window (in ms)") +
  facet_wrap(~dataset_name) + 
  ggtitle("Correlation with CDI comprehension, n > 50")
```
```{r}
ms_corr <- cdi_corrs_long |>
  filter(measure == "cor_prod", n_prod > 50) |>
  group_by(t_start, t_end) |>
  summarise(r = mean(r, na.rm=TRUE)) 
        
ggplot(ms_corr, aes(col = r)) + 
  geom_vline(xintercept=0, linetype="dashed")+
  geom_segment(aes(x=t_start,xend=t_end,y=r,yend=r))+
  scale_color_viridis(name="Mean ICC",direction=-1) + 
  theme(legend.position="none") +
  ylab("Correlation with MB-CDI sumscore") +
  xlab("Analysis Window (in ms)") +
  ggtitle("Correlation with CDI production, n > 50")

```

## Across datasets

```{r}
cdi_sim_alldata <- function (t_start = -500, t_end = 4000) 
{
  # first average by trial then by subject
  by_trial_accuracies <- d_aoi  |>
    filter(t_norm >= t_start, t_norm <= t_end) |>
    group_by(dataset_name, subject_id, administration_id, trial_id) |> 
    summarize(correct = mean(correct, na.rm=TRUE)) 
  
  by_subject_accuracies <- by_trial_accuracies |>
    group_by(dataset_name, subject_id, administration_id) |> 
    summarize(mean_correct = mean(correct, na.rm=TRUE)) |>
    left_join(cdi_data) |> 
    filter(!(is.na(prod) & is.na(comp)) & !is.na(mean_correct))

  by_subject_accuracies |>
    ungroup() |>
    summarise(cor_comp = ifelse(sum(!is.na(comp)) > 0, cor.test(mean_correct, comp)$estimate, NA), 
              cor_prod = ifelse(sum(!is.na(prod)) > 0, cor.test(mean_correct, prod)$estimate, NA), 
              n_comp = sum(!is.na(comp)),
              n_prod = sum(!is.na(prod)), 
              n_total = sum(!is.na(mean_correct)))
}

cluster_copy(cluster, "cdi_sim_alldata")
cluster_copy(cluster, "cdi_data")

tic()
cdi_corrs_alldata <- cdi_params |> 
  partition(cluster) |>
  mutate(icc = pmap(list(t_start, t_end), cdi_sim_alldata)) |>
  collect() |>
  unnest(col = icc)
toc()

save(file = here("cached_intermediates","3_cdi_corrs_alldata.Rds"), cdi_corrs)
```

```{r}
ggplot(cdi_corrs_alldata, aes(col = cor_prod)) + 
  geom_vline(xintercept=0, linetype="dashed")+
  geom_segment(aes(x=t_start, xend=t_end, y=cor_prod, yend=cor_prod))+
  scale_color_viridis(name="Mean ICC",direction=-1) + 
  theme(legend.position="none") +
  ylab("Correlation with MB-CDI sumscore") +
  xlab("Analysis Window (in ms)") +
  ggtitle("Accuracy/CDI production correlation across all datasets")
```
```{r}
ggplot(cdi_corrs_alldata, aes(col = cor_comp)) + 
  geom_vline(xintercept=0, linetype="dashed")+
  geom_segment(aes(x=t_start, xend=t_end, y=cor_prod, yend=cor_prod))+
  scale_color_viridis(name="Mean ICC",direction=-1) + 
  theme(legend.position="none") +
  ylab("Correlation with MB-CDI sumscore") +
  xlab("Analysis Window (in ms)") +
  ggtitle("Accuracy/CDI comprehension correlation across all datasets")
```
# Baseline-corrected accuracy

## ICC approach

```{r}
icc_bc_window_sim <- function (b_start = -2000, b_end = 0,  
                            t_start = 500, t_end = 4000, 
                            object) 
{
  # get trials with some baseline
  baseline_lengths <- d_aoi |>
    group_by(dataset_name, trial_id) |> 
    summarise(t_min = min(t_norm))
  
  # get baseline corrected accuracies for all trials with ANY baseline info
  df <- d_aoi |>
    left_join(baseline_lengths) |>
    filter(t_min < 0) |>
    group_by(dataset_name, dataset_id, administration_id, target_label, trial_id) |>
    summarise(window_accuracy = mean(correct[t_norm >= t_start & t_norm <= t_end], 
                                     na.rm=TRUE),
              baseline_accuracy = mean(correct[t_norm >= b_start & t_norm <= b_end], 
                                     na.rm=TRUE), 
              bc_accuracy = window_accuracy - baseline_accuracy) |>
    filter(!is.na(bc_accuracy))
  
  # compute ICCs
  df |> 
    group_by(dataset_name) |> 
    nest() |>
    mutate(icc = unlist(map(data, ~get_icc(., "bc_accuracy", object)))) |>
    select(-data) |>
    unnest(cols = c()) 
}
```

```{r}
bc_acc_params <- expand_grid(t_start = seq(500, 1500, 500),
                             t_end = seq(2000, 4000, 500),
                             b_start = seq(-2000,-1000, 500), 
                             b_end = seq(-500, 0, 500),
                             object = c("stimulus", "administration"))

# multidyplr attempt
cluster <- new_cluster(14) 
cluster_library(cluster, "tidyverse")
cluster_library(cluster, "agreement")
cluster_copy(cluster, "icc_bc_window_sim")
cluster_copy(cluster, "get_icc")
cluster_copy(cluster, "d_aoi")
  
tic()
bc_accs <- bc_acc_params |> 
  partition(cluster) |>
  mutate(icc = pmap(list(b_start, b_end, t_start, t_end, object), icc_bc_window_sim)) |>
  collect() |>
  unnest(col = icc)
toc()

save(file = "cached_intermediates/3_bc_accs.Rds", bc_accs)
```

```{r}
load(file = "cached_intermediates/3_bc_accs.Rds")
```

Summary data frame. 

```{r}
bc_accs_summary <- bc_accs |>
  group_by(b_start, b_end, t_start, t_end, object) |>
  summarize(N = n(),
            mean_icc = mean(icc,na.rm=TRUE)) |>
  mutate(window_size = t_end - t_start, 
         bc_window_size = b_end - b_start)
```


```{r}
ggplot(bc_accs_summary,
       aes(color=mean_icc))+
  geom_vline(xintercept=0,linetype="dashed")+
  geom_segment(aes(x=t_start,xend=t_end,y=mean_icc,yend=mean_icc))+
  geom_segment(aes(x=t_start,xend=t_start,y=mean_icc-0.005,yend=mean_icc+0.005))+
  geom_segment(aes(x=t_end,xend=t_end,y=mean_icc-0.005,yend=mean_icc+0.005))+
  scale_color_viridis(name="Mean ICC",direction=-1) + 
  theme(legend.position="none") +
  ylab("Mean ICC") +
  xlab("Analysis Window (in ms)") + 
  facet_grid(bc_window_size~object)
```
These numbers seem low. 

Compare to non-corrected accuracies. 

```{r}
load(file = "cached_intermediates/3_accs.Rds")

accs_summary <- accs |>
  group_by(t_start,t_end,object) |>
  summarize(mean_uncorrected_icc = mean(icc, na.rm=TRUE)) 

comparison_accs_summary <- left_join(bc_accs_summary, accs_summary)
```

```{r}
ggplot(comparison_accs_summary, aes(x = mean_uncorrected_icc, y = mean_icc, col = window_size)) + 
  geom_point() +
  geom_smooth(method = "lm") + 
  geom_abline(lty = 2) + 
  # xlim(0,.6) + ylim(0,.6) + 
  facet_grid(bc_window_size~ object)
```
Possible interpretation (pace Dan Swingley): baselines are short and noisy. By adding them into the signal, you are diluting what you have. 

Note that we don't have a lot of baseline data here (no more than 2s) so we can't rule out the idea that a longer (4s or so) baseline would be meaningful or useful in a correction analysis. But even with 2s we see substantial reductions in ICC. 

## CDI validity with baseline correction

```{r}
cdi_bc_sim <- function (t_start = 500, t_end = 4000) 
{
  # get trials with some baseline
  baseline_lengths <- vanilla_cdi_datasets |>
    group_by(dataset_name, trial_id) |> 
    summarise(t_min = min(t_norm))
  
  # get baseline corrected accuracies for all trials with ANY baseline info
  by_subject_accuracies <- vanilla_cdi_datasets |>
    left_join(baseline_lengths) |>
    filter(t_min < 0) |>
    group_by(dataset_name, lab_subject_id, trial_id) |>
    summarize(window_accuracy = mean(correct[t_norm >= t_start & t_norm <= t_end], 
                                     na.rm=TRUE),
              baseline_accuracy = mean(correct[t_norm >= -2000 & t_norm <= 0], 
                                     na.rm=TRUE), 
              bc_accuracy = window_accuracy - baseline_accuracy) 
  
  mean_accuracies <- by_subject_accuracies |>
    group_by(dataset_name, lab_subject_id) |> 
    summarize(bc_accuracy = mean(bc_accuracy)) |>
    left_join(cdis)
  
  mean_accuracies |>
    group_by(dataset_name) |>
    summarise(cor_comp = cor.test(bc_accuracy, eng_wg_understood)$estimate,
              cor_prod = cor.test(bc_accuracy, eng_wg_produced)$estimate)
}
```

```{r}
cdi_params <- expand_grid(t_start = seq(500, 1500, 500),
                          t_end = seq(2000, 4000, 500))  
tic()
cdi_bc_corrs <- cdi_params |> 
  mutate(icc = pmap(list(t_start, t_end), cdi_bc_sim)) |>
  unnest(col = icc)
toc()

cdi_bc_corrs <- cdi_bc_corrs |>
  pivot_longer(names_to = "measure", values_to = "r", starts_with("cor"))
```

Visualize!


```{r}
ggplot(cdi_bc_corrs, aes(col = r)) + 
  geom_vline(xintercept=0, linetype="dashed")+
  geom_hline(yintercept=0.05, lty=3)+
  geom_segment(aes(x=t_start,xend=t_end,y=r,yend=r))+
  # geom_segment(aes(x=t_start,xend=t_start,y=mean_icc-0.005,yend=mean_icc+0.005))+
  # geom_segment(aes(x=t_end,xend=t_end,y=mean_icc-0.005,yend=mean_icc+0.005))+
  scale_color_viridis(name="Mean ICC",direction=-1) + 
  # scale_y_log10() + 
  theme(legend.position="none") +
  ylab("Correlation with MB-CDI sumscore") +
  xlab("Analysis Window (in ms)") +
  facet_grid(dataset_name~ measure)
```

Compare to uncorrected. 

```{r}
cdi_comparison <- left_join(rename(cdi_bc_corrs, r_baseline_corrected = r), 
          rename(cdi_corrs, r_uncorrected = r)) |>
  mutate(window_size = t_end - t_start)

ggplot(cdi_comparison, aes(x = r_uncorrected, y = r_baseline_corrected, col = window_size)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  geom_abline(lty = 2) + 
  facet_wrap(~dataset_name)

```

This is overall surprising. For Swingley & Aslin, baseline correction makes things look way worse. But for Garrison & Bergelson, it seems like baseline correction helps. 


# Summary

* ICCs show high reliability for LONG time windows (500 - 4000) for subjects. 
* For administrations, the baseline period actually is quite reliable (indicating visual salience). 
* For experimental effects, there is a shorter window when the curves pull apart, but we don't have an a priori guess about when that is. Would be interesting to do this with more datasets. 
* For correlations with CDI, it looks like shorter more traditional windows are more correlated (at least for the youngest kids). 

So longer windows apparently index information about the child beyond what's captured by parent report. This could be language-related but not captured by CDIs - for example, late emerging or more fragmentary word knowledge, or it could be something like attention or memory or sticky fixation. Some users might want to get this information, while others might not. 

