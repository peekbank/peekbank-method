---
title: "RT Computation"
author: "Mike Frank"
date: "2022-12-15"
output: html_document
---


```{r}
source(here::here("helper/common.R"))
```
# Load data and prep intermediates



```{r}
# later version cached, no need to run
load(file = here("cached_intermediates", "1_d_trial.Rds"))
```

```{r}
source("helper/rt_helper.R")
```

```{r}
rle_data <- d_trial %>%
  filter(
    any(t_norm == 0), # must have data at 0
    t_norm >= 0
  ) %>% # only pass data after 0
  group_by(administration_id, trial_id, trial_order) %>%
  reframe(
    lengths = rle(aoi)$lengths,
    values = rle(aoi)$values
  )

d_rt <- rle_data %>%
  group_by(administration_id, trial_id, trial_order) %>%
  nest() %>%
  mutate(data = lapply(data, get_rt)) %>%
  unnest(cols = c(data)) %>%
  left_join(d_trial %>%
    select(-t_norm, -correct, -aoi) %>%
    distinct())

saveRDS(file = here("cached_intermediates", "4_d_rt.Rds"), d_rt)
```
# Measure 3: Reaction time
```{r}
d_rt <- readRDS(file = here("cached_intermediates", "4_d_rt.Rds"))
```

IV analysis options:
* what time point to use for RT -- the first time you leave, the last time you leave before landing, when you land
* raw vs log 
* filter by max shift length
* filter min start time
* do we exclude based on pre-min loss (between t_0 and min start time)

outcome measures:
* reliability = ICC
* data loss = how many datapoints are kept

## How much data shows differences?

### time point to use for RT + max shift length
```{r}
ggplot(d_rt, aes(x = shift_start_rt, y = rt)) +
  geom_point(alpha = .5, aes(col = age)) +
  geom_smooth(method = "lm") +
  viridis::scale_color_viridis()

ggplot(
  d_rt,
  aes(x = shift_start_rt, y = rt)
) +
  geom_point(alpha = .5, aes(col = age)) +
  geom_point(
    data = filter(d_rt, shift_length > 600),
    col = "red"
  ) +
  geom_smooth(method = "lm") +
  viridis::scale_color_viridis()
```

this is filtering at 600ms based on first leaving distractor

```{r}
# does type of start initiation matter

d_rt |>
  ungroup() |>
  filter(!is.na(shift_start_rt)) |>
  mutate(
    initiation_type_matters = shift_start_rt != last_shift_rt,
    long_shift_occurs = shift_length > 600
  ) |>
  group_by(initiation_type_matters, long_shift_occurs) |>
  tally() |>
  ungroup() |>
  mutate(pct = n / sum(n))
```
for the most part, these combos won't matter because >90% of the data has the kid only leaving once and doesn't have a long shift. 

distribution of shift lengths -- cut off at 1000ms; by far most shifts are <250ms

```{r}
d_rt |> ggplot(aes(x = shift_length)) +
  geom_histogram(binwidth = 50) +
  coord_cartesian(xlim = c(0, 1000))
d_rt |> ggplot(aes(x = last_shift_length)) +
  geom_histogram(binwidth = 50) +
  coord_cartesian(xlim = c(0, 1000))
```
### how important is consistency in 0-400ms window
how much of the time are kids looking at the same thing between 0 and 400 ms -- many studies require looks to distractor + no shifts for 250/300/367 ms; how much data loss is coming from this?

```{r}
t_0 <- d_trial |>
  filter(t_norm == 0) |>
  mutate(t_0_aoi = aoi) |>
  select(administration_id, trial_id, dataset_name, t_0_aoi) |>
  mutate(t_0_aoi = ifelse(t_0_aoi %in% c("target", "distractor"), t_0_aoi, "other"))
t_375 <- d_trial |>
  filter(t_norm == 375) |>
  mutate(t_375_aoi = aoi) |>
  select(administration_id, trial_id, dataset_name, t_375_aoi) |>
  mutate(t_375_aoi = ifelse(t_375_aoi %in% c("target", "distractor"), t_375_aoi, "other"))
early_dist <- d_trial |>
  filter(t_norm < 400 & t_norm >= 0) |>
  group_by(administration_id, trial_id, dataset_name, aoi) |>
  tally() |>
  left_join(t_0) |>
  left_join(t_375) |>
  pivot_wider(names_from = aoi, values_from = n, values_fill = 0) |>
  mutate(type = case_when(
    target + distractor + missing + other != 16 ~ "some missing ts",
    target == 16 ~ "only target",
    distractor == 16 ~ "only distractor",
    missing + other == 16 ~ "all off",
    target == 0 & distractor > 8 ~ "d+m (mostly d)",
    target == 0 ~ "d+m (mostly m)",
    distractor == 0 & target > 8 ~ "t+m (mostly t)",
    distractor == 0 ~ "t+m (mostly m)",
    T ~ "both"
  ))

ggplot(early_dist, aes(x = t_0_aoi, fill = type)) +
  facet_wrap(~t_375_aoi) +
  geom_bar()

early_dist |>
  group_by(type, t_0_aoi, t_375_aoi) |>
  tally() |>
  ungroup() |>
  mutate(pct = round(n / sum(n), 3)) |>
  arrange(desc(pct))
```
we want to know of the ones that are on t/d/m at start

~31% is on distractor for 0-375
~29% is on target for 0-375

~14% is missing/other for 0-375(this is going to get tossed in all cases!)

~5.5% goes from d to t
~5.5% goes from t to d 

~5.5% is mostly on d during the time, with some being on other (at start/end/middle)
~5% is mostly on t during the time, with some being on other (at start/end/middle)

to look at:
* when we have d/other or t/other what's the typical patterns
  * how much is other & when
* for both t/d this probably can't be salvaged but look at patterns

```{r}
early_dist |>
  filter(target == 0) |>
  filter(missing + other < 16) |>
  filter(distractor != 16) |>
  ggplot(aes(x = distractor)) +
  geom_bar()

early_dist |>
  filter(distractor == 0) |>
  filter(missing + other < 16) |>
  filter(target != 16) |>
  ggplot(aes(x = target)) +
  geom_bar()
```
so, most of the d/m or t/m mixes is heavily weighted to d or t with only a little m.
when does this m occur?
```{r}
d_trial |>
  filter(t_norm < 400 & t_norm >= 0) |>
  inner_join(early_dist |> filter(target == 0) |> filter(missing + other < 16) |> filter(distractor != 16) |> select(administration_id, dataset_name, trial_id, num_distractor = distractor)) |>
  mutate(is_distractor = ifelse(aoi == "distractor", 1, 0)) |>
  group_by(t_norm, num_distractor) |>
  summarize(is_distractor = mean(is_distractor)) |>
  ggplot(aes(x = t_norm, y = is_distractor, col = num_distractor, group = num_distractor)) +
  geom_point() +
  geom_line() +
  scale_color_viridis()
```
so, most of the d/m that is mostly d has the m at the beginning or end (rather than in the middle) -- possibly this is just because of how fixations work? 
this is especially true when d is >11 or so, which is most of this chunk of data. 

```{r}
d_trial |>
  filter(t_norm < 400 & t_norm >= 0) |>
  inner_join(early_dist |> filter(distractor == 0) |> filter(missing + other < 16) |> filter(target != 16) |> select(administration_id, dataset_name, trial_id, num_target = target)) |>
  mutate(is_target = ifelse(aoi == "target", 1, 0)) |>
  group_by(t_norm, num_target) |>
  summarize(is_target = mean(is_target)) |>
  ggplot(aes(x = t_norm, y = is_target, col = num_target, group = num_target)) +
  geom_point() +
  geom_line() +
  scale_color_viridis()
```
what about when there is both t and d?

I think all we're seeing here is autocorrelation, and also not sure how to deal with 3 way data. 

```{r}
d_trial |>
  filter(t_norm < 400 & t_norm >= 0) |>
  inner_join(early_dist |> filter(distractor > 0) |> filter(missing + other < 16) |> filter(target > 0) |> select(administration_id, dataset_name, trial_id, num_target = target, num_distractor = distractor)) |>
  mutate(distractor_target = case_when(
    aoi == "target" ~ 1,
    aoi == "distractor" ~ 0,
    T ~ NA
  )) |>
  group_by(t_norm, num_target) |>
  summarize(distractor_target = mean(distractor_target, na.rm = T)) |>
  ggplot(aes(x = t_norm, y = distractor_target, col = num_target, group = num_target)) +
  geom_point() +
  geom_line() +
  scale_color_viridis()

d_trial |>
  filter(t_norm < 400 & t_norm >= 0) |>
  inner_join(early_dist |> filter(distractor > 0) |> filter(missing + other < 16) |> filter(target > 0) |> select(administration_id, dataset_name, trial_id, num_target = target, num_distractor = distractor)) |>
  mutate(distractor_target = case_when(
    aoi == "target" ~ 1,
    aoi == "distractor" ~ 0,
    T ~ NA
  )) |>
  group_by(t_norm, num_distractor) |>
  summarize(distractor_target = mean(distractor_target, na.rm = T)) |>
  ggplot(aes(x = t_norm, y = distractor_target, col = num_distractor, group = num_distractor)) +
  geom_point() +
  geom_line() +
  scale_color_viridis()
```
Take-aways from data-viz:
* most of the data is reasonably behaved 30% T-T, 30% D-D, we're looking at whether we can save another like 5%ish onto either by relaxing early missing data requirements
* for other exclusions around long-shift, again, not much data is being affected (maybe 5% but some of this is also going to overlap more with data that has other issues)

reasonable options for where looking when:
* at t=0 at D (nothing else)
* during window (of variable window length), only looking at D (window {100, 200, 300, 400})
* during window (of variable window length), not looking at T (window {100, 200, 300, 400})
* during window (of variable window length), not looking at T and looking at D 3/4+ of the time (window {100, 200, 300, 400})
* at t=0 at D & during window (of variable window length), not looking at T (window {100, 200, 300, 400})
* at t=0 at D & * during window (of variable window length), not looking at T and looking at D 3/4+ of the time (window {100, 200, 300, 400})

so maybe the combinatorics are:

always: during window no looking at T
* looking at D at t=0 (yes/no)
* window length {100, 200, 300, 400}
* looking at D at t=end of window (yes,no)
* looking at D 3/4+ of the time during the window

so we'd want to add functions for 
* window length 0, 100, 200, 300, 400 (where 0=no_window)
* time_0 (binary)
* time_end (binary)
* during (binary) does the 3/4s thing

The obvious place to do this is inside the RLE, but that means working with RLE time-series, which is harder. 
it's built it that t=0 has to be D, that's the part we'd need to re-write

## Attempt 1 at combinatorics
This only analyses D-T shifts
looking at
* the 3 options for RT = the first time you leave, the last time you leave before landing, when you land
* raw v log RT
* the option to trim for max shift length of 600ms either calculated from first leaving or final leaving

all of this is within a requirement of RT data at time 0 (to appropriate thing) but no minimums for shift-start

```{r}
d_rt_dt <- d_rt |>
  filter(shift_type == "D-T") |>
  mutate(
    land_rt = rt,
    first_launch_rt = shift_start_rt,
    last_launch_rt = last_shift_rt
  ) |>
  mutate(
    across(c("land_rt", "first_launch_rt", "last_launch_rt"), log, .names = "log{.col}"),
    across(
      c(
        "land_rt", "first_launch_rt", "last_launch_rt",
        "log_land_rt", "log_first_launch_rt", "log_last_launch_rt"
      ),
      ~ ifelse(shift_length <= 600, .x, NA),
      .names = "trim_first_{.col}"
    ),
    across(
      c(
        "land_rt", "first_launch_rt", "last_launch_rt",
        "log_land_rt", "log_first_launch_rt", "log_last_launch_rt"
      ),
      ~ ifelse(last_shift_length <= 600, .x, NA),
      .names = "trim_last_{.col}"
    )
  ) |>
  select(-rt, -shift_start_rt, -last_shift_rt)

rt_iccs <- d_rt_dt |>
  group_by(dataset_name) |>
  nest() |>
  mutate(icc_admin = map(data, \(d) {
    rt_names <- colnames(d)[str_ends(colnames(d), "rt")]
    n_total <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        nrow()
    })
    n_admin <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        select(administration_id) |>
        unique() |>
        nrow()
    })
    max_kid <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        group_by(administration_id) |>
        tally() |>
        summarize(m = max(n)) |>
        pluck(1, 1)
    })
    min_kid <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        group_by(administration_id) |>
        tally() |>
        summarize(m = min(n)) |>
        pluck(1, 1)
    })
    icc_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])), column = rt_col, object = "administration")
    })
    icc_2_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])) |> group_by(administration_id) |> mutate(trials = n()) |> filter(trials > 1), column = rt_col, object = "administration")
    })
    tibble(measure = rt_names, icc = icc_values, icc_2 = icc_2_values, n_total = n_total, n_admin = n_admin, min_kid = min_kid, max_kid = max_kid)
  })) |>
  select(-data) |>
  unnest(icc_admin)
```

note, still have 0 values, even if we require multiple trials per kid. 
double check on consistency v agreement on ICC. 

```{r}
rt_iccs$dataset_name <- fct_reorder(rt_iccs$dataset_name, rt_iccs$icc)

rt_iccs_coded <- rt_iccs |> mutate(
  type = case_when(
    str_detect(measure, "first_launch_rt") ~ "first_launch",
    str_detect(measure, "last_launch_rt") ~ "last_launch",
    str_detect(measure, "land_rt") ~ "land"
  ),
  logged = case_when(
    str_detect(measure, "log") ~ "log",
    T ~ "raw"
  ),
  trimming = case_when(
    str_detect(measure, "trim_first") ~ "trim_first",
    str_detect(measure, "trim_last") ~ "trim_last",
    T ~ "untrimmed"
  )
)

rt_iccs_coded |>
  group_by(type, logged, trimming) |>
  summarize(mean_icc = mean(icc), datapoints = sum(n_total)) |>
  View()

rt_iccs_coded |> View()
```

raw rt leads to better ICC than log rt

untrimmed landing is pretty good!

but, major issues is that we are seeing 0s! (and 1 x 1) which doesn't make sense?

graphing this is hard!

```{r}
ggplot(
  rt_iccs_coded,
  aes(x = dataset_name, y = icc, col = type)
) +
  geom_point(position = position_dodge(width = .5)) +
  geom_line(aes(group = measure)) +
  coord_flip() +
  facet_grid(logged ~ trimming)
```


## Attempt 2 at combinatorics

so we'd want to add functions for 
* window length 0, 100, 200, 300, 400 (where 0=no_window)
* time_0 (binary)
* time_end (binary)
* during (binary) does the 3/4s thing

This only analyses D-T shifts
looking at
* the 3 options for RT = the first time you leave, the last time you leave before landing, when you land
* raw v log RT
* the option to trim for max shift length of 600ms either calculated from first leaving or final leaving

all of this is within a requirement of RT data at time 0 (to appropriate thing) but no minimums for shift-start

start with just 0, 200, 400 if we see anything then can do a finer grained search!

```{r}
rle_data <- d_trial %>%
  filter(
    any(t_norm == 0), # must have data at 0
    t_norm >= 0
  ) %>% # only pass data after 0
  group_by(administration_id, trial_id, trial_order) %>%
  reframe(
    lengths = rle(aoi)$lengths,
    values = rle(aoi)$values
  )

tic()
d_rt_2 <- rle_data %>%
  group_by(administration_id, trial_id, trial_order) %>%
  nest() |>
  expand_grid(window = c(0, 200, 400), time_0 = c(T, F), time_end = c(F, T), during = c(F, T), frac = c(.75)) %>%
  mutate(rts = pmap(
    list(data, time_0, window, time_end, during, frac),
    \(d, t0, w, te, dur, fr) get_rt(d,
      t_0 = t0, window_length = w,
      t_end = te, window_mostly_region = dur, mostly_fraction = fr
    )
  )) |>
  unnest(cols = c(rts))

toc()

saveRDS(file = here("cached_intermediates", "4_d_rt_2.Rds"), d_rt_2)
```


```{r}
d_rt_2 <- readRDS(here("cached_intermediates", "4_d_rt_2.Rds"))
d_rt_dt_2 <- d_rt_2 |>
  filter(shift_type == "D-T") |>
  mutate(
    land_rt = rt,
    first_launch_rt = shift_start_rt,
    last_launch_rt = last_shift_rt
  ) |>
  mutate(
    across(c("land_rt", "first_launch_rt", "last_launch_rt"), log, .names = "log_{.col}"),
    across(
      c(
        "land_rt", "first_launch_rt", "last_launch_rt",
        "log_land_rt", "log_first_launch_rt", "log_last_launch_rt"
      ),
      ~ ifelse(shift_length <= 600, .x, NA),
      .names = "trim_first_{.col}"
    ),
    across(
      c(
        "land_rt", "first_launch_rt", "last_launch_rt",
        "log_land_rt", "log_first_launch_rt", "log_last_launch_rt"
      ),
      ~ ifelse(last_shift_length <= 600, .x, NA),
      .names = "trim_last_{.col}"
    )
  ) |>
  select(-rt, -shift_start_rt, -last_shift_rt) |>
  left_join(d_trial %>%
    select(-t_norm, -correct, -aoi) %>%
    distinct())

tic()
rt_iccs_2 <- d_rt_dt_2 |>
  group_by(dataset_name, window, time_0, time_end, during, frac) |>
  nest() |>
  mutate(icc_admin = map(data, \(d) {
    rt_names <- colnames(d)[str_ends(colnames(d), "rt")]
    n_total <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        nrow()
    })
    n_admin <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        select(administration_id) |>
        unique() |>
        nrow()
    })
    n_admin_2 <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        group_by(administration_id) |>
        mutate(trials = n()) |>
        filter(trials > 4) |>
        select(administration_id) |>
        unique() |>
        nrow()
    })
    icc_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])), column = rt_col, object = "administration")
    })
    icc_2_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])) |> group_by(administration_id) |> mutate(trials = n()) |> filter(trials > 4), column = rt_col, object = "administration")
    })
    tibble(measure = rt_names, icc = icc_values, icc_2 = icc_2_values, n_total = n_total, n_admin = n_admin, n_admin_2 = n_admin_2)
  })) |>
  select(-data) |>
  unnest(icc_admin)
toc()

fix <- rt_iccs_2 |>
  select(window, time_0, time_end, during, frac, dataset_name, n_admin_2) |>
  unnest(n_admin_2) |>
  unique()

rt_iccs_2 <- rt_iccs_2 |>
  select(-data, -n_admin_2) |>
  left_join(fix)

saveRDS(file = here("cached_intermediates", "4_d_icc_2.Rds"), rt_iccs_2)
```

note, still have 0 values, even if we require multiple trials per kid. 
double check on consistency v agreement on ICC. 

```{r}
rt_iccs_2 <- readRDS(file = here("cached_intermediates", "4_d_icc_2.Rds"))

rt_iccs_2$dataset_name <- fct_reorder(rt_iccs_2$dataset_name, rt_iccs_2$icc)

rt_iccs_coded_2 <- rt_iccs_2 |> mutate(
  type = case_when(
    str_detect(measure, "first_launch_rt") ~ "first_launch",
    str_detect(measure, "last_launch_rt") ~ "last_launch",
    str_detect(measure, "land_rt") ~ "land"
  ),
  logged = case_when(
    str_detect(measure, "log") ~ "log",
    T ~ "raw"
  ),
  trimming = case_when(
    str_detect(measure, "trim_first") ~ "trim_first",
    str_detect(measure, "trim_last") ~ "trim_last",
    T ~ "untrimmed"
  )
)


rt_iccs_coded_2 |> View()
```

note, there's still a large number of 0s and 1s that seem a little suspicious
may want to investigate that
also may want to confirm that the icc we have in the right one

### results

here we collapse across datasets and just look at mean performance. 

looking at best icc's
```{r}
rt_iccs_2_summ <- rt_iccs_coded_2 |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(mean_icc = mean(icc), datapoints = sum(n_total))

rt_iccs_2_summ |>
  arrange(desc(mean_icc)) |>
  head(20) |>
  knitr::kable()
```
a few things we see -- land & last_launch each appear; as do both raw and log; as do trim_last and unntrimmed
window is always 400 and time_end is always true,
some variation in time_0 and during

let's make a lot of plots 

```{r}
rt_iccs_2_summ |> ggplot(aes(x = str_c(logged, "_", type), y = mean_icc, group = interaction(type, logged, trimming))) +
  geom_point(aes(col = trimming), position = position_dodge(width = .4)) +
  stat_summary(position = position_dodge(width = .4)) +
  coord_flip() +
  geom_hline(yintercept = .6) +
  scale_color_brewer(type = "qual", palette = 1)
```
here, raw generally looks better than log (although note is mostly due to low outliers for log). First launch doesn't look great. 


```{r}
rt_iccs_2_summ |>
  ggplot(aes(x = str_c("during", during, "_", "window_end", time_end), y = mean_icc, group = interaction(time_0, time_end, window))) +
  geom_point(aes(col = as.character(window)), position = position_dodge(width = .4)) +
  stat_summary(position = position_dodge(width = .4)) +
  coord_flip() +
  facet_wrap(~ str_c("time_0", time_0)) +
  geom_hline(yintercept = .6) +
  scale_color_brewer(type = "qual", palette = 2)
```

here's the other slides on the data -- of the options we considered for excluding trials based on behavior early in the trial (i.e. not being on the distractor enough), the longer window is best, and it looks like 
* either being on distractor 3/4+ of the time or being on the distractor at the window end is important; with end is slightly better
* given that, being on the distractor at t=0 doesn't matter 

So, combining across these two plots and what the absolute top 20 iccs are, I think we see:
* either land or last_launch is the best option
* we're not sure about trimming, but (especially for coherence with above) either no trim or trim for long delays between last_launch and land
* the 400 window did best, but people often use windows between 200 and 400, so we can explore that region more
* it's important to be on distractor at the end of the window

we also didn't consider a commonly used criteria which is to be on d for the *entirety* of the window.

#### robustness
what if we look instead at a more conservative version -- only kids who contributed 5+ datapoints, and only datasets where there were 10+ of these kids? 

```{r}
rt_iccs_2_summ <- rt_iccs_coded_2 |>
  filter(n_admin_2 > 9) |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(mean_icc = mean(icc_2), datapoints = sum(n_total))

rt_iccs_2_summ |>
  arrange(desc(mean_icc)) |>
  head(20) |>
  knitr::kable()
```
still seeing that for the most part, last_launch and land are best, here it's all log, 400 and time_end true

```{r}
rt_iccs_2_summ |> ggplot(aes(x = str_c(logged, "_", type), y = mean_icc, group = interaction(type, logged, trimming))) +
  geom_point(aes(col = trimming), position = position_dodge(width = .4)) +
  stat_summary(position = position_dodge(width = .4)) +
  coord_flip() +
  geom_hline(yintercept = .6) +
  scale_color_brewer(type = "qual", palette = 1)
```


```{r}
rt_iccs_2_summ |>
  ggplot(aes(x = str_c("during", during, "_", "window_end", time_end), y = mean_icc, group = interaction(time_0, time_end, window))) +
  geom_point(aes(col = as.character(window)), position = position_dodge(width = .4)) +
  stat_summary(position = position_dodge(width = .4)) +
  coord_flip() +
  facet_wrap(~ str_c("time_0", time_0)) +
  geom_hline(yintercept = .6) +
  scale_color_brewer(type = "qual", palette = 2)
```

```{r}
rt_iccs_2_summ |>
  filter(window == 400) |>
  filter(time_end == T) |>
  ggplot(aes(x = str_c(logged, "_", type), y = mean_icc, group = interaction(type, logged, trimming))) +
  geom_point(aes(col = trimming), position = position_dodge(width = .4)) +
  stat_summary(position = position_dodge(width = .4)) +
  coord_flip() +
  geom_hline(yintercept = .6) +
  scale_color_brewer(type = "qual", palette = 1)
```

## Attempt 3 at combinatorics

so for attempt 3, we expand the grid on windows between 200 and 400 and add a new dimension -- the fraction required during that window, ranging across {0, .5, .75, 1}, whereas attempt 2 only checked 0 and .75.




```{r}
rle_data <- d_trial %>%
  filter(
    any(t_norm == 0), # must have data at 0
    t_norm >= 0
  ) %>% # only pass data after 0
  group_by(administration_id, trial_id, trial_order) %>%
  reframe(
    lengths = rle(aoi)$lengths,
    values = rle(aoi)$values
  )

tic()
d_rt_3 <- rle_data %>%
  group_by(administration_id, trial_id, trial_order) %>%
  nest() |>
  expand_grid(window = c(200, 250, 300, 350, 400), time_0 = c(T, F), time_end = c(T), during = c(T), frac = c(0, .5, .75, 1)) %>%
  mutate(rts = pmap(
    list(data, time_0, window, time_end, during, frac),
    \(d, t0, w, te, dur, fr) get_rt(d,
      t_0 = t0, window_length = w,
      t_end = te, window_mostly_region = dur, mostly_fraction = fr
    )
  )) |>
  unnest(cols = c(rts))

toc()

saveRDS(file = here("cached_intermediates", "4_d_rt_3.Rds"), d_rt_3)
```


now do icc for this
```{r}
d_rt_3 <- readRDS(here("cached_intermediates", "4_d_rt_3.Rds"))
d_rt_dt_3 <- d_rt_3 |>
  filter(shift_type == "D-T") |>
  mutate(
    land_rt = rt,
    last_launch_rt = last_shift_rt
  ) |>
  mutate(
    across(c("land_rt", "last_launch_rt"), log, .names = "log_{.col}"),
    across(
      c(
        "land_rt", "last_launch_rt",
        "log_land_rt", "log_last_launch_rt"
      ),
      ~ ifelse(last_shift_length <= 600, .x, NA),
      .names = "trim_last_{.col}"
    )
  ) |>
  select(-rt, -shift_start_rt, -last_shift_rt) |>
  left_join(d_trial %>%
    select(-t_norm, -correct, -aoi) %>%
    distinct())

tic()
rt_iccs_3 <- d_rt_dt_3 |>
  group_by(dataset_name, window, time_0, time_end, during, frac) |>
  nest() |>
  mutate(icc_admin = map(data, \(d) {
    rt_names <- colnames(d)[str_ends(colnames(d), "rt")]
    n_total <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        nrow()
    })
    n_admin <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        select(administration_id) |>
        unique() |>
        nrow()
    })
    n_admin_2 <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        group_by(administration_id) |>
        mutate(trials = n()) |>
        filter(trials > 4) |>
        select(administration_id) |>
        unique() |>
        nrow()
    })
    icc_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])), column = rt_col, object = "administration")
    })
    icc_2_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])) |> group_by(administration_id) |> mutate(trials = n()) |> filter(trials > 4), column = rt_col, object = "administration")
    })
    tibble(measure = rt_names, icc = icc_values, icc_2 = icc_2_values, n_total = n_total, n_admin = n_admin, n_admin_2 = n_admin_2)
  })) |>
  select(-data) |>
  unnest(icc_admin)
toc()

saveRDS(file = here("cached_intermediates", "4_d_rt_icc_3.Rds"), rt_iccs_3)
```

note, still have 0 values, even if we require multiple trials per kid. 
double check on consistency v agreement on ICC. 

```{r}
rt_iccs_3 <- readRDS(here("cached_intermediates", "4_d_rt_icc_3.Rds"))

rt_iccs_3$dataset_name <- fct_reorder(rt_iccs_3$dataset_name, rt_iccs_3$icc)

rt_iccs_coded_3 <- rt_iccs_3 |> mutate(
  type = case_when(
    str_detect(measure, "first_launch_rt") ~ "first_launch",
    str_detect(measure, "last_launch_rt") ~ "last_launch",
    str_detect(measure, "land_rt") ~ "land"
  ),
  logged = case_when(
    str_detect(measure, "log") ~ "log",
    T ~ "raw"
  ),
  trimming = case_when(
    str_detect(measure, "trim_first") ~ "trim_first",
    str_detect(measure, "trim_last") ~ "trim_last",
    T ~ "untrimmed"
  )
)


rt_iccs_coded_3 |> View()
```

### results

here we collapse across datasets and just look at mean performance. 

looking at best icc's
```{r}
rt_iccs_3_summ <- rt_iccs_coded_3 |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(mean_icc = mean(icc), datapoints = sum(n_total))

rt_iccs_3_summ |>
  arrange(desc(mean_icc)) |>
  head(20) |>
  knitr::kable()
```
huh, it's again only 400 -- so possibly this is an issue where the signal we're getting through ICC is either artifactual or it's getting non-relevant consistency? idk. 

some variation in time_0 and variation in required during percentage

let's make a lot of plots 

```{r}
rt_iccs_3_summ |> ggplot(aes(x = str_c(logged, "_", type), y = mean_icc, group = interaction(type, logged, trimming))) +
  geom_point(aes(col = trimming), position = position_dodge(width = .4)) +
  stat_summary(position = position_dodge(width = .4)) +
  coord_flip() +
  geom_hline(yintercept = .6) +
  scale_color_brewer(type = "qual", palette = 1)
```
so, landing looks best at the top, best are untrimmed. 

```{r}
rt_iccs_3_summ |>
  ggplot(aes(x = str_c("frac", frac), y = mean_icc, group = interaction(time_0, frac, window))) +
  geom_point(aes(col = as.character(window)), position = position_dodge(width = .6)) +
  stat_summary(position = position_dodge(width = .6)) +
  coord_flip() +
  facet_wrap(~ str_c("time_0", time_0)) +
  geom_hline(yintercept = .6) +
  scale_color_brewer(type = "qual", palette = 2)
```
hmm, I'm surprised that 400 has such as advantage. that's kind of concerning. 

is it that the 400 standard just drops a lot of data? 

```{r}
rt_iccs_3_summ |>
  ggplot(aes(x = str_c("frac", frac), y = datapoints, group = interaction(time_0, frac, window))) +
  geom_point(aes(col = as.character(window)), position = position_dodge(width = .6)) +
  coord_flip() +
  facet_wrap(~ str_c("time_0", time_0)) +
  scale_color_brewer(type = "qual", palette = 2)

rt_iccs_3_summ |> ggplot(aes(x = mean_icc, y = datapoints)) +
  geom_point(aes(col = as.character(window)), position = position_dodge(width = .6)) +
  coord_flip() +
  facet_wrap(~ str_c("time_0", time_0)) +
  scale_color_brewer(type = "qual", palette = 2)
```
not hugely! 

so, what's the takeaway here?
kind of want to check for cross-data-set reliability

####robustness

again, what if we limit to kids with 5+ and studies with 10+ of those?

```{r}
rt_iccs_3_summ <- rt_iccs_coded_3 |>
  filter(n_admin_2 > 9) |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(mean_icc = mean(icc_2), datapoints = sum(n_total))

rt_iccs_3_summ |>
  arrange(desc(mean_icc)) |>
  head(20) |>
  knitr::kable()
```
huh, maybe we should trim? 

```{r}
rt_iccs_3_summ |> ggplot(aes(x = str_c(logged, "_", type), y = mean_icc, group = interaction(type, logged, trimming))) +
  geom_point(aes(col = trimming), position = position_dodge(width = .4)) +
  stat_summary(position = position_dodge(width = .4)) +
  coord_flip() +
  geom_hline(yintercept = .6) +
  scale_color_brewer(type = "qual", palette = 1)
```
actually, not a huge difference for trim v untrimmed (except for raw_land)

```{r}
rt_iccs_3_summ |>
  ggplot(aes(x = str_c("frac", frac), y = mean_icc, group = interaction(time_0, frac, window))) +
  geom_point(aes(col = as.character(window)), position = position_dodge(width = .6)) +
  stat_summary(position = position_dodge(width = .6)) +
  coord_flip() +
  facet_wrap(~ str_c("time_0", time_0)) +
  geom_hline(yintercept = .6) +
  scale_color_brewer(type = "qual", palette = 2)
```

## Attempt 4
from attempt 3, we saw that requiring kids to be on distractor at 400ms got highest reliability, but this also the highest we tried, so I'm concerned that there's some sort of losing data making icc better rather than actual (good) reliability. 

to check on that, for one setting, let's try doing windows of > 400 ms and up to when the peak RTs we're observing are. 

looks like the peak tends to be <1000ms

we're also not doing the full combinatorics here, I just want to check what the pattern is. 

```{r}
rle_data <- d_trial %>%
  filter(
    any(t_norm == 0), # must have data at 0
    t_norm >= 0
  ) %>% # only pass data after 0
  group_by(administration_id, trial_id, trial_order) %>%
  reframe(
    lengths = rle(aoi)$lengths,
    values = rle(aoi)$values
  )

tic()
d_rt_4 <- rle_data %>%
  group_by(administration_id, trial_id, trial_order) %>%
  nest() |>
  expand_grid(window = c(450, 500, 600, 700, 800, 900, 1000), time_0 = c(F), time_end = c(T), during = c(T), frac = c(0)) %>%
  mutate(rts = pmap(
    list(data, time_0, window, time_end, during, frac),
    \(d, t0, w, te, dur, fr) get_rt(d,
      t_0 = t0, window_length = w,
      t_end = te, window_mostly_region = dur, mostly_fraction = fr
    )
  )) |>
  unnest(cols = c(rts))

toc()

saveRDS(file = here("cached_intermediates", "4_d_rt_4.Rds"), d_rt_4)
```

```{r}
d_rt_4 <- readRDS(here("cached_intermediates", "4_d_rt_4.Rds"))
d_rt_dt_4 <- d_rt_4 |>
  filter(shift_type == "D-T") |>
  mutate(
    land_rt = rt
  ) |>
  select(-rt, -shift_start_rt, -last_shift_rt) |>
  left_join(d_trial %>%
    select(-t_norm, -correct, -aoi) %>%
    distinct())

tic()
rt_iccs_4 <- d_rt_dt_4 |>
  group_by(dataset_name, window, time_0, time_end, during, frac) |>
  nest() |>
  mutate(icc_admin = map(data, \(d) {
    rt_names <- colnames(d)[str_ends(colnames(d), "rt")]
    n_total <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        nrow()
    })
    n_admin <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        select(administration_id) |>
        unique() |>
        nrow()
    })
    n_admin_2 <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        group_by(administration_id) |>
        mutate(trials = n()) |>
        filter(trials > 4) |>
        select(administration_id) |>
        unique() |>
        nrow()
    })
    icc_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])), column = rt_col, object = "administration")
    })
    icc_2_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])) |> group_by(administration_id) |> mutate(trials = n()) |> filter(trials > 4), column = rt_col, object = "administration")
    })
    tibble(measure = rt_names, icc = icc_values, icc_2 = icc_2_values, n_total = n_total, n_admin = n_admin, n_admin_2 = n_admin_2)
  })) |>
  select(-data) |>
  unnest(icc_admin)
toc()

saveRDS(file = here("cached_intermediates", "4_d_rt_icc_4.Rds"), rt_iccs_4)
```

```{r}
rt_iccs_4 <- readRDS(here("cached_intermediates", "4_d_rt_icc_4.Rds"))

rt_iccs_4$dataset_name <- fct_reorder(rt_iccs_4$dataset_name, rt_iccs_4$icc)

rt_iccs_coded_4 <- rt_iccs_4 |> mutate(
  type = case_when(
    str_detect(measure, "first_launch_rt") ~ "first_launch",
    str_detect(measure, "last_launch_rt") ~ "last_launch",
    str_detect(measure, "land_rt") ~ "land"
  ),
  logged = case_when(
    str_detect(measure, "log") ~ "log",
    T ~ "raw"
  ),
  trimming = case_when(
    str_detect(measure, "trim_first") ~ "trim_first",
    str_detect(measure, "trim_last") ~ "trim_last",
    T ~ "untrimmed"
  )
)


rt_iccs_coded_4 |> View()
```

### results

```{r}
rt_iccs_4_summ <- rt_iccs_coded_4 |>
  bind_rows(rt_iccs_coded_3) |>
  filter(type == "land", logged == "raw", trimming == "untrimmed", time_0 == F, time_end == T, during == T, frac == 0) |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(mean_icc = mean(icc), datapoints = sum(n_total))

rt_iccs_4_summ |>
  arrange(desc(mean_icc)) |>
  head(20) |>
  knitr::kable()
```
that's reassuring! here we see that it is a local peak at 400. 

```{r}
rt_iccs_coded_4 |>
  bind_rows(rt_iccs_coded_3) |>
  filter(type == "land", logged == "raw", trimming == "untrimmed", time_0 == F, time_end == T, during == T, frac == 0) |>
  ggplot(aes(x = window, y = icc)) +
  geom_point(aes(col = dataset_name)) +
  stat_summary()
```


```{r}
rt_iccs_4_summ <- rt_iccs_coded_4 |>
  bind_rows(rt_iccs_coded_3) |>
  filter(type == "land", logged == "raw", trimming == "untrimmed", time_0 == F, time_end == T, during == T, frac == 0) |>
  filter(n_admin_2 > 9) |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(mean_icc = mean(icc_2), datapoints = sum(n_total))

rt_iccs_4_summ |>
  arrange(desc(mean_icc)) |>
  head(20) |>
  knitr::kable()

rt_iccs_coded_4 |>
  bind_rows(rt_iccs_coded_3) |>
  filter(type == "land", logged == "raw", trimming == "untrimmed", time_0 == F, time_end == T, during == T, frac == 0) |>
  filter(n_admin_2 > 9) |>
  ggplot(aes(x = window, y = icc_2)) +
  geom_point(aes(col = dataset_name)) +
  stat_summary()
```
in the more filtered one, we're seeing it a little differently. we should look more closely at the 300-500 range I think, maybe with more measures. 

## how much is this driven by 0s and 1s

```{r}
all <- rt_iccs_coded_2 |>
  bind_rows(rt_iccs_coded_3) |>
  bind_rows(rt_iccs_coded_4)

all_raw <- all |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(icc_raw = mean(icc)) |>
  arrange(desc(icc_raw)) |>
  head(50)

all_raw_no_0 <- all |>
  filter(icc > 0, icc < 1) |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(icc_raw_no_0 = mean(icc)) |>
  arrange(desc(icc_raw_no_0)) |>
  head(50)

all_filter <- all |>
  filter(n_admin_2 > 9) |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(icc_filter = mean(icc_2)) |>
  arrange(desc(icc_filter)) |>
  head(50)

all_filter_no_0 <- all |>
  filter(n_admin_2 > 9) |>
  filter(icc_2 > 0, icc_2 < 1) |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(icc_filter_no_0 = mean(icc_2)) |>
  arrange(desc(icc_filter_no_0)) |>
  head(50)

all_icc <- all_raw |>
  inner_join(all_raw_no_0) |>
  inner_join(all_filter) |>
  inner_join(all_filter_no_0)

View(all_icc)
```
so, across these, suggests that log is better; landing is fine (but last launch is also fine); trimming is probably not necessary; being on distractor at end of time window (=400) is good; being on distractor at T=0 is good, fine to wander in between. 


## Attempt 5: what's like the essential comparison

we could take the options that were well performing (+ non-logged versions)

land x (log | raw) x (trim |untrim) x (windows in 300-500) x (on at time 0) x (on at time end) 

knowing there's a lot of substitutions one could make!

```{r}
rle_data <- d_trial %>%
  filter(
    any(t_norm == 0), # must have data at 0
    t_norm >= 0
  ) %>% # only pass data after 0
  group_by(administration_id, trial_id, trial_order) %>%
  reframe(
    lengths = rle(aoi)$lengths,
    values = rle(aoi)$values
  )

tic()
d_rt_5 <- rle_data %>%
  group_by(administration_id, trial_id, trial_order) %>%
  nest() |>
  expand_grid(window = c(300, 350, 400, 450, 500), time_0 = c(T), time_end = c(T), during = c(F), frac = c(0)) %>%
  mutate(rts = pmap(
    list(data, time_0, window, time_end, during, frac),
    \(d, t0, w, te, dur, fr) get_rt(d,
      t_0 = t0, window_length = w,
      t_end = te, window_mostly_region = dur, mostly_fraction = fr
    )
  )) |>
  unnest(cols = c(rts))

toc()

saveRDS(file = here("cached_intermediates", "4_d_rt_5.Rds"), d_rt_5)
```

```{r}
d_rt_5 <- readRDS(here("cached_intermediates", "4_d_rt_5.Rds"))
d_rt_dt_5 <- d_rt_5 |>
  filter(shift_type == "D-T") |>
  mutate(
    land_rt = rt,
    last_launch_rt = last_shift_rt
  ) |>
  mutate(
    across(c("land_rt", ), log, .names = "log_{.col}"),
    across(
      c(
        "land_rt",
        "log_land_rt",
      ),
      ~ ifelse(last_shift_length <= 600, .x, NA),
      .names = "trim_last_{.col}"
    )
  ) |>
  select(-rt, -shift_start_rt, -last_shift_rt) |>
  left_join(d_trial %>%
    select(-t_norm, -correct, -aoi) %>%
    distinct())

tic()
rt_iccs_5 <- d_rt_dt_5 |>
  group_by(dataset_name, window, time_0, time_end, during, frac) |>
  nest() |>
  mutate(icc_admin = map(data, \(d) {
    rt_names <- colnames(d)[str_ends(colnames(d), "rt")]
    n_total <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        nrow()
    })
    n_admin <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        select(administration_id) |>
        unique() |>
        nrow()
    })
    n_admin_2 <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        group_by(administration_id) |>
        mutate(trials = n()) |>
        filter(trials > 4) |>
        select(administration_id) |>
        unique() |>
        nrow()
    })
    icc_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])), column = rt_col, object = "administration")
    })
    icc_2_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])) |> group_by(administration_id) |> mutate(trials = n()) |> filter(trials > 4), column = rt_col, object = "administration")
    })
    tibble(measure = rt_names, icc = icc_values, icc_2 = icc_2_values, n_total = n_total, n_admin = n_admin, n_admin_2 = n_admin_2)
  })) |>
  select(-data) |>
  unnest(icc_admin)
toc()

saveRDS(file = here("cached_intermediates", "4_d_rt_icc_5.Rds"), rt_iccs_5)
```
### results
```{r}
rt_iccs_5 <- readRDS(here("cached_intermediates", "4_d_rt_icc_5.Rds"))

rt_iccs_5$dataset_name <- fct_reorder(rt_iccs_5$dataset_name, rt_iccs_5$icc)

rt_iccs_coded_5 <- rt_iccs_5 |> mutate(
  type = case_when(
    str_detect(measure, "first_launch_rt") ~ "first_launch",
    str_detect(measure, "last_launch_rt") ~ "last_launch",
    str_detect(measure, "land_rt") ~ "land"
  ),
  logged = case_when(
    str_detect(measure, "log") ~ "log",
    T ~ "raw"
  ),
  trimming = case_when(
    str_detect(measure, "trim_first") ~ "trim_first",
    str_detect(measure, "trim_last") ~ "trim_last",
    T ~ "untrimmed"
  )
)


rt_iccs_coded_5 |> View()
```


```{r}
all <- rt_iccs_coded_5

all_raw <- all |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(icc_raw = mean(icc))

all_raw_no_0 <- all |>
  filter(icc > 0, icc < 1) |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(icc_raw_no_0 = mean(icc))

all_filter <- all |>
  filter(n_admin_2 > 9) |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(icc_filter = mean(icc_2))

all_filter_no_0 <- all |>
  filter(n_admin_2 > 9) |>
  filter(icc_2 > 0, icc_2 < 1) |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(icc_filter_no_0 = mean(icc_2))

all_icc <- all_raw |>
  left_join(all_raw_no_0) |>
  left_join(all_filter) |>
  left_join(all_filter_no_0)
```

```{r}
all_icc |>
  filter(type == "land") |>
  ggplot(aes(x = as.character(window), y = icc_filter, group = interaction(logged, trimming, window))) +
  geom_point(aes(col = str_c(logged, "_", trimming)), position = position_dodge(width = .6)) +
  coord_flip() +
  geom_hline(yintercept = .6) +
  scale_color_brewer(type = "qual", palette = 2)
```

so 400 is better than 350, and works pretty well regardless of log or trim
450 and 500 logged are also good
if we filter log is important

## compare to ~common practices

so I think the proposed options are
* on continuously 0-{350|400} + land
* on continuously 0-{350|400} + first launch + trim to 600
* mine

and we can do both log and non-log

note that we actually need to rerun to get traditional launch!
```{r}
rle_data <- d_trial %>%
  filter(
    any(t_norm == 0), # must have data at 0
    t_norm >= 0
  ) %>% # only pass data after 0
  group_by(administration_id, trial_id, trial_order) %>%
  reframe(
    lengths = rle(aoi)$lengths,
    values = rle(aoi)$values
  )

tic()
d_rt_6 <- rle_data %>%
  group_by(administration_id, trial_id, trial_order) %>%
  nest() |>
  expand_grid(window = c(350, 400), time_0 = c(T), time_end = c(T), during = c(T), frac = c(1)) %>%
  mutate(rts = pmap(
    list(data, time_0, window, time_end, during, frac),
    \(d, t0, w, te, dur, fr) get_rt(d,
      t_0 = t0, window_length = w,
      t_end = te, window_mostly_region = dur, mostly_fraction = fr
    )
  )) |>
  unnest(cols = c(rts))

toc()

saveRDS(file = here("cached_intermediates", "4_d_rt_6.Rds"), d_rt_6)
```

```{r}
d_rt_6 <- readRDS(here("cached_intermediates", "4_d_rt_6.Rds"))
d_rt_dt_6 <- d_rt_6 |>
  filter(shift_type == "D-T") |>
  mutate(
    first_launch_rt = shift_start_rt,
  ) |>
  mutate(
    across(c("first_launch_rt", ), log, .names = "log_{.col}"),
    across(
      c(
        "first_launch_rt", ,
        "log_first_launch_rt",
      ),
      ~ ifelse(shift_length <= 600, .x, NA),
      .names = "trim_first_{.col}"
    ),
  ) |>
  select(-rt, -shift_start_rt, -last_shift_rt, -first_launch_rt, -log_first_launch_rt) |>
  left_join(d_trial %>%
    select(-t_norm, -correct, -aoi) %>%
    distinct())

tic()
rt_iccs_6 <- d_rt_dt_6 |>
  group_by(dataset_name, window, time_0, time_end, during, frac) |>
  nest() |>
  mutate(icc_admin = map(data, \(d) {
    rt_names <- colnames(d)[str_ends(colnames(d), "rt")]
    n_total <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        nrow()
    })
    n_admin <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        select(administration_id) |>
        unique() |>
        nrow()
    })
    n_admin_2 <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        group_by(administration_id) |>
        mutate(trials = n()) |>
        filter(trials > 4) |>
        select(administration_id) |>
        unique() |>
        nrow()
    })
    icc_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])), column = rt_col, object = "administration")
    })
    icc_2_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])) |> group_by(administration_id) |> mutate(trials = n()) |> filter(trials > 4), column = rt_col, object = "administration")
    })
    tibble(measure = rt_names, icc = icc_values, icc_2 = icc_2_values, n_total = n_total, n_admin = n_admin, n_admin_2 = n_admin_2)
  })) |>
  select(-data) |>
  unnest(icc_admin)
toc()

saveRDS(file = here("cached_intermediates", "4_d_rt_icc_6.Rds"), rt_iccs_6)
```
```{r}
rt_iccs_6 <- readRDS(here("cached_intermediates", "4_d_rt_icc_6.Rds"))

rt_iccs_6$dataset_name <- fct_reorder(rt_iccs_6$dataset_name, rt_iccs_6$icc)

rt_iccs_coded_6 <- rt_iccs_6 |> mutate(
  type = case_when(
    str_detect(measure, "first_launch_rt") ~ "first_launch",
    str_detect(measure, "last_launch_rt") ~ "last_launch",
    str_detect(measure, "land_rt") ~ "land"
  ),
  logged = case_when(
    str_detect(measure, "log") ~ "log",
    T ~ "raw"
  ),
  trimming = case_when(
    str_detect(measure, "trim_first") ~ "trim_first",
    str_detect(measure, "trim_last") ~ "trim_last",
    T ~ "untrimmed"
  )
)


rt_iccs_coded_6 |> View()
```

```{r}
all <- rt_iccs_coded_2 |>
  bind_rows(rt_iccs_coded_3) |>
  bind_rows(rt_iccs_coded_4) |>
  bind_rows(rt_iccs_coded_5) |>
  bind_rows(rt_iccs_coded_6)

traditional_land <- all |>
  filter(frac == 1, type == "land", window %in% c(350, 400), trimming == "untrimmed", time_0, time_end) |>
  mutate(approach = "trad_land")

traditional_launch <- all |>
  filter(frac == 1, type == "first_launch", trimming == "trim_first", window %in% c(350, 400), time_0, time_end) |>
  mutate(approach = "trad_launch")

data_driven <- all |>
  filter(type == "land", window %in% c(350, 400), time_end, time_0, during == F, trimming == "untrimmed", frac == 0) |>
  mutate(approach = "data_driven")

comp <- traditional_land |>
  bind_rows(traditional_launch) |>
  bind_rows(data_driven)
```

```{r}
comp |> ggplot(aes(x = as.character(window), y = icc, color = approach, group = approach)) +
  facet_wrap(~logged) +
  geom_point(position = position_dodge(width = .5)) +
  stat_summary(fun.data = "mean_cl_boot", color = "black", position = position_dodge(width = .5)) +
  geom_hline(yintercept = .6) +
  coord_flip()

comp |>
  filter(icc > 0, icc < 1) |>
  ggplot(aes(x = as.character(window), y = icc, color = approach, group = approach)) +
  facet_wrap(~logged) +
  geom_point(position = position_dodge(width = .5)) +
  stat_summary(fun.data = "mean_cl_boot", color = "black", position = position_dodge(width = .5)) +
  coord_flip()


comp |> ggplot(aes(x = as.character(window), y = log(n_total), color = approach, group = approach)) +
  facet_wrap(~logged) +
  geom_point(position = position_dodge(width = .5)) +
  stat_summary(fun.data = "mean_cl_boot", color = "black", position = position_dodge(width = .5)) +
  coord_flip()
```
So, I think the conclusion is that what people have been doing is ~fine, but also has been tossing out more data than necessary (especially on datasets where there might be tracker loss). 

From onset to earliest response, want the kid not looking at target and at least mostly looking at distractor -- easy to operationalize as on distractor at time 0 and time end. No need for trimming for shift length, and landing RT is fine to use. 

Using log RT is better and 400 ms is a better cutoff than 350 (unclear what happens inbetween). 

## validity?

so we don't have great validity options here because it's less clear what RT should index, but we can check for age effects (very expected, but could index non-linguistic noise) and CDI (not necessarily expected to correlate as much with RT as accuracy)

so we'll go with the 400ms versions of the 3 above (here we aren't logging, but we could compare to logged as well)

### get the RTs from caches

```{r}
trad_launch <- readRDS(here("cached_intermediates", "4_d_rt_6.Rds")) |>
  filter(frac == 1, window == 400, time_0, time_end) |>
  filter(shift_length <= 600) |>
  filter(shift_type == "D-T") |>
  mutate(useable_rt = shift_start_rt) |>
  mutate(approach = "trad_launch") |>
  group_by(approach, administration_id) |>
  summarize(mean_rt = mean(useable_rt), n_rts = n())


trad_land <- readRDS(here("cached_intermediates", "4_d_rt_3.Rds")) |>
  filter(frac == 1, window == 400, time_0, time_end) |>
  filter(shift_type == "D-T") |>
  mutate(useable_rt = rt) |>
  mutate(approach = "trad_land") |>
  group_by(approach, administration_id) |>
  summarize(mean_rt = mean(useable_rt), n_rts = n())

new <- readRDS(here("cached_intermediates", "4_d_rt_3.Rds")) |>
  filter(frac == 0, window == 400, time_0, time_end) |>
  filter(shift_type == "D-T") |>
  mutate(useable_rt = rt) |>
  mutate(approach = "new") |>
  group_by(approach, administration_id) |>
  summarize(mean_rt = mean(useable_rt), n_rts = n())

cdi_data <- readRDS(here("cached_intermediates", "1_cdi_subjects.Rds"))

approaches_for_cdi <- trad_launch |>
  bind_rows(trad_land, new) |>
  left_join(d_trial |> select(dataset_name, administration_id, subject_id) |> unique())

for_cdi_corr <- approaches_for_cdi |> left_join(cdi_data)

dataset_relevant <- approaches_for_cdi |>
  ungroup() |>
  select(dataset_name, administration_id) |>
  unique()

cdi_data |>
  inner_join(dataset_relevant) |>
  filter(!(is.na(prod) & is.na(comp))) |>
  select(dataset_name) |>
  unique()

for_cdi_corr |>
  ungroup() |>
  filter(!(is.na(prod) & is.na(comp))) |>
  select(dataset_name) |>
  unique()
```

something is wrong here -- the administration id/subject ids from cdi aren't lining up with the ones from RT --> is this somehow a dataset versioning issue?

```{r}
# cdi data
cdi_corr <- for_cdi_corr |>
  filter(!(is.na(prod) & is.na(comp))) |>
  filter(!is.na(mean_rt))
group_by(dataset_name, approach) |>
  summarise(
    cor_comp = ifelse(sum(!is.na(comp)) > 0, cor.test(mean_rt, comp)$estimate, NA),
    cor_prod = ifelse(sum(!is.na(prod)) > 0, cor.test(mean_rt, prod)$estimate, NA),
    cor_age = ifelse(sum(!is.na(age)) > 0, cor.test(mean_rt, age)$estimate, NA),
    n_comp = sum(!is.na(comp)),
    n_prod = sum(!is.na(prod)),
    n_total = sum(!is.na(mean_rt)),
    mean_trials = mean(n_rts)
  )
```

### visualize

```{r}
cdi_corr |> ggplot(aes(x = approach, y = cor_prod)) +
  geom_point() +
  coord_flip()
```





# Old
## Computing RT 
First compute reaction time. 

NOTE 1/31/24 - consider computing RT from LAUNCH not from LANDING - this may make a difference to what we end up finding. 
MZ: 4/29/24 - both launch and landing-based RT computed by rt helper function
* `rt`: landing-time based RT
* `shift_start_rt`: launch-time based RT

We need RLE data, then we use the RT helper from peekbank-shiny. 

Note MCF: 8/25/25 - we cached this function in the current repo to remove dependencies. 



Compute RTs, relying on the RLE workflow from the shiny app. 



How many trials have RTs for them?

Almost every trial makes it through the computation, but what prop do we have RTs for.

```{r}
d_rt <- readRDS(file = here("cached_intermediates", "4_d_rt.Rds"))

# rt_stats <- d_rt %>%
#   ungroup() %>%
#   summarise(
#     nas = mean(is.na(shift_start_rt)),
#     too_fast = mean(shift_start_rt < 300, na.rm = TRUE),
#     d_t = mean(shift_type == "D-T", na.rm = TRUE),
#     t_d = mean(shift_type == "T-D", na.rm = TRUE),
#     other = mean(shift_type == "other", na.rm = TRUE),
#     no_shift = mean(shift_type == "no shift", na.rm = TRUE)
#   )
#
# knitr::kable(rt_stats, digits = 2)
```




## How to measure shift initiation

```{r}
# not sure whether we should count shift initiation as when the child first looks away from D or when they are last looking at D before looking at T

# how often are these distinct?
```
about 5% of the data that has a shift has a difference between these two measures
but only abut 1% of data with a shift has this difference *and* doesn't have a long shift time, so this is probably not of large consequence. 

```{r}
# does it matter which type of shift we use
ggplot(d_rt, aes(x = shift_start_rt, y = last_shift_rt)) +
  geom_point(alpha = .5, aes(col = age)) +
  geom_smooth(method = "lm") +
  viridis::scale_color_viridis()

ggplot(
  d_rt,
  aes(x = shift_start_rt, y = last_shift_rt)
) +
  geom_point(alpha = .5, aes(col = age)) +
  geom_point(
    data = filter(d_rt, shift_length > 600),
    col = "red"
  ) +
  geom_smooth(method = "lm") +
  viridis::scale_color_viridis()
```





## RT distribution & exclusion

Examine RT distribution.

```{r}
ggplot(filter(d_rt), aes(x = shift_start_rt)) +
  geom_histogram()
```

Logs. 

```{r}
ggplot(d_rt, aes(x = shift_start_rt)) +
  geom_histogram() +
  scale_x_log10()
```

Probably should get rid of the RTs < 250ms or so. 

```{r}
mean(d_rt$shift_start_rt < 250, na.rm = TRUE)
```

Filter. 

```{r}
d_rt_all <- filter(
  d_rt,
  !is.na(shift_start_rt)
)
d_rt <- filter(
  d_rt,
  !is.na(shift_start_rt),
  shift_start_rt > 250
)
```

Look by age.

```{r}
ggplot(
  d_rt,
  aes(x = age, y = rt)
) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm")
```
Add dataset to try to figure out blockiness. 

```{r}
ggplot(
  d_rt,
  aes(x = age, y = rt)
) +
  geom_point(alpha = .1) +
  geom_smooth(method = "lm") +
  facet_wrap(~dataset_name)
```

Histogram by dataset. 

```{r}
ggplot(
  d_rt,
  aes(x = rt)
) +
  geom_histogram(bins = 10) +
  scale_x_log10() +
  facet_wrap(~dataset_name, scales = "free_y")
```



## RT reliabilities




TODO: rank/score them for the different things 
Why are some ICCs zero? Let's look at Pomper Saffran 2016.

```{r}
ps <- d_rt |>
  filter(dataset_name == "pomper_saffran_2016")

ggplot(
  ps,
  aes(x = target_label, y = shift_start_rt)
) +
  geom_jitter(alpha = .5, width = .2) +
  stat_summary(col = "red") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

ggplot(
  ps,
  aes(x = administration_id, y = shift_start_rt)
) +
  geom_jitter(alpha = .5, width = .2) +
  stat_summary(col = "red")
```

Now check ICCs for RTs for ALL trials (not subsetting to D-T trials). They look OK.

```{r}
# disaggregated
get_icc(ps, object = "stimulus", column = "shift_start_rt")
get_icc(ps, object = "administration", column = "shift_start_rt")
```


```{r}
ps_icc <- dim_icc(ps,
  model = "2A",
  type = "agreement",
  unit = "average",
  object = administration_id,
  rater = target_label,
  trial = trial_id,
  score = shift_start_rt,
  bootstrap = 1000
)

summary(ps_icc)
```

This all looks good and ICCs seem reasonably high - but why do we get fewer zeros when we subset to D-T trials? Let's dig into this. 

Pomper SalientMe shows this pattern. 

```{r}
ps_dt <- ps |>
  filter(shift_type == "D-T")

get_icc(ps, object = "stimulus", column = "shift_start_rt")
get_icc(ps_dt, object = "stimulus", column = "shift_start_rt")
```

Stimulus ICC goes to zero for D-T trials. Let's look at the cross between subjects and trials for each. 

```{r}
ps |>
  ungroup() |>
  select(subject_id, target_label, shift_start_rt) |>
  arrange(target_label) |>
  pivot_wider(names_from = "target_label", values_from = "shift_start_rt") |>
  arrange(subject_id) |>
  View()

# summarize by stimulus
ps_stimulus_rt_summarized <- ps |>
  ungroup() |>
  group_by(target_label) |>
  summarize(
    N = n(),
    mean_rt = mean(shift_start_rt, na.rm = TRUE)
  )

ps_stimulus_rt_summarized <- ps |>
  ungroup() |>
  group_by(target_label) |>
  summarize(
    N = n(),
    mean_rt = mean(shift_start_rt, na.rm = TRUE)
  )

ps_admin_rt_summarized <- ps |>
  ungroup() |>
  group_by(administration_id) |>
  summarize(
    N = n(),
    mean_rt = mean(shift_start_rt, na.rm = TRUE)
  )


ps_dt |>
  ungroup() |>
  select(subject_id, target_label, shift_start_rt) |>
  arrange(target_label) |>
  pivot_wider(names_from = "target_label", values_from = "shift_start_rt") |>
  arrange(subject_id) |>
  View()

# summarize by stimulus
ps_dt_stimulus_rt_summarized <- ps_dt |>
  ungroup() |>
  group_by(administration_id, target_label) |>
  summarize(
    N = n(),
    mean_rt = mean(shift_start_rt, na.rm = TRUE),
    unique_participants = length(unique(administration_id))
  )

ps_dt_admin_rt_summarized <- ps_dt |>
  ungroup() |>
  group_by(administration_id) |>
  summarize(
    N = n(),
    mean_rt = mean(shift_start_rt, na.rm = TRUE)
  )
```

So the D-T dataframe is sparser, but looks more consistent. Let's check out the distributions. 

Let's check if removing rare items fixes the ICC issue

```{r}
rare_items <- ps_dt_stimulus_rt_summarized |>
  filter(N < 8) %>%
  pull(target_label)
rare_participants <- ps_dt_admin_rt_summarized |>
  filter(N < 5) %>%
  pull(administration_id)

get_icc(filter(ps_dt, !(target_label %in% rare_items)), object = "stimulus", column = "shift_start_rt")
get_icc(filter(ps_dt, !(administration_id %in% rare_participants)), object = "stimulus", column = "shift_start_rt")
```

filtering out rare participants or stimuli doesn't seem to matter.


```{r}
ggplot(ps, aes(x = rt)) +
  geom_histogram() +
  facet_wrap(~shift_type)
```
This is consistent with the idea that T-D shifts are more random/ uninformative. Let's look at all data. 

```{r}
ggplot(d_rt, aes(x = rt)) +
  geom_histogram() +
  facet_wrap(~shift_type)
```
Looks well-supported that T-D RTs are different. I now feel comfortable moving forward with D-T only. 
Let's compare ICC from RTs to ICCs from accuracy. 

```{r}
d_summary <- d_trial |>
  group_by(
    dataset_name, trial_id, dataset_id, subject_id, administration_id,
    target_label
  ) |>
  summarise(
    accuracy = mean(correct[t_norm > 500], na.rm = TRUE),
    prop_data = mean(!is.na(correct[t_norm > 500]))
  ) |>
  filter(!is.na(accuracy))

trial_ns_acc <- bind_rows(
  d_summary |>
    group_by(dataset_name, subject_id) |>
    count() |>
    group_by(dataset_name) |>
    summarise(
      n = mean(n),
      dimension = "admin"
    ),
  d_summary |>
    group_by(dataset_name, target_label) |>
    count() |>
    group_by(dataset_name) |>
    summarise(
      n = mean(n),
      dimension = "stimulus"
    )
)

trial_ns_rt <- bind_rows(
  d_rt_dt |>
    group_by(dataset_name, subject_id) |>
    count() |>
    group_by(dataset_name) |>
    summarise(
      n = mean(n),
      dimension = "admin"
    ),
  bind_rows(d_rt_dt |>
    group_by(dataset_name, subject_id) |>
    count() |>
    group_by(dataset_name) |>
    summarise(
      n = mean(n),
      dimension = "stimulus"
    ))
)
# load ICCs for accuracy
load(file = here("cached_intermediates", "2_iccs_accuracy.Rds"))

iccs_long <- iccs |>
  pivot_longer(
    names_to = "dimension", values_to = "icc",
    icc_stimulus_acc:icc_admin_acc
  ) |>
  ungroup() |>
  separate(dimension, into = c("type", "dimension", "measure")) |>
  mutate(dataset_name = fct_reorder(dataset_name, icc))


acc_rt_iccs <- bind_rows(
  filter(iccs_long, measure == "acc") |>
    left_join(trial_ns_acc),
  rt_iccs_long |>
    left_join(trial_ns_rt)
) |>
  mutate(dataset_name = fct_reorder(as.factor(dataset_name), icc)) |>
  select(-type)


ggplot(
  acc_rt_iccs,
  aes(x = dataset_name, y = icc, col = measure)
) +
  geom_point(aes(size = n),
    position = position_dodge(width = .5)
  ) +
  geom_line(aes(group = measure)) +
  facet_wrap(~dimension) +
  theme(axis.text.x = element_text(angle = -90))

acc_rt_iccs |>
  arrange(dataset_name) |>
  mutate(
    icc = round(icc, digits = 2),
    n = round(n)
  )
```

Let's plot by N. 

```{r}
ggplot(
  acc_rt_iccs,
  aes(x = n, y = icc, col = dataset_name)
) +
  geom_point() +
  geom_smooth(aes(group = 1), method = "loess", span = 10, se = FALSE) +
  # scale_x_log10() +
  facet_wrap(dimension ~ measure, scales = "free_x") +
  xlab("N trials per child/word") +
  ylab("Intraclass Correlation Coefficient") +
  ylim(0, 1)
```
This is interesting! We are getting a bunch of signal about individual participants from RT, actually higher ICC than accuracies. Not so much for stimulus information, where it seems like we are doing better from accuracy. Also, as predicted the number of trials per child or per word appears to relate across datasets to the ICC (though there's lots of variance at the bottom end that presumably relates to the variation in ability across kids/variation in difficulty across words). If you choose very different words you get high reliability on that dimension (see "reliability paradoxes" idea).

## Compare ICCs for RT and Accuracy

```{r}
# combine
all_iccs <- iccs %>%
  left_join(rt_iccs)

# plot - Participants
ggplot(all_iccs, aes(admin_rt, icc_admin_acc)) +
  geom_point(size = 1.5) +
  geom_text(aes(label = dataset_name)) +
  geom_abline(intercept = 0, slope = 1) +
  xlim(0, 1) +
  ylim(0, 1)
```

plot - Items

```{r}
ggplot(all_iccs, aes(stimulus_rt, icc_stimulus_acc)) +
  geom_point(size = 1.5) +
  geom_text(aes(label = dataset_name)) +
  geom_abline(intercept = 0, slope = 1) +
  xlim(0, 1) +
  ylim(0, 1)
```

## Look at RTs as a function of filtering

```{r}
save(d_rt_dt, file = here("cached_intermediates", "4_d_rt_dt.Rds"))
```
