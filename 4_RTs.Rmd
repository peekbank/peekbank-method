---
title: "RT Computation"
author: "Mike Frank"
date: "2022-12-15"
output: html_document
---


```{r}
source(here::here("helper/common.R"))
```
# Load data and prep intermediates



```{r}
# later version cached, no need to run
load(file = here("cached_intermediates", "1_d_trial.Rds"))
```

```{r}
source("helper/rt_helper.R")
```

```{r}
rle_data <- d_trial %>%
  filter(
    any(t_norm == 0), # must have data at 0
    t_norm >= 0
  ) %>% # only pass data after 0
  group_by(administration_id, trial_id, trial_order) %>%
  reframe(
    lengths = rle(aoi)$lengths,
    values = rle(aoi)$values
  )

d_rt <- rle_data %>%
  group_by(administration_id, trial_id, trial_order) %>%
  nest() %>%
  mutate(data = lapply(data, get_rt)) %>%
  unnest(cols = c(data)) %>%
  left_join(d_trial %>%
    select(-t_norm, -correct, -aoi) %>%
    distinct())

saveRDS(file = here("cached_intermediates", "4_d_rt.Rds"), d_rt)
```
# Measure 3: Reaction time
```{r}
d_rt <- readRDS(file = here("cached_intermediates", "4_d_rt.Rds"))
```

IV analysis options:
* what time point to use for RT -- the first time you leave, the last time you leave before landing, when you land
* raw vs log 
* filter by max shift length
* filter min start time
* do we exclude based on pre-min loss (between t_0 and min start time)

outcome measures:
* reliability = ICC
* data loss = how many datapoints are kept

## How much data shows differences?

### time point to use for RT + max shift length
```{r}
ggplot(d_rt, aes(x = shift_start_rt, y = rt)) +
  geom_point(alpha = .5, aes(col = age)) +
  geom_smooth(method = "lm") +
  viridis::scale_color_viridis()

ggplot(
  d_rt,
  aes(x = shift_start_rt, y = rt)
) +
  geom_point(alpha = .5, aes(col = age)) +
  geom_point(
    data = filter(d_rt, shift_length > 600),
    col = "red"
  ) +
  geom_smooth(method = "lm") +
  viridis::scale_color_viridis()
```

this is filtering at 600ms based on first leaving distractor

```{r}
# does type of start initiation matter

d_rt |>
  ungroup() |>
  filter(!is.na(shift_start_rt)) |>
  mutate(
    initiation_type_matters = shift_start_rt != last_shift_rt,
    long_shift_occurs = shift_length > 600
  ) |>
  group_by(initiation_type_matters, long_shift_occurs) |>
  tally() |>
  ungroup() |>
  mutate(pct = n / sum(n))
```
for the most part, these combos won't matter because >90% of the data has the kid only leaving once and doesn't have a long shift. 

distribution of shift lengths -- cut off at 1000ms; by far most shifts are <250ms

```{r}
d_rt |> ggplot(aes(x = shift_length)) +
  geom_histogram(binwidth = 50) +
  coord_cartesian(xlim = c(0, 1000))
d_rt |> ggplot(aes(x = last_shift_length)) +
  geom_histogram(binwidth = 50) +
  coord_cartesian(xlim = c(0, 1000))
```
### how important is consistency in 0-400ms window
how much of the time are kids looking at the same thing between 0 and 400 ms -- many studies require looks to distractor + no shifts for 250/300/367 ms; how much data loss is coming from this?

```{r}
t_0 <- d_trial |>
  filter(t_norm == 0) |>
  mutate(t_0_aoi = aoi) |>
  select(administration_id, trial_id, dataset_name, t_0_aoi) |>
  mutate(t_0_aoi = ifelse(t_0_aoi %in% c("target", "distractor"), t_0_aoi, "other"))
t_375 <- d_trial |>
  filter(t_norm == 375) |>
  mutate(t_375_aoi = aoi) |>
  select(administration_id, trial_id, dataset_name, t_375_aoi) |>
  mutate(t_375_aoi = ifelse(t_375_aoi %in% c("target", "distractor"), t_375_aoi, "other"))
early_dist <- d_trial |>
  filter(t_norm < 400 & t_norm >= 0) |>
  group_by(administration_id, trial_id, dataset_name, aoi) |>
  tally() |>
  left_join(t_0) |>
  left_join(t_375) |>
  pivot_wider(names_from = aoi, values_from = n, values_fill = 0) |>
  mutate(type = case_when(
    target + distractor + missing + other != 16 ~ "some missing ts",
    target == 16 ~ "only target",
    distractor == 16 ~ "only distractor",
    missing + other == 16 ~ "all off",
    target == 0 & distractor > 8 ~ "d+m (mostly d)",
    target == 0 ~ "d+m (mostly m)",
    distractor == 0 & target > 8 ~ "t+m (mostly t)",
    distractor == 0 ~ "t+m (mostly m)",
    T ~ "both"
  ))

ggplot(early_dist, aes(x = t_0_aoi, fill = type)) +
  facet_wrap(~t_375_aoi) +
  geom_bar()

early_dist |>
  group_by(type, t_0_aoi, t_375_aoi) |>
  tally() |>
  ungroup() |>
  mutate(pct = round(n / sum(n), 3)) |>
  arrange(desc(pct))
```
we want to know of the ones that are on t/d/m at start

~31% is on distractor for 0-375
~29% is on target for 0-375

~14% is missing/other for 0-375(this is going to get tossed in all cases!)

~5.5% goes from d to t
~5.5% goes from t to d 

~5.5% is mostly on d during the time, with some being on other (at start/end/middle)
~5% is mostly on t during the time, with some being on other (at start/end/middle)

to look at:
* when we have d/other or t/other what's the typical patterns
  * how much is other & when
* for both t/d this probably can't be salvaged but look at patterns

```{r}
early_dist |>
  filter(target == 0) |>
  filter(missing + other < 16) |>
  filter(distractor != 16) |>
  ggplot(aes(x = distractor)) +
  geom_bar()

early_dist |>
  filter(distractor == 0) |>
  filter(missing + other < 16) |>
  filter(target != 16) |>
  ggplot(aes(x = target)) +
  geom_bar()
```
so, most of the d/m or t/m mixes is heavily weighted to d or t with only a little m.
when does this m occur?
```{r}
d_trial |>
  filter(t_norm < 400 & t_norm >= 0) |>
  inner_join(early_dist |> filter(target == 0) |> filter(missing + other < 16) |> filter(distractor != 16) |> select(administration_id, dataset_name, trial_id, num_distractor = distractor)) |>
  mutate(is_distractor = ifelse(aoi == "distractor", 1, 0)) |>
  group_by(t_norm, num_distractor) |>
  summarize(is_distractor = mean(is_distractor)) |>
  ggplot(aes(x = t_norm, y = is_distractor, col = num_distractor, group = num_distractor)) +
  geom_point() +
  geom_line() +
  scale_color_viridis()
```
so, most of the d/m that is mostly d has the m at the beginning or end (rather than in the middle) -- possibly this is just because of how fixations work? 
this is especially true when d is >11 or so, which is most of this chunk of data. 

```{r}
d_trial |>
  filter(t_norm < 400 & t_norm >= 0) |>
  inner_join(early_dist |> filter(distractor == 0) |> filter(missing + other < 16) |> filter(target != 16) |> select(administration_id, dataset_name, trial_id, num_target = target)) |>
  mutate(is_target = ifelse(aoi == "target", 1, 0)) |>
  group_by(t_norm, num_target) |>
  summarize(is_target = mean(is_target)) |>
  ggplot(aes(x = t_norm, y = is_target, col = num_target, group = num_target)) +
  geom_point() +
  geom_line() +
  scale_color_viridis()
```
what about when there is both t and d?

I think all we're seeing here is autocorrelation, and also not sure how to deal with 3 way data. 

```{r}
d_trial |>
  filter(t_norm < 400 & t_norm >= 0) |>
  inner_join(early_dist |> filter(distractor > 0) |> filter(missing + other < 16) |> filter(target > 0) |> select(administration_id, dataset_name, trial_id, num_target = target, num_distractor = distractor)) |>
  mutate(distractor_target = case_when(
    aoi == "target" ~ 1,
    aoi == "distractor" ~ 0,
    T ~ NA
  )) |>
  group_by(t_norm, num_target) |>
  summarize(distractor_target = mean(distractor_target, na.rm = T)) |>
  ggplot(aes(x = t_norm, y = distractor_target, col = num_target, group = num_target)) +
  geom_point() +
  geom_line() +
  scale_color_viridis()

d_trial |>
  filter(t_norm < 400 & t_norm >= 0) |>
  inner_join(early_dist |> filter(distractor > 0) |> filter(missing + other < 16) |> filter(target > 0) |> select(administration_id, dataset_name, trial_id, num_target = target, num_distractor = distractor)) |>
  mutate(distractor_target = case_when(
    aoi == "target" ~ 1,
    aoi == "distractor" ~ 0,
    T ~ NA
  )) |>
  group_by(t_norm, num_distractor) |>
  summarize(distractor_target = mean(distractor_target, na.rm = T)) |>
  ggplot(aes(x = t_norm, y = distractor_target, col = num_distractor, group = num_distractor)) +
  geom_point() +
  geom_line() +
  scale_color_viridis()
```
Take-aways from data-viz:
* most of the data is reasonably behaved 30% T-T, 30% D-D, we're looking at whether we can save another like 5%ish onto either by relaxing early missing data requirements
* for other exclusions around long-shift, again, not much data is being affected (maybe 5% but some of this is also going to overlap more with data that has other issues)

reasonable options for where looking when:
* at t=0 at D (nothing else)
* during window (of variable window length), only looking at D (window {100, 200, 300, 400})
* during window (of variable window length), not looking at T (window {100, 200, 300, 400})
* during window (of variable window length), not looking at T and looking at D 3/4+ of the time (window {100, 200, 300, 400})
* at t=0 at D & during window (of variable window length), not looking at T (window {100, 200, 300, 400})
* at t=0 at D & * during window (of variable window length), not looking at T and looking at D 3/4+ of the time (window {100, 200, 300, 400})

so maybe the combinatorics are:

always: during window no looking at T
* looking at D at t=0 (yes/no)
* window length {100, 200, 300, 400}
* looking at D at t=end of window (yes,no)
* looking at D 3/4+ of the time during the window

so we'd want to add functions for 
* window length 0, 100, 200, 300, 400 (where 0=no_window)
* time_0 (binary)
* time_end (binary)
* during (binary) does the 3/4s thing

The obvious place to do this is inside the RLE, but that means working with RLE time-series, which is harder. 
it's built it that t=0 has to be D, that's the part we'd need to re-write

## Attempt 1 at combinatorics
This only analyses D-T shifts
looking at
* the 3 options for RT = the first time you leave, the last time you leave before landing, when you land
* raw v log RT
* the option to trim for max shift length of 600ms either calculated from first leaving or final leaving

all of this is within a requirement of RT data at time 0 (to appropriate thing) but no minimums for shift-start

```{r}
d_rt_dt <- d_rt |>
  filter(shift_type == "D-T") |>
  mutate(
    land_rt = rt,
    first_launch_rt = shift_start_rt,
    last_launch_rt = last_shift_rt
  ) |>
  mutate(
    across(c("land_rt", "first_launch_rt", "last_launch_rt"), log, .names = "log{.col}"),
    across(
      c(
        "land_rt", "first_launch_rt", "last_launch_rt",
        "log_land_rt", "log_first_launch_rt", "log_last_launch_rt"
      ),
      ~ ifelse(shift_length <= 600, .x, NA),
      .names = "trim_first_{.col}"
    ),
    across(
      c(
        "land_rt", "first_launch_rt", "last_launch_rt",
        "log_land_rt", "log_first_launch_rt", "log_last_launch_rt"
      ),
      ~ ifelse(last_shift_length <= 600, .x, NA),
      .names = "trim_last_{.col}"
    )
  ) |>
  select(-rt, -shift_start_rt, -last_shift_rt)

rt_iccs <- d_rt_dt |>
  group_by(dataset_name) |>
  nest() |>
  mutate(icc_admin = map(data, \(d) {
    rt_names <- colnames(d)[str_ends(colnames(d), "rt")]
    n_total <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        nrow()
    })
    n_admin <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        select(administration_id) |>
        unique() |>
        nrow()
    })
    max_kid <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        group_by(administration_id) |>
        tally() |>
        summarize(m = max(n)) |>
        pluck(1, 1)
    })
    min_kid <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        group_by(administration_id) |>
        tally() |>
        summarize(m = min(n)) |>
        pluck(1, 1)
    })
    icc_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])), column = rt_col, object = "administration")
    })
    icc_2_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])) |> group_by(administration_id) |> mutate(trials = n()) |> filter(trials > 1), column = rt_col, object = "administration")
    })
    tibble(measure = rt_names, icc = icc_values, icc_2 = icc_2_values, n_total = n_total, n_admin = n_admin, min_kid = min_kid, max_kid = max_kid)
  })) |>
  select(-data) |>
  unnest(icc_admin)
```

note, still have 0 values, even if we require multiple trials per kid. 
double check on consistency v agreement on ICC. 

```{r}
rt_iccs$dataset_name <- fct_reorder(rt_iccs$dataset_name, rt_iccs$icc)

rt_iccs_coded <- rt_iccs |> mutate(
  type = case_when(
    str_detect(measure, "first_launch_rt") ~ "first_launch",
    str_detect(measure, "last_launch_rt") ~ "last_launch",
    str_detect(measure, "land_rt") ~ "land"
  ),
  logged = case_when(
    str_detect(measure, "log") ~ "log",
    T ~ "raw"
  ),
  trimming = case_when(
    str_detect(measure, "trim_first") ~ "trim_first",
    str_detect(measure, "trim_last") ~ "trim_last",
    T ~ "untrimmed"
  )
)

rt_iccs_coded |>
  group_by(type, logged, trimming) |>
  summarize(mean_icc = mean(icc), datapoints = sum(n_total)) |>
  View()

rt_iccs_coded |> View()
```

raw rt leads to better ICC than log rt

untrimmed landing is pretty good!

but, major issues is that we are seeing 0s! (and 1 x 1) which doesn't make sense?

graphing this is hard!

```{r}
ggplot(
  rt_iccs_coded,
  aes(x = dataset_name, y = icc, col = type)
) +
  geom_point(position = position_dodge(width = .5)) +
  geom_line(aes(group = measure)) +
  coord_flip() +
  facet_grid(logged ~ trimming)
```


## Attempt 2 at combinatorics

so we'd want to add functions for 
* window length 0, 100, 200, 300, 400 (where 0=no_window)
* time_0 (binary)
* time_end (binary)
* during (binary) does the 3/4s thing

This only analyses D-T shifts
looking at
* the 3 options for RT = the first time you leave, the last time you leave before landing, when you land
* raw v log RT
* the option to trim for max shift length of 600ms either calculated from first leaving or final leaving

all of this is within a requirement of RT data at time 0 (to appropriate thing) but no minimums for shift-start

start with just 0, 200, 400 if we see anything then can do a finer grained search!

```{r}
rle_data <- d_trial %>%
  filter(
    any(t_norm == 0), # must have data at 0
    t_norm >= 0
  ) %>% # only pass data after 0
  group_by(administration_id, trial_id, trial_order) %>%
  reframe(
    lengths = rle(aoi)$lengths,
    values = rle(aoi)$values
  )

tic()
d_rt_2 <- rle_data %>%
  group_by(administration_id, trial_id, trial_order) %>%
  nest() |>
  expand_grid(window = c(0, 200, 400), time_0 = c(T, F), time_end = c(F, T), during = c(F, T), frac = c(.75)) %>%
  mutate(rts = pmap(
    list(data, time_0, window, time_end, during, frac),
    \(d, t0, w, te, dur, fr) get_rt(d,
      t_0 = t0, window_length = w,
      t_end = te, window_mostly_region = dur, mostly_fraction = fr
    )
  )) |>
  unnest(cols = c(rts))

toc()

saveRDS(file = here("cached_intermediates", "4_d_rt_2.Rds"), d_rt_2)
```


```{r}
readRDS(here("cached_intermediates", "4_d_rt_2.Rds"))
d_rt_dt_2 <- d_rt_2 |>
  filter(shift_type == "D-T") |>
  mutate(
    land_rt = rt,
    first_launch_rt = shift_start_rt,
    last_launch_rt = last_shift_rt
  ) |>
  mutate(
    across(c("land_rt", "first_launch_rt", "last_launch_rt"), log, .names = "log_{.col}"),
    across(
      c(
        "land_rt", "first_launch_rt", "last_launch_rt",
        "log_land_rt", "log_first_launch_rt", "log_last_launch_rt"
      ),
      ~ ifelse(shift_length <= 600, .x, NA),
      .names = "trim_first_{.col}"
    ),
    across(
      c(
        "land_rt", "first_launch_rt", "last_launch_rt",
        "log_land_rt", "log_first_launch_rt", "log_last_launch_rt"
      ),
      ~ ifelse(last_shift_length <= 600, .x, NA),
      .names = "trim_last_{.col}"
    )
  ) |>
  select(-rt, -shift_start_rt, -last_shift_rt) |>
  left_join(d_trial %>%
    select(-t_norm, -correct, -aoi) %>%
    distinct())

tic()
rt_iccs_2 <- d_rt_dt_2 |>
  group_by(dataset_name, window, time_0, time_end, during, frac) |>
  nest() |>
  mutate(icc_admin = map(data, \(d) {
    rt_names <- colnames(d)[str_ends(colnames(d), "rt")]
    n_total <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        nrow()
    })
    n_admin <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        select(administration_id) |>
        unique() |>
        nrow()
    })
    max_kid <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        group_by(administration_id) |>
        tally() |>
        summarize(m = max(n)) |>
        pluck(1, 1)
    })
    min_kid <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        group_by(administration_id) |>
        tally() |>
        summarize(m = min(n)) |>
        pluck(1, 1)
    })
    icc_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])), column = rt_col, object = "administration")
    })
    icc_2_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])) |> group_by(administration_id) |> mutate(trials = n()) |> filter(trials > 1), column = rt_col, object = "administration")
    })
    tibble(measure = rt_names, icc = icc_values, icc_2 = icc_2_values, n_total = n_total, n_admin = n_admin, min_kid = min_kid, max_kid = max_kid)
  })) |>
  select(-data) |>
  unnest(icc_admin)
toc()
saveRDS(file = here("cached_intermediates", "4_d_icc_2.Rds"), rt_iccs_2)
```

note, still have 0 values, even if we require multiple trials per kid. 
double check on consistency v agreement on ICC. 

```{r}
rt_iccs_2 <- readRDS(file = here("cached_intermediates", "4_d_icc_2.Rds"))

rt_iccs_2$dataset_name <- fct_reorder(rt_iccs_2$dataset_name, rt_iccs_2$icc)

rt_iccs_coded_2 <- rt_iccs_2 |> mutate(
  type = case_when(
    str_detect(measure, "first_launch_rt") ~ "first_launch",
    str_detect(measure, "last_launch_rt") ~ "last_launch",
    str_detect(measure, "land_rt") ~ "land"
  ),
  logged = case_when(
    str_detect(measure, "log") ~ "log",
    T ~ "raw"
  ),
  trimming = case_when(
    str_detect(measure, "trim_first") ~ "trim_first",
    str_detect(measure, "trim_last") ~ "trim_last",
    T ~ "untrimmed"
  )
)


rt_iccs_coded_2 |> View()
```

note, there's still a large number of 0s and 1s that seem a little suspicious
may want to investigate that
also may want to confirm that the icc we have in the right one

### results

here we collapse across datasets and just look at mean performance. 

looking at best icc's
```{r}
rt_iccs_2_summ <- rt_iccs_coded_2 |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(mean_icc = mean(icc), datapoints = sum(n_total))

rt_iccs_2_summ |>
  arrange(desc(mean_icc)) |>
  head(20) |>
  knitr::kable()
```
a few things we see -- land & last_launch each appear; as do both raw and log; as do trim_last and unntrimmed
window is always 400 and time_end is always true,
some variation in time_0 and during

let's make a lot of plots 

```{r}
rt_iccs_2_summ |> ggplot(aes(x = str_c(logged, "_", type), y = mean_icc, group = interaction(type, logged, trimming))) +
  geom_point(aes(col = trimming), position = position_dodge(width = .4)) +
  stat_summary(position = position_dodge(width = .4)) +
  coord_flip() +
  geom_hline(yintercept = .6) +
  scale_color_brewer(type = "qual", palette = 1)
```
here, raw generally looks better than log (although note is mostly due to low outliers for log). First launch doesn't look great. 


```{r}
rt_iccs_2_summ |>
  ggplot(aes(x = str_c("during", during, "_", "window_end", time_end), y = mean_icc, group = interaction(time_0, time_end, window))) +
  geom_point(aes(col = as.character(window)), position = position_dodge(width = .4)) +
  stat_summary(position = position_dodge(width = .4)) +
  coord_flip() +
  facet_wrap(~ str_c("time_0", time_0)) +
  geom_hline(yintercept = .6) +
  scale_color_brewer(type = "qual", palette = 2)
```

here's the other slides on the data -- of the options we considered for excluding trials based on behavior early in the trial (i.e. not being on the distractor enough), the longer window is best, and it looks like 
* either being on distractor 3/4+ of the time or being on the distractor at the window end is important; with end is slightly better
* given that, being on the distractor at t=0 doesn't matter 

So, combining across these two plots and what the absolute top 20 iccs are, I think we see:
* either land or last_launch is the best option
* we're not sure about trimming, but (especially for coherence with above) either no trim or trim for long delays between last_launch and land
* the 400 window did best, but people often use windows between 200 and 400, so we can explore that region more
* it's important to be on distractor at the end of the window

we also didn't consider a commonly used criteria which is to be on d for the *entirety* of the window.

## Attempt 3 at combinatorics

so for attempt 3, we expand the grid on windows between 200 and 400 and add a new dimension -- the fraction required during that window, ranging across {0, .5, .75, 1}, whereas attempt 2 only checked 0 and .75.




```{r}
rle_data <- d_trial %>%
  filter(
    any(t_norm == 0), # must have data at 0
    t_norm >= 0
  ) %>% # only pass data after 0
  group_by(administration_id, trial_id, trial_order) %>%
  reframe(
    lengths = rle(aoi)$lengths,
    values = rle(aoi)$values
  )

tic()
d_rt_3 <- rle_data %>%
  group_by(administration_id, trial_id, trial_order) %>%
  nest() |>
  expand_grid(window = c(200, 250, 300, 350, 400), time_0 = c(T, F), time_end = c(T), during = c(T), frac = c(0, .5, .75, 1)) %>%
  mutate(rts = pmap(
    list(data, time_0, window, time_end, during, frac),
    \(d, t0, w, te, dur, fr) get_rt(d,
      t_0 = t0, window_length = w,
      t_end = te, window_mostly_region = dur, mostly_fraction = fr
    )
  )) |>
  unnest(cols = c(rts))

toc()

saveRDS(file = here("cached_intermediates", "4_d_rt_3.Rds"), d_rt_3)
```


now do icc for this
```{r}
d_rt_3 <- readRDS(here("cached_intermediates", "4_d_rt_3.Rds"))
d_rt_dt_3 <- d_rt_3 |>
  filter(shift_type == "D-T") |>
  mutate(
    land_rt = rt,
    last_launch_rt = last_shift_rt
  ) |>
  mutate(
    across(c("land_rt", "last_launch_rt"), log, .names = "log_{.col}"),
    across(
      c(
        "land_rt", "last_launch_rt",
        "log_land_rt", "log_last_launch_rt"
      ),
      ~ ifelse(last_shift_length <= 600, .x, NA),
      .names = "trim_last_{.col}"
    )
  ) |>
  select(-rt, -shift_start_rt, -last_shift_rt) |>
  left_join(d_trial %>%
    select(-t_norm, -correct, -aoi) %>%
    distinct())

tic()
rt_iccs_3 <- d_rt_dt_3 |>
  group_by(dataset_name, window, time_0, time_end, during, frac) |>
  nest() |>
  mutate(icc_admin = map(data, \(d) {
    rt_names <- colnames(d)[str_ends(colnames(d), "rt")]
    n_total <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        nrow()
    })
    n_admin <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        select(administration_id) |>
        unique() |>
        nrow()
    })
    max_kid <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        group_by(administration_id) |>
        tally() |>
        summarize(m = max(n)) |>
        pluck(1, 1)
    })
    min_kid <- map_dbl(rt_names, \(rt_col) {
      d |>
        filter(!is.na(d[rt_col])) |>
        group_by(administration_id) |>
        tally() |>
        summarize(m = min(n)) |>
        pluck(1, 1)
    })
    icc_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])), column = rt_col, object = "administration")
    })
    icc_2_values <- map_dbl(rt_names, \(rt_col) {
      get_icc(d |> filter(!is.na(d[rt_col])) |> group_by(administration_id) |> mutate(trials = n()) |> filter(trials > 1), column = rt_col, object = "administration")
    })
    tibble(measure = rt_names, icc = icc_values, icc_2 = icc_2_values, n_total = n_total, n_admin = n_admin, min_kid = min_kid, max_kid = max_kid)
  })) |>
  select(-data) |>
  unnest(icc_admin)
toc()

saveRDS(file = here("cached_intermediates", "4_d_rt_icc_3.Rds"), rt_iccs_3)
```

note, still have 0 values, even if we require multiple trials per kid. 
double check on consistency v agreement on ICC. 

```{r}
rt_iccs_3 <- readRDS(here("cached_intermediates", "4_d_rt_icc_3.Rds"))

rt_iccs_3$dataset_name <- fct_reorder(rt_iccs_3$dataset_name, rt_iccs_3$icc)

rt_iccs_coded_3 <- rt_iccs_3 |> mutate(
  type = case_when(
    str_detect(measure, "first_launch_rt") ~ "first_launch",
    str_detect(measure, "last_launch_rt") ~ "last_launch",
    str_detect(measure, "land_rt") ~ "land"
  ),
  logged = case_when(
    str_detect(measure, "log") ~ "log",
    T ~ "raw"
  ),
  trimming = case_when(
    str_detect(measure, "trim_first") ~ "trim_first",
    str_detect(measure, "trim_last") ~ "trim_last",
    T ~ "untrimmed"
  )
)


rt_iccs_coded_3 |> View()
```

### results

here we collapse across datasets and just look at mean performance. 

looking at best icc's
```{r}
rt_iccs_3_summ <- rt_iccs_coded_3 |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(mean_icc = mean(icc), datapoints = sum(n_total))

rt_iccs_3_summ |>
  arrange(desc(mean_icc)) |>
  head(20) |>
  knitr::kable()
```
huh, it's again only 400 -- so possibly this is an issue where the signal we're getting through ICC is either artifactual or it's getting non-relevant consistency? idk. 

some variation in time_0 and variation in required during percentage

let's make a lot of plots 

```{r}
rt_iccs_3_summ |> ggplot(aes(x = str_c(logged, "_", type), y = mean_icc, group = interaction(type, logged, trimming))) +
  geom_point(aes(col = trimming), position = position_dodge(width = .4)) +
  stat_summary(position = position_dodge(width = .4)) +
  coord_flip() +
  geom_hline(yintercept = .6) +
  scale_color_brewer(type = "qual", palette = 1)
```
so, landing looks best at the top, best are untrimmed. 

```{r}
rt_iccs_3_summ |>
  ggplot(aes(x = str_c("frac", frac), y = mean_icc, group = interaction(time_0, frac, window))) +
  geom_point(aes(col = as.character(window)), position = position_dodge(width = .6)) +
  stat_summary(position = position_dodge(width = .6)) +
  coord_flip() +
  facet_wrap(~ str_c("time_0", time_0)) +
  geom_hline(yintercept = .6) +
  scale_color_brewer(type = "qual", palette = 2)
```
hmm, I'm surprised that 400 has such as advantage. that's kind of concerning. 

is it that the 400 standard just drops a lot of data? 

```{r}
rt_iccs_3_summ |>
  ggplot(aes(x = str_c("frac", frac), y = datapoints, group = interaction(time_0, frac, window))) +
  geom_point(aes(col = as.character(window)), position = position_dodge(width = .6)) +
  coord_flip() +
  facet_wrap(~ str_c("time_0", time_0)) +
  scale_color_brewer(type = "qual", palette = 2)

rt_iccs_3_summ |> ggplot(aes(x = mean_icc, y = datapoints)) +
  geom_point(aes(col = as.character(window)), position = position_dodge(width = .6)) +
  coord_flip() +
  facet_wrap(~ str_c("time_0", time_0)) +
  scale_color_brewer(type = "qual", palette = 2)
```
not hugely! 

so, what's the takeaway here?
kind of want to check for cross-data-set reliability

## by dataset reliability

```{r}
ranks <- rt_iccs_coded_2 |>
  bind_rows(rt_iccs_coded_3) |>
  unique() |>
  group_by(dataset_name) |>
  mutate(max_icc = max(icc)) |>
  arrange(desc(icc)) |>
  mutate(rank = row_number(), norm_icc = icc / max_icc) |>
  ungroup() |>
  group_by(type, logged, trimming, window, time_0, time_end, during, frac) |>
  summarize(min_normed_icc = min(norm_icc), mean_normed_icc = mean(norm_icc))

ranks |>
  arrange(desc(mean_normed_icc)) |>
  head(20) |>
  knitr::kable()
```


land, log, 400 window, time_end true, and variable beyond that

the top (rank) is land - log - untrimmed - 400 - time_0 - time_end, no during
the top (% of best ICC) is land - log - untrimmed - 400 - time_end, 75% during

another way to check this is to look at what measures are *always* pretty near the top by saying that their value is at least X% of the best icc for that dataset

```{r}
ranks |>
  filter(min_normed_icc > .7) |>
  knitr::kable()
```
this again suggests that what you really should do is land (either raw or logged); with a 400 window and time_end and don't both about the rest? (and that you actually maybe shouldn't filter at 0 or within?)

should try to do some validity measures on this!


# Old
## Computing RT 
First compute reaction time. 

NOTE 1/31/24 - consider computing RT from LAUNCH not from LANDING - this may make a difference to what we end up finding. 
MZ: 4/29/24 - both launch and landing-based RT computed by rt helper function
* `rt`: landing-time based RT
* `shift_start_rt`: launch-time based RT

We need RLE data, then we use the RT helper from peekbank-shiny. 

Note MCF: 8/25/25 - we cached this function in the current repo to remove dependencies. 



Compute RTs, relying on the RLE workflow from the shiny app. 



How many trials have RTs for them?

Almost every trial makes it through the computation, but what prop do we have RTs for.

```{r}
d_rt <- readRDS(file = here("cached_intermediates", "4_d_rt.Rds"))

# rt_stats <- d_rt %>%
#   ungroup() %>%
#   summarise(
#     nas = mean(is.na(shift_start_rt)),
#     too_fast = mean(shift_start_rt < 300, na.rm = TRUE),
#     d_t = mean(shift_type == "D-T", na.rm = TRUE),
#     t_d = mean(shift_type == "T-D", na.rm = TRUE),
#     other = mean(shift_type == "other", na.rm = TRUE),
#     no_shift = mean(shift_type == "no shift", na.rm = TRUE)
#   )
#
# knitr::kable(rt_stats, digits = 2)
```




## How to measure shift initiation

```{r}
# not sure whether we should count shift initiation as when the child first looks away from D or when they are last looking at D before looking at T

# how often are these distinct?
```
about 5% of the data that has a shift has a difference between these two measures
but only abut 1% of data with a shift has this difference *and* doesn't have a long shift time, so this is probably not of large consequence. 

```{r}
# does it matter which type of shift we use
ggplot(d_rt, aes(x = shift_start_rt, y = last_shift_rt)) +
  geom_point(alpha = .5, aes(col = age)) +
  geom_smooth(method = "lm") +
  viridis::scale_color_viridis()

ggplot(
  d_rt,
  aes(x = shift_start_rt, y = last_shift_rt)
) +
  geom_point(alpha = .5, aes(col = age)) +
  geom_point(
    data = filter(d_rt, shift_length > 600),
    col = "red"
  ) +
  geom_smooth(method = "lm") +
  viridis::scale_color_viridis()
```





## RT distribution & exclusion

Examine RT distribution.

```{r}
ggplot(filter(d_rt), aes(x = shift_start_rt)) +
  geom_histogram()
```

Logs. 

```{r}
ggplot(d_rt, aes(x = shift_start_rt)) +
  geom_histogram() +
  scale_x_log10()
```

Probably should get rid of the RTs < 250ms or so. 

```{r}
mean(d_rt$shift_start_rt < 250, na.rm = TRUE)
```

Filter. 

```{r}
d_rt_all <- filter(
  d_rt,
  !is.na(shift_start_rt)
)
d_rt <- filter(
  d_rt,
  !is.na(shift_start_rt),
  shift_start_rt > 250
)
```

Look by age.

```{r}
ggplot(
  d_rt,
  aes(x = age, y = rt)
) +
  geom_point(alpha = .5) +
  geom_smooth(method = "lm")
```
Add dataset to try to figure out blockiness. 

```{r}
ggplot(
  d_rt,
  aes(x = age, y = rt)
) +
  geom_point(alpha = .1) +
  geom_smooth(method = "lm") +
  facet_wrap(~dataset_name)
```

Histogram by dataset. 

```{r}
ggplot(
  d_rt,
  aes(x = rt)
) +
  geom_histogram(bins = 10) +
  scale_x_log10() +
  facet_wrap(~dataset_name, scales = "free_y")
```



## RT reliabilities




TODO: rank/score them for the different things 
Why are some ICCs zero? Let's look at Pomper Saffran 2016.

```{r}
ps <- d_rt |>
  filter(dataset_name == "pomper_saffran_2016")

ggplot(
  ps,
  aes(x = target_label, y = shift_start_rt)
) +
  geom_jitter(alpha = .5, width = .2) +
  stat_summary(col = "red") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

ggplot(
  ps,
  aes(x = administration_id, y = shift_start_rt)
) +
  geom_jitter(alpha = .5, width = .2) +
  stat_summary(col = "red")
```

Now check ICCs for RTs for ALL trials (not subsetting to D-T trials). They look OK.

```{r}
# disaggregated
get_icc(ps, object = "stimulus", column = "shift_start_rt")
get_icc(ps, object = "administration", column = "shift_start_rt")
```


```{r}
ps_icc <- dim_icc(ps,
  model = "2A",
  type = "agreement",
  unit = "average",
  object = administration_id,
  rater = target_label,
  trial = trial_id,
  score = shift_start_rt,
  bootstrap = 1000
)

summary(ps_icc)
```

This all looks good and ICCs seem reasonably high - but why do we get fewer zeros when we subset to D-T trials? Let's dig into this. 

Pomper SalientMe shows this pattern. 

```{r}
ps_dt <- ps |>
  filter(shift_type == "D-T")

get_icc(ps, object = "stimulus", column = "shift_start_rt")
get_icc(ps_dt, object = "stimulus", column = "shift_start_rt")
```

Stimulus ICC goes to zero for D-T trials. Let's look at the cross between subjects and trials for each. 

```{r}
ps |>
  ungroup() |>
  select(subject_id, target_label, shift_start_rt) |>
  arrange(target_label) |>
  pivot_wider(names_from = "target_label", values_from = "shift_start_rt") |>
  arrange(subject_id) |>
  View()

# summarize by stimulus
ps_stimulus_rt_summarized <- ps |>
  ungroup() |>
  group_by(target_label) |>
  summarize(
    N = n(),
    mean_rt = mean(shift_start_rt, na.rm = TRUE)
  )

ps_stimulus_rt_summarized <- ps |>
  ungroup() |>
  group_by(target_label) |>
  summarize(
    N = n(),
    mean_rt = mean(shift_start_rt, na.rm = TRUE)
  )

ps_admin_rt_summarized <- ps |>
  ungroup() |>
  group_by(administration_id) |>
  summarize(
    N = n(),
    mean_rt = mean(shift_start_rt, na.rm = TRUE)
  )


ps_dt |>
  ungroup() |>
  select(subject_id, target_label, shift_start_rt) |>
  arrange(target_label) |>
  pivot_wider(names_from = "target_label", values_from = "shift_start_rt") |>
  arrange(subject_id) |>
  View()

# summarize by stimulus
ps_dt_stimulus_rt_summarized <- ps_dt |>
  ungroup() |>
  group_by(administration_id, target_label) |>
  summarize(
    N = n(),
    mean_rt = mean(shift_start_rt, na.rm = TRUE),
    unique_participants = length(unique(administration_id))
  )

ps_dt_admin_rt_summarized <- ps_dt |>
  ungroup() |>
  group_by(administration_id) |>
  summarize(
    N = n(),
    mean_rt = mean(shift_start_rt, na.rm = TRUE)
  )
```

So the D-T dataframe is sparser, but looks more consistent. Let's check out the distributions. 

Let's check if removing rare items fixes the ICC issue

```{r}
rare_items <- ps_dt_stimulus_rt_summarized |>
  filter(N < 8) %>%
  pull(target_label)
rare_participants <- ps_dt_admin_rt_summarized |>
  filter(N < 5) %>%
  pull(administration_id)

get_icc(filter(ps_dt, !(target_label %in% rare_items)), object = "stimulus", column = "shift_start_rt")
get_icc(filter(ps_dt, !(administration_id %in% rare_participants)), object = "stimulus", column = "shift_start_rt")
```

filtering out rare participants or stimuli doesn't seem to matter.


```{r}
ggplot(ps, aes(x = rt)) +
  geom_histogram() +
  facet_wrap(~shift_type)
```
This is consistent with the idea that T-D shifts are more random/ uninformative. Let's look at all data. 

```{r}
ggplot(d_rt, aes(x = rt)) +
  geom_histogram() +
  facet_wrap(~shift_type)
```
Looks well-supported that T-D RTs are different. I now feel comfortable moving forward with D-T only. 
Let's compare ICC from RTs to ICCs from accuracy. 

```{r}
d_summary <- d_trial |>
  group_by(
    dataset_name, trial_id, dataset_id, subject_id, administration_id,
    target_label
  ) |>
  summarise(
    accuracy = mean(correct[t_norm > 500], na.rm = TRUE),
    prop_data = mean(!is.na(correct[t_norm > 500]))
  ) |>
  filter(!is.na(accuracy))

trial_ns_acc <- bind_rows(
  d_summary |>
    group_by(dataset_name, subject_id) |>
    count() |>
    group_by(dataset_name) |>
    summarise(
      n = mean(n),
      dimension = "admin"
    ),
  d_summary |>
    group_by(dataset_name, target_label) |>
    count() |>
    group_by(dataset_name) |>
    summarise(
      n = mean(n),
      dimension = "stimulus"
    )
)

trial_ns_rt <- bind_rows(
  d_rt_dt |>
    group_by(dataset_name, subject_id) |>
    count() |>
    group_by(dataset_name) |>
    summarise(
      n = mean(n),
      dimension = "admin"
    ),
  bind_rows(d_rt_dt |>
    group_by(dataset_name, subject_id) |>
    count() |>
    group_by(dataset_name) |>
    summarise(
      n = mean(n),
      dimension = "stimulus"
    ))
)
# load ICCs for accuracy
load(file = here("cached_intermediates", "2_iccs_accuracy.Rds"))

iccs_long <- iccs |>
  pivot_longer(
    names_to = "dimension", values_to = "icc",
    icc_stimulus_acc:icc_admin_acc
  ) |>
  ungroup() |>
  separate(dimension, into = c("type", "dimension", "measure")) |>
  mutate(dataset_name = fct_reorder(dataset_name, icc))


acc_rt_iccs <- bind_rows(
  filter(iccs_long, measure == "acc") |>
    left_join(trial_ns_acc),
  rt_iccs_long |>
    left_join(trial_ns_rt)
) |>
  mutate(dataset_name = fct_reorder(as.factor(dataset_name), icc)) |>
  select(-type)


ggplot(
  acc_rt_iccs,
  aes(x = dataset_name, y = icc, col = measure)
) +
  geom_point(aes(size = n),
    position = position_dodge(width = .5)
  ) +
  geom_line(aes(group = measure)) +
  facet_wrap(~dimension) +
  theme(axis.text.x = element_text(angle = -90))

acc_rt_iccs |>
  arrange(dataset_name) |>
  mutate(
    icc = round(icc, digits = 2),
    n = round(n)
  )
```

Let's plot by N. 

```{r}
ggplot(
  acc_rt_iccs,
  aes(x = n, y = icc, col = dataset_name)
) +
  geom_point() +
  geom_smooth(aes(group = 1), method = "loess", span = 10, se = FALSE) +
  # scale_x_log10() +
  facet_wrap(dimension ~ measure, scales = "free_x") +
  xlab("N trials per child/word") +
  ylab("Intraclass Correlation Coefficient") +
  ylim(0, 1)
```
This is interesting! We are getting a bunch of signal about individual participants from RT, actually higher ICC than accuracies. Not so much for stimulus information, where it seems like we are doing better from accuracy. Also, as predicted the number of trials per child or per word appears to relate across datasets to the ICC (though there's lots of variance at the bottom end that presumably relates to the variation in ability across kids/variation in difficulty across words). If you choose very different words you get high reliability on that dimension (see "reliability paradoxes" idea).

## Compare ICCs for RT and Accuracy

```{r}
# combine
all_iccs <- iccs %>%
  left_join(rt_iccs)

# plot - Participants
ggplot(all_iccs, aes(admin_rt, icc_admin_acc)) +
  geom_point(size = 1.5) +
  geom_text(aes(label = dataset_name)) +
  geom_abline(intercept = 0, slope = 1) +
  xlim(0, 1) +
  ylim(0, 1)
```

plot - Items

```{r}
ggplot(all_iccs, aes(stimulus_rt, icc_stimulus_acc)) +
  geom_point(size = 1.5) +
  geom_text(aes(label = dataset_name)) +
  geom_abline(intercept = 0, slope = 1) +
  xlim(0, 1) +
  ylim(0, 1)
```

## Look at RTs as a function of filtering

```{r}
save(d_rt_dt, file = here("cached_intermediates", "4_d_rt_dt.Rds"))
```
