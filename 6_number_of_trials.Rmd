---
title: "Number of trials"
author: "Mike Frank"
date: "2022-12-15"
output: html_document
---

```{r}
source(here::here("helper/common.R"))


d_aoi <- readRDS(here("cached_intermediates", "1_d_aoi.Rds"))
```

Goal is to find out how reliability (test-retest) varies with number of trials, within datasets. 

what dataset have repeated administrations?
```{r}
admins <- d_aoi |>
  select(dataset_name, subject_id, administration_id, age) |>
  distinct()
repeated <- admins |>
  group_by(dataset_name, subject_id) |>
  tally() |>
  filter(n > 1)

repeated_subjects <- admins |> inner_join(repeated)
```

adams_marchman has 2 admins for each age and up to 5 ages 
fernald totlot has 1 admin at each of 4 ages
fmw sometimes has 2 admins at 1 age and 2 ages
weaver_zettersten has 2 admins at 1 age 
potter_remix has 2 admins at 1 age 

so, we can say a pair is "close enough" if the ages are within 1 month of each other and then we'll have a bunch of test-retest pairs. 

* for those pairs, for each admin, we want # of trials (administered), trial accuracy, trial RT, # trials with RT
and then we want the correlation between admin-1 and admin-2 ?

I don't know how much there's item overlap (probably is), so might be able to do something finer grained? 

```{r}
# identify pairs
# hmm, sometimes we have times with 3+ 1 month apart,
# for now allow all the pairs that result so like 14-15 and 15-16 for the same kid

pairs <- repeated_subjects |>
  group_by(dataset_name, subject_id) |>
  mutate(
    forward_age = lead(age),
    forward_diff = forward_age - age,
    test_num = case_when(
      forward_diff < 1.5 ~ 1,
    ),
    mean_age = case_when(
      test_num == 1 ~ (age + forward_age) / 2,
    ),
    second_admin = case_when(
      test_num == 1 ~ lead(administration_id)
    )
  ) |>
  filter(!is.na(test_num)) |>
  rename(first_admin = administration_id) |>
  select(-n, -age) |>
  left_join(repeated_subjects |> select(-age, -n), by = c("dataset_name", "subject_id", "second_admin" = "administration_id")) |>
  ungroup() |>
  mutate(pair_number = row_number()) |>
  select(-forward_age, -forward_diff, -test_num)

pairs_long <- pairs |> pivot_longer(c("first_admin", "second_admin"), names_to = "session_num", values_to = "administration_id")
```

# test - retest and number of trials
* for those pairs, for each admin, we want # of trials (administered), trial accuracy, trial RT, # trials with RT

```{r}
acc <- d_aoi |>
  inner_join(pairs_long |> select(dataset_name, administration_id, subject_id) |> distinct()) |>
  filter(t_norm >= 500) |>
  filter(t_norm <= 4000) |>
  group_by(dataset_name, subject_id, administration_id, trial_id, trial_order, target_label) |>
  summarize(acc = mean(correct, na.rm = T)) |>
  filter(!is.na(acc))

acc_mean <- acc |>
  group_by(dataset_name, subject_id, administration_id) |>
  summarize(acc_trials = sum(!is.na(acc)), acc = mean(acc, na.rm = T))

rt <- readRDS(here("cached_intermediates", "4_rt_canonical.rds")) |>
  inner_join(pairs_long |> select(dataset_name, administration_id, subject_id) |> distinct()) |>
  filter(shift_type == "D-T")

rt_mean <- rt |>
  group_by(dataset_name, subject_id, administration_id) |>
  summarize(rt_trials = n(), mean_rt = mean(rt))
```
```{r}
all <- pairs_long |>
  left_join(acc_mean) |>
  left_join(rt_mean)

all_wide <- all |>
  mutate(session_num = ifelse(session_num == "first_admin", 1, 2)) |>
  pivot_wider(values_from = c("administration_id", "acc", "acc_trials", "rt_trials", "mean_rt"), names_from = session_num) |>
  mutate(age_bin = case_when(
    mean_age < 18 ~ "12-17",
    mean_age < 21 ~ "18-20",
    mean_age < 28 ~ "21-27",
    mean_age < 33 ~ "28-32",
    mean_age >= 33 ~ "33+"
  ))
```

## test-retest on summary

let's start with some graphs

```{r}
ggplot(all_wide, aes(x = mean_rt_1, y = mean_rt_2, col = age_bin)) +
  geom_point(alpha = .5) +
  geom_abline() +
  facet_wrap(~dataset_name) +
  scale_color_viridis(discrete = T)

ggplot(all_wide, aes(x = acc_1, y = acc_2, col = age_bin)) +
  geom_point(alpha = .5) +
  geom_abline() +
  facet_wrap(~dataset_name) +
  scale_color_viridis(discrete = T)
```
what ages?

```{r}
ggplot(all_wide, aes(x = mean_age, fill = age_bin)) +
  facet_wrap(~dataset_name, scales = "free_y") +
  geom_histogram()
ggplot(all_wide, aes(x = mean_age, fill = age_bin)) +
  geom_histogram(binwidth = 1)
```
how much data

```{r}
ggplot(all_wide, aes(x = acc_trials_1, y = acc_trials_2, col = age_bin)) +
  geom_point(alpha = .5) +
  geom_abline() +
  facet_wrap(~dataset_name) +
  scale_color_viridis(discrete = T)

ggplot(all_wide, aes(x = rt_trials_1, y = rt_trials_2, col = age_bin)) +
  geom_point(alpha = .5) +
  geom_abline() +
  facet_wrap(~dataset_name) +
  scale_color_viridis(discrete = T)
```

how much more acc than RT data?

```{r}
ggplot(all_wide, aes(x = acc_trials_1, y = rt_trials_1, col = age_bin)) +
  geom_point(alpha = .5) +
  geom_abline(slope = 1) +
  geom_abline(slope = 1 / 3) +
  facet_wrap(~dataset_name) +
  scale_color_viridis(discrete = T)

ggplot(all_wide, aes(x = acc_trials_2, y = rt_trials_2, col = age_bin)) +
  geom_point(alpha = .5) +
  geom_abline(slope = 1) +
  geom_abline(slope = 1 / 3) +
  facet_wrap(~dataset_name) +
  scale_color_viridis(discrete = T)
```
yeah, seems like kids generally have 3x the number of accuracy trials as RT trials (ish)


so a number of kids do have a good number of trials, so we could reasonable do subsampling


```{r}
test_retest <- all_wide |>
  group_by(dataset_name, age_bin) |>
  summarise(
    cor_rt = ifelse(sum(!is.na(mean_rt_1) & !is.na(mean_rt_2)) > 2, cor.test(mean_rt_1, mean_rt_2)$estimate, NA),
    cor_acc = ifelse(sum(!is.na(acc_1) & !is.na(acc_2)) > 2, cor.test(acc_1, acc_2)$estimate, NA),
  )
```

```{r}
ggplot(test_retest, aes(x = dataset_name, y = cor_rt, col = age_bin)) +
  geom_point() +
  coord_flip() +
  scale_color_viridis(discrete = T)
ggplot(test_retest, aes(x = dataset_name, y = cor_acc, col = age_bin)) +
  geom_point() +
  coord_flip() +
  scale_color_viridis(discrete = T)
```
# simulate post-hoc cutoffs
start with the easy thing, what happens if you exclude pairs that don't have enough (valid) trials at each time point in the pair?

for RT
```{r}
cutoffs <- expand_grid(min = c(1, 2, 3, 4, 5, 8, 10, 12, 15))

cutoff_rt <- all_wide |>
  group_by(dataset_name, age_bin) |>
  cross_join(cutoffs) |>
  filter(rt_trials_1 >= min, rt_trials_2 >= min) |>
  group_by(dataset_name, age_bin, min) |>
  summarise(
    cor_rt = ifelse(sum(!is.na(mean_rt_1) & !is.na(mean_rt_2)) > 2, cor.test(mean_rt_1, mean_rt_2)$estimate, NA),
    pairs = n()
  )

ggplot(cutoff_rt, aes(x = min, y = cor_rt, col = age_bin)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)


ggplot(cutoff_rt, aes(x = min, y = cor_rt, col = age_bin)) +
  geom_point(position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)
```
something is weird with the 28-32 bin, 
otherwise, seems like cutting out kids who don't have at least a few RT trials is reasonable (for few in the 2-5 range?)

for accuracy 
```{r}
cutoffs <- expand_grid(min = c(1, 2, 3, 4, 5, 8, 10, 12, 15))

cutoff_acc <- all_wide |>
  group_by(dataset_name, age_bin) |>
  cross_join(cutoffs) |>
  filter(acc_trials_1 >= min, acc_trials_2 >= min) |>
  group_by(dataset_name, age_bin, min) |>
  summarise(
    cor_acc = ifelse(sum(!is.na(acc_1) & !is.na(acc_2)) > 2, cor.test(acc_1, acc_2)$estimate, NA), pairs = n()
  )

ggplot(cutoff_acc, aes(x = min, y = cor_acc, col = age_bin)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)


ggplot(cutoff_acc, aes(x = min, y = cor_acc, col = age_bin)) +
  geom_point(position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)
```

don't see as much for acc trials, but we expect that kids have like 3x the accuray trials as the RT trials, so scale might be off, but we're also not seeing differences up around 15 either

# simulate different trial counts

## RT
let's start with RT
we'll look at all the kids where we *actually* have 5+ datapoints for each time
and then look at how t-rt varies if we only take 1,2,3,4,5 of them 

for now, maybe just use slice (rather than a random sampling), but could reconsider

```{r}
eligible_5 <- all_wide |>
  filter(rt_trials_1 > 4, rt_trials_2 > 4) |>
  select(dataset_name, subject_id, mean_age, pair_number, administration_id_1, administration_id_2) |>
  pivot_longer(c("administration_id_1", "administration_id_2"), names_to = "session_num", values_to = "administration_id") |>
  select(dataset_name, subject_id, administration_id)

rt_subsample_5 <- expand_grid(num_samples = c(1, 2, 3, 4, 5)) |>
  mutate(rts = map(num_samples, \(num) {
    rt |>
      group_by(dataset_name, subject_id, administration_id) |>
      inner_join(eligible_5) |>
      group_by(dataset_name, subject_id, administration_id) |>
      slice(1:num) |>
      summarize(rt_trials = n(), mean_rt = mean(rt))
  })) |>
  unnest(rts)


rt_sub_corr_5 <- pairs_long |>
  left_join(rt_subsample_5) |>
  mutate(session_num = ifelse(session_num == "first_admin", 1, 2)) |>
  filter(!is.na(num_samples)) |>
  pivot_wider(values_from = c("administration_id", "rt_trials", "mean_rt"), names_from = session_num) |>
  mutate(age_bin = case_when(
    mean_age < 18 ~ "12-17",
    mean_age < 21 ~ "18-20",
    mean_age < 28 ~ "21-27",
    mean_age < 33 ~ "28-32",
    mean_age >= 33 ~ "33+"
  )) |>
  filter(!is.na(mean_rt_1)) |>
  filter(!is.na(mean_rt_2)) |>
  group_by(dataset_name, age_bin, num_samples) |>
  summarise(
    cor_rt = ifelse(sum(!is.na(mean_rt_1) & !is.na(mean_rt_2)) > 2, cor.test(mean_rt_1, mean_rt_2)$estimate, NA),
    pairs = n()
  )

ggplot(rt_sub_corr_5 |> filter(pairs > 9), aes(x = num_samples, y = cor_rt, col = age_bin)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)


ggplot(rt_sub_corr_5, aes(x = num_samples, y = cor_rt, col = age_bin)) +
  geom_point(position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)
```
some datasets don't have very many kids left, so capping to dataset-age bins with 10 kids

seems like more helps, but also some datasets are weird? 

```{r}
eligible_10 <- all_wide |>
  filter(rt_trials_1 > 9, rt_trials_2 > 9) |>
  select(dataset_name, subject_id, mean_age, pair_number, administration_id_1, administration_id_2) |>
  pivot_longer(c("administration_id_1", "administration_id_2"), names_to = "session_num", values_to = "administration_id") |>
  select(dataset_name, subject_id, administration_id)

rt_subsample_10 <- expand_grid(num_samples = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)) |>
  mutate(rts = map(num_samples, \(num) {
    rt |>
      group_by(dataset_name, subject_id, administration_id) |>
      inner_join(eligible_10) |>
      group_by(dataset_name, subject_id, administration_id) |>
      slice(1:num) |>
      summarize(rt_trials = n(), mean_rt = mean(rt))
  })) |>
  unnest(rts)


rt_sub_corr_10 <- pairs_long |>
  left_join(rt_subsample_10) |>
  mutate(session_num = ifelse(session_num == "first_admin", 1, 2)) |>
  filter(!is.na(num_samples)) |>
  pivot_wider(values_from = c("administration_id", "rt_trials", "mean_rt"), names_from = session_num) |>
  mutate(age_bin = case_when(
    mean_age < 18 ~ "12-17",
    mean_age < 21 ~ "18-20",
    mean_age < 28 ~ "21-27",
    mean_age < 33 ~ "28-32",
    mean_age >= 33 ~ "33+"
  )) |>
  filter(!is.na(mean_rt_1)) |>
  filter(!is.na(mean_rt_2)) |>
  group_by(dataset_name, age_bin, num_samples) |>
  summarise(
    cor_rt = ifelse(sum(!is.na(mean_rt_1) & !is.na(mean_rt_2)) > 2, cor.test(mean_rt_1, mean_rt_2)$estimate, NA),
    pairs = n()
  )

ggplot(rt_sub_corr_10 |> filter(pairs > 5), aes(x = num_samples, y = cor_rt, col = age_bin)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)


ggplot(rt_sub_corr_10, aes(x = num_samples, y = cor_rt, col = age_bin)) +
  geom_point(position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)
```

more RT samples is better, maybe some diminishing returns about like 5 or 7? 



and the real goal is to simulate anyway!

so, two options for how to approach this -- 1 is to filter kids by a min # of datapoints (ignore kids who don't contribute data) and the other is to subsample kids to the number of datapoints (simulate different experiment lengths)




## acc
let's start with RT
we'll look at all the kids where we *actually* have 5+ datapoints for each time
and then look at how t-rt varies if we only take 1,2,3,4,5 of them 

for now, maybe just use slice (rather than a random sampling), but could reconsider

```{r}
eligible_5 <- all_wide |>
  filter(acc_trials_1 > 4, acc_trials_2 > 4) |>
  select(dataset_name, subject_id, mean_age, pair_number, administration_id_1, administration_id_2) |>
  pivot_longer(c("administration_id_1", "administration_id_2"), names_to = "session_num", values_to = "administration_id") |>
  select(dataset_name, subject_id, administration_id)

acc_subsample_5 <- expand_grid(num_samples = c(1, 2, 3, 4, 5)) |>
  mutate(accs = map(num_samples, \(num) {
    acc |>
      group_by(dataset_name, subject_id, administration_id) |>
      inner_join(eligible_5) |>
      group_by(dataset_name, subject_id, administration_id) |>
      slice(1:num) |>
      summarize(acc_trials = n(), mean_acc = mean(acc))
  })) |>
  unnest(accs)


acc_sub_corr_5 <- pairs_long |>
  left_join(acc_subsample_5) |>
  mutate(session_num = ifelse(session_num == "first_admin", 1, 2)) |>
  filter(!is.na(num_samples)) |>
  pivot_wider(values_from = c("administration_id", "acc_trials", "mean_acc"), names_from = session_num) |>
  mutate(age_bin = case_when(
    mean_age < 18 ~ "12-17",
    mean_age < 21 ~ "18-20",
    mean_age < 28 ~ "21-27",
    mean_age < 33 ~ "28-32",
    mean_age >= 33 ~ "33+"
  )) |>
  filter(!is.na(mean_acc_1)) |>
  filter(!is.na(mean_acc_2)) |>
  group_by(dataset_name, age_bin, num_samples) |>
  summarise(
    cor_acc = ifelse(sum(!is.na(mean_acc_1) & !is.na(mean_acc_2)) > 2, cor.test(mean_acc_1, mean_acc_2)$estimate, NA),
    pairs = n()
  )

ggplot(acc_sub_corr_5 |> filter(pairs > 9), aes(x = num_samples, y = cor_acc, col = age_bin)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)


ggplot(acc_sub_corr_5 |> filter(pairs > 4), aes(x = num_samples, y = cor_acc, col = age_bin)) +
  geom_point(position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)
```
some datasets don't have very many kids left, so capping to dataset-age bins with 10 kids

seems like more helps, but also some datasets are weird? 

```{r}
eligible_10 <- all_wide |>
  filter(acc_trials_1 > 9, acc_trials_2 > 9) |>
  select(dataset_name, subject_id, mean_age, pair_number, administration_id_1, administration_id_2) |>
  pivot_longer(c("administration_id_1", "administration_id_2"), names_to = "session_num", values_to = "administration_id") |>
  select(dataset_name, subject_id, administration_id)

acc_subsample_10 <- expand_grid(num_samples = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)) |>
  mutate(accs = map(num_samples, \(num) {
    acc |>
      group_by(dataset_name, subject_id, administration_id) |>
      inner_join(eligible_10) |>
      group_by(dataset_name, subject_id, administration_id) |>
      slice(1:num) |>
      summarize(acc_trials = n(), mean_acc = mean(acc))
  })) |>
  unnest(accs)


acc_sub_corr_10 <- pairs_long |>
  left_join(acc_subsample_10) |>
  mutate(session_num = ifelse(session_num == "first_admin", 1, 2)) |>
  filter(!is.na(num_samples)) |>
  pivot_wider(values_from = c("administration_id", "acc_trials", "mean_acc"), names_from = session_num) |>
  mutate(age_bin = case_when(
    mean_age < 18 ~ "12-17",
    mean_age < 21 ~ "18-20",
    mean_age < 28 ~ "21-27",
    mean_age < 33 ~ "28-32",
    mean_age >= 33 ~ "33+"
  )) |>
  filter(!is.na(mean_acc_1)) |>
  filter(!is.na(mean_acc_2)) |>
  group_by(dataset_name, age_bin, num_samples) |>
  summarise(
    cor_acc = ifelse(sum(!is.na(mean_acc_1) & !is.na(mean_acc_2)) > 2, cor.test(mean_acc_1, mean_acc_2)$estimate, NA),
    pairs = n()
  )

ggplot(acc_sub_corr_10 |> filter(pairs > 4), aes(x = num_samples, y = cor_acc, col = age_bin)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)


ggplot(acc_sub_corr_10 |> filter(pairs > 4), aes(x = num_samples, y = cor_acc, col = age_bin)) +
  geom_point(position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)
```

accuracy also shows a more is better, with some stabilizing? but we can also check even higher. 

```{r}
eligible_20 <- all_wide |>
  filter(acc_trials_1 > 19, acc_trials_2 > 19) |>
  select(dataset_name, subject_id, mean_age, pair_number, administration_id_1, administration_id_2) |>
  pivot_longer(c("administration_id_1", "administration_id_2"), names_to = "session_num", values_to = "administration_id") |>
  select(dataset_name, subject_id, administration_id)

acc_subsample_20 <- expand_grid(num_samples = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)) |>
  mutate(accs = map(num_samples, \(num) {
    acc |>
      group_by(dataset_name, subject_id, administration_id) |>
      inner_join(eligible_20) |>
      group_by(dataset_name, subject_id, administration_id) |>
      slice(1:num) |>
      summarize(acc_trials = n(), mean_acc = mean(acc))
  })) |>
  unnest(accs)


acc_sub_corr_20 <- pairs_long |>
  left_join(acc_subsample_20) |>
  mutate(session_num = ifelse(session_num == "first_admin", 1, 2)) |>
  filter(!is.na(num_samples)) |>
  pivot_wider(values_from = c("administration_id", "acc_trials", "mean_acc"), names_from = session_num) |>
  mutate(age_bin = case_when(
    mean_age < 18 ~ "12-17",
    mean_age < 21 ~ "18-20",
    mean_age < 28 ~ "21-27",
    mean_age < 33 ~ "28-32",
    mean_age >= 33 ~ "33+"
  )) |>
  filter(!is.na(mean_acc_1)) |>
  filter(!is.na(mean_acc_2)) |>
  group_by(dataset_name, age_bin, num_samples) |>
  summarise(
    cor_acc = ifelse(sum(!is.na(mean_acc_1) & !is.na(mean_acc_2)) > 2, cor.test(mean_acc_1, mean_acc_2)$estimate, NA),
    pairs = n()
  )

ggplot(acc_sub_corr_20 |> filter(pairs > 4), aes(x = num_samples, y = cor_acc, col = age_bin)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)


ggplot(acc_sub_corr_20 |> filter(pairs > 4), aes(x = num_samples, y = cor_acc, col = age_bin)) +
  geom_point(position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)
```
# test - retest on baseline correction

(let's wait and see what the best baseline correction options look like) 
# test - retest on RT choices 
(let's wait and see what the "good" space looks like) 

