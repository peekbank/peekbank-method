---
title: "Number of trials"
author: "Mike Frank"
date: "2022-12-15"
output: html_document
---

```{r}
source(here::here("helper/common.R"))


d_aoi <- readRDS(here("cached_intermediates", "1_d_aoi.Rds"))
```

Goal is to find out how reliability (test-retest) varies with number of trials, within datasets. 

what dataset have repeated administrations?
```{r}
admins <- d_aoi |>
  select(dataset_name, subject_id, administration_id, age) |>
  distinct()
repeated <- admins |>
  group_by(dataset_name, subject_id) |>
  tally() |>
  filter(n > 1)

repeated_subjects <- admins |> inner_join(repeated)
```

adams_marchman has 2 admins for each age and up to 5 ages 
fernald totlot has 1 admin at each of 4 ages
fmw sometimes has 2 admins at 1 age and 2 ages
weaver_zettersten has 2 admins at 1 age 
potter_remix has 2 admins at 1 age 

so, we can say a pair is "close enough" if the ages are within 1 month of each other and then we'll have a bunch of test-retest pairs. 

* for those pairs, for each admin, we want # of trials (administered), trial accuracy, trial RT, # trials with RT
and then we want the correlation between admin-1 and admin-2 ?

I don't know how much there's item overlap (probably is), so might be able to do something finer grained? 

```{r}
# identify pairs
# hmm, sometimes we have times with 3+ 1 month apart,
# for now allow all the pairs that result so like 14-15 and 15-16 for the same kid

pairs <- repeated_subjects |>
  group_by(dataset_name, subject_id) |>
  mutate(
    forward_age = lead(age),
    forward_diff = forward_age - age,
    test_num = case_when(
      forward_diff < 1.5 ~ 1,
    ),
    mean_age = case_when(
      test_num == 1 ~ (age + forward_age) / 2,
    ),
    second_admin = case_when(
      test_num == 1 ~ lead(administration_id)
    )
  ) |>
  filter(!is.na(test_num)) |>
  rename(first_admin = administration_id) |>
  select(-n, -age) |>
  left_join(repeated_subjects |> select(-age, -n), by = c("dataset_name", "subject_id", "second_admin" = "administration_id")) |>
  ungroup() |>
  mutate(pair_number = row_number()) |>
  filter(!(dataset_name=="adams_marchman_2018" & mean_age>28)) |> # these do have multiple sessions but with very different items banks for the two sessions!
  select(-forward_age, -forward_diff, -test_num)

pairs_long <- pairs |> pivot_longer(c("first_admin", "second_admin"), names_to = "session_num", values_to = "administration_id")
```


it has been observed that there are item distribution effects that could mess with some of these datasets.


```{r}
check_items <- d_aoi |> distinct(target_label, administration_id, trial_id, age)  |> inner_join(pairs_long) |> 
mutate(age=round(age)) |>  group_by(dataset_name, age, target_label, session_num)


check_items |> filter(dataset_name=="adams_marchman_2018") |> ggplot(aes(x=target_label, y=age, col=session_num))+geom_point()+coord_flip()+facet_wrap(~session_num)

check_items |> filter(dataset_name=="fernald_marchman_2012") |> ggplot(aes(x=target_label, y=age, col=session_num))+geom_point()+coord_flip()+facet_wrap(~session_num)

check_items |> filter(dataset_name=="fmw_2013") |> ggplot(aes(x=target_label, y=age, col=session_num))+geom_point()+coord_flip()+facet_wrap(~session_num)

check_items |> filter(dataset_name=="potter_remix") |> ggplot(aes(x=target_label, y=age, col=session_num))+geom_point()+coord_flip()+facet_wrap(~session_num)

check_items |> filter(dataset_name=="weaver_zettersten_2024") |> ggplot(aes(x=target_label, y=age, col=session_num))+geom_point()+coord_flip()+facet_wrap(~session_num)

```
conclusion: adams_marchman uses very different items for the two sessions for the 28mo + and that should be excluded, everything else looks fine 

# test - retest and number of trials
* for those pairs, for each admin, we want # of trials (administered), trial accuracy, trial RT, # trials with RT

```{r}
acc <- d_aoi |>
  inner_join(pairs_long |> select(dataset_name, administration_id, subject_id) |> distinct()) |>
  filter(t_norm >= 500) |>
  filter(t_norm <= 4000) |>
  group_by(dataset_name, subject_id, administration_id, trial_id, trial_order, target_label) |>
  summarize(acc = mean(correct, na.rm = T)) |>
  filter(!is.na(acc))

acc_mean <- acc |>
  group_by(dataset_name, subject_id, administration_id) |>
  summarize(acc_trials = sum(!is.na(acc)), acc = mean(acc, na.rm = T))

rt <- readRDS(here("cached_intermediates", "4_rt_canonical.rds")) |>
  inner_join(pairs_long |> select(dataset_name, administration_id, subject_id) |> distinct()) |>
  filter(shift_type == "D-T") |> filter(approach=="trad_launch") |> filter(logged=="raw") |> filter(!is.na(rt))

rt_mean <- rt |>
  group_by(dataset_name, subject_id, administration_id) |>
  summarize(rt_trials = n(), mean_rt = mean(rt))
```

```{r}
all <- pairs_long |>
  left_join(acc_mean) |>
  left_join(rt_mean)

all_wide <- all |>
  mutate(session_num = ifelse(session_num == "first_admin", 1, 2)) |>
  pivot_wider(values_from = c("administration_id", "acc", "acc_trials", "rt_trials", "mean_rt"), names_from = session_num) |>
  mutate(age_bin = case_when(
    mean_age < 18 ~ "12-17",
    mean_age < 21 ~ "18-20",
    mean_age < 28 ~ "21-27",
    mean_age < 33 ~ "28-32",
    mean_age >= 33 ~ "33+"
  ))
```

## test-retest on summary

let's start with some graphs

```{r}
ggplot(all_wide, aes(x = mean_rt_1, y = mean_rt_2, col = age_bin)) +
  geom_point(alpha = .5) +
  geom_abline() +
  facet_wrap(~dataset_name) +
  scale_color_viridis(discrete = T)

ggplot(all_wide, aes(x = acc_1, y = acc_2, col = age_bin)) +
  geom_point(alpha = .5) +
  geom_abline() +
  facet_wrap(~dataset_name) +
  scale_color_viridis(discrete = T)
```
what ages?

```{r}
ggplot(all_wide, aes(x = mean_age, fill = age_bin)) +
  facet_wrap(~dataset_name, scales = "free_y") +
  geom_histogram()
ggplot(all_wide, aes(x = mean_age, fill = age_bin)) +
  geom_histogram(binwidth = 1)
```
how much data

```{r}
ggplot(all_wide, aes(x = acc_trials_1, y = acc_trials_2, col = age_bin)) +
  geom_point(alpha = .5) +
  geom_abline() +
  facet_wrap(~dataset_name) +
  scale_color_viridis(discrete = T)

ggplot(all_wide, aes(x = rt_trials_1, y = rt_trials_2, col = age_bin)) +
  geom_point(alpha = .5) +
  geom_abline() +
  facet_wrap(~dataset_name) +
  scale_color_viridis(discrete = T)
```

how much more acc than RT data?

```{r}
ggplot(all_wide, aes(x = acc_trials_1, y = rt_trials_1, col = age_bin)) +
  geom_point(alpha = .5) +
  geom_abline(slope = 1) +
  geom_abline(slope = 1 / 3) +
  facet_wrap(~dataset_name)+

  #geom_smooth(method="lm", se=F)+
  scale_color_viridis(discrete = T)

ggplot(all_wide, aes(x = acc_trials_2, y = rt_trials_2, col = age_bin)) +
  geom_point(alpha = .5) +
  geom_abline(slope = 1) +
  geom_abline(slope = 1 / 3) +
  facet_wrap(~dataset_name) +
  scale_color_viridis(discrete = T)
```
yeah, seems like kids generally have 3x the number of accuracy trials as RT trials (ish)


so a number of kids do have a good number of trials, so we could reasonable do subsampling


```{r}
test_retest <- all_wide |>
  group_by(dataset_name, age_bin) |>
  summarise(
    cor_rt = ifelse(sum(!is.na(mean_rt_1) & !is.na(mean_rt_2)) > 2, cor.test(mean_rt_1, mean_rt_2)$estimate, NA),
    cor_acc = ifelse(sum(!is.na(acc_1) & !is.na(acc_2)) > 2, cor.test(acc_1, acc_2)$estimate, NA),
  )
```

```{r}
ggplot(test_retest, aes(x = dataset_name, y = cor_rt, col = age_bin)) +
  geom_point() +
  coord_flip() +
  scale_color_viridis(discrete = T)
ggplot(test_retest, aes(x = dataset_name, y = cor_acc, col = age_bin)) +
  geom_point() +
  coord_flip() +
  scale_color_viridis(discrete = T)
```
# simulate post-hoc cutoffs
start with the easy thing, what happens if you exclude pairs that don't have enough (valid) trials at each time point in the pair?

for RT
```{r}
cutoffs <- expand_grid(min = c(1, 2, 3, 4, 5, 8, 10, 12, 15))

do_boot <- function(data, indices)
  {
  df <- data |> slice(indices) |> 
    summarise(
    cor_rt = ifelse(sum(!is.na(mean_rt_1) & !is.na(mean_rt_2)) > 2, cor.test(mean_rt_1, mean_rt_2)$estimate, NA),
    )
return(df$cor_rt[1])
}

cutoff_rt <- all_wide |>
  group_by(dataset_name, age_bin) |>
  cross_join(cutoffs) |>
  filter(rt_trials_1 >= min, rt_trials_2 >= min) |>
  group_by(dataset_name, age_bin, min) |> 
  mutate(pairs=n()) |> 
  filter(pairs>4) |> 
  select(-pairs) |> 
    group_by(dataset_name, age_bin, min) |> 
  nest() |> 
  mutate(trt=map(data, \(d) {
    print(dataset_name)
      b <- boot::boot(d, do_boot, 2000)
            ci <- boot::boot.ci(b, type = "basic")
      tibble(est = b$t0, lower = ci$basic[4], upper = ci$basic[5])
    })) |>
    select(-data) |>
    unnest(trt)

saveRDS(cutoff_rt, here("cached_intermediates", "6_cutoff_rt_posthoc.rds"))
```


```{r}

cutoffs <- expand_grid(min = c(1, 2, 3, 4, 5, 8, 10, 12, 15))

data_loss <- all_wide |>
  group_by(dataset_name, age_bin) |>
  cross_join(cutoffs) |>
  filter(rt_trials_1 >= min, rt_trials_2 >= min) |>
  group_by(dataset_name, age_bin, min) |> 
  mutate(pairs=n()) |> 
  filter(pairs>4) |> 
  group_by(dataset_name, age_bin, min) |> 
  tally() |> 
  group_by(dataset_name, age_bin) |> 
  mutate(pct=n/max(n))

data_loss |> filter(min<6) |> ggplot(aes(x=min, y=pct, col=age_bin))+geom_point()+  scale_color_viridis(discrete = T) +
facet_wrap(~dataset_name)+geom_line()
cutoff_rt <- readRDS(here("cached_intermediates", "6_cutoff_rt_posthoc.rds"))

library(metafor)
cutoff_rt_summ_age <-  cutoff_rt |>
  mutate(
    stdev = (upper - lower) / (1.96 * 2),
    var = stdev**2,
  ) |>
  group_by(age_bin, min) |>
  nest() |>
  mutate(corr= map(data, \(d){
    rma(d$est, d$var) |>
      summary() |>
      coef()
  })) |> 
  unnest(corr)
  

cutoff_rt_summ <-  cutoff_rt |>
  mutate(
    stdev = (upper - lower) / (1.96 * 2),
    var = stdev**2,
  ) |>
  group_by(min) |>
  nest() |>
  mutate(corr= map(data, \(d){
    rma(d$est, d$var) |>
      summary() |>
      coef()
  })) |> 
  unnest(corr)
cutoff_rt|> ggplot(aes(x = min, y = est, ymin=lower, ymax=upper, col = age_bin)) +
  geom_pointrange( position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)

cutoff_rt_summ_age|> ggplot(aes(x = min, y = estimate, ymin=ci.lb, ymax=ci.ub, col = age_bin)) +
  geom_pointrange( position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  geom_hline(yintercept = 0)

cutoff_rt_summ|> ggplot(aes(x = min, y = estimate, ymin=ci.lb, ymax=ci.ub)) +
  geom_pointrange( position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  geom_hline(yintercept = 0)
```
something is weird with the 28-32 bin, 
otherwise, seems like cutting out kids who don't have at least a few RT trials is reasonable (for few in the 2-5 range?)

*should also check on # of datapoints left!

Minimums in the 1-5 range seem justifiable. Seems reasonable to do 2 RT as a way to balance reliability and reducing # of kids, but will depend on how large the dataset is!

for accuracy 
```{r}



cutoffs <- expand_grid(min = c(1, 2, 3, 4, 5, 8, 10, 12, 15))

do_boot <- function(data, indices)
  {
  df <- data |> slice(indices) |> 
    summarise(
    cor_acc = ifelse(sum(!is.na(acc_1) & !is.na(acc_2)) > 2, cor.test(acc_1, acc_2)$estimate, NA),
    )
return(df$cor_acc[1])
}

cutoff_acc <- all_wide |>
  group_by(dataset_name, age_bin) |>
  cross_join(cutoffs) |>
  filter(acc_trials_1 >= min, acc_trials_2 >= min) |>
  group_by(dataset_name, age_bin, min) |> 
  mutate(pairs=n()) |> 
  filter(pairs>4) |> 
  select(-pairs) |> 
    group_by(dataset_name, age_bin, min) |> 
  nest() |> 
  mutate(trt=map(data, \(d) {
    print(dataset_name)
      b <- boot::boot(d, do_boot, 2000)
            ci <- boot::boot.ci(b, type = "basic")
      tibble(est = b$t0, lower = ci$basic[4], upper = ci$basic[5])
    })) |>
    select(-data) |>
    unnest(trt)

saveRDS(cutoff_acc, here("cached_intermediates", "6_cutoff_acc_posthoc.rds"))
```


```{r}
cutoffs <- expand_grid(min = c(1, 2, 3, 4, 5, 8, 10, 12, 15))

data_loss <- all_wide |>
  group_by(dataset_name, age_bin) |>
  cross_join(cutoffs) |>
  filter(acc_trials_1 >= min, acc_trials_2 >= min) |>
  group_by(dataset_name, age_bin, min) |> 
  mutate(pairs=n()) |> 
  filter(pairs>4) |> 
  group_by(dataset_name, age_bin, min) |> 
  tally() |> 
  group_by(dataset_name, age_bin) |> 
  mutate(pct=n/max(n))

data_loss |> filter(min<6) |> ggplot(aes(x=min, y=pct, col=age_bin))+geom_point()+  scale_color_viridis(discrete = T) +
facet_wrap(~dataset_name)+geom_line()

cutoff_acc <- readRDS(here("cached_intermediates", "6_cutoff_acc_posthoc.rds"))

library(metafor)
cutoff_acc_summ_age <-  cutoff_acc |>
  mutate(
    stdev = (upper - lower) / (1.96 * 2),
    var = stdev**2,
  ) |>
  group_by(age_bin, min) |>
  nest() |>
  mutate(corr= map(data, \(d){
    rma(d$est, d$var) |>
      summary() |>
      coef()
  })) |> 
  unnest(corr)
  

cutoff_acc_summ <-  cutoff_acc |>
  mutate(
    stdev = (upper - lower) / (1.96 * 2),
    var = stdev**2,
  ) |>
  group_by(min) |>
  nest() |>
  mutate(corr= map(data, \(d){
    rma(d$est, d$var) |>
      summary() |>
      coef()
  })) |> 
  unnest(corr)

cutoff_acc|> ggplot(aes(x = min, y = est, ymin=lower, ymax=upper, col = age_bin)) +
  geom_pointrange( position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)

cutoff_acc_summ_age|> ggplot(aes(x = min, y = estimate, ymin=ci.lb, ymax=ci.ub, col = age_bin)) +
  geom_pointrange( position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  geom_hline(yintercept = 0)

cutoff_acc_summ|> ggplot(aes(x = min, y = estimate, ymin=ci.lb, ymax=ci.ub)) +
  geom_pointrange( position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  geom_hline(yintercept = 0)
```

don't see as much for acc trials, but we expect that kids have like 3x the accuray trials as the RT trials, so scale might be off, but we're also not seeing differences up around 15 either

Accuracy min of 3 seems reasonable, but there are also less likely to be data tradeoffs. 

# simulate different trial counts

## RT
let's start with RT
we'll look at all the kids where we *actually* have 5+ datapoints for each time
and then look at how t-rt varies if we only take 1,2,3,4,5 of them 

for now, maybe just use slice (rather than a random sampling), but could reconsider

```{r}
eligible_5 <- all_wide |>
  filter(rt_trials_1 > 4, rt_trials_2 > 4) |>
  select(dataset_name, subject_id, mean_age, pair_number, administration_id_1, administration_id_2) |>
  pivot_longer(c("administration_id_1", "administration_id_2"), names_to = "session_num", values_to = "administration_id") |>
  select(dataset_name, subject_id, administration_id)

rt_subsample_5 <- expand_grid(num_samples = c(1, 2, 3, 4, 5)) |>
  mutate(rts = map(num_samples, \(num) {
    rt |>
      group_by(dataset_name, subject_id, administration_id) |>
      inner_join(eligible_5) |>
      group_by(dataset_name, subject_id, administration_id) |>
      slice(1:num) |>
      summarize(rt_trials = n(), mean_rt = mean(rt))
  })) |>
  unnest(rts)


rt_sub_corr_5 <- pairs_long |>
  left_join(rt_subsample_5) |>
  mutate(session_num = ifelse(session_num == "first_admin", 1, 2)) |>
  filter(!is.na(num_samples)) |>
  pivot_wider(values_from = c("administration_id", "rt_trials", "mean_rt"), names_from = session_num) |>
  mutate(age_bin = case_when(
    mean_age < 18 ~ "12-17",
    mean_age < 21 ~ "18-20",
    mean_age < 28 ~ "21-27",
    mean_age < 33 ~ "28-32",
    mean_age >= 33 ~ "33+"
  )) |>
  filter(!is.na(mean_rt_1)) |>
  filter(!is.na(mean_rt_2)) |>
  group_by(dataset_name, age_bin, num_samples) |>
  summarise(
    cor_rt = ifelse(sum(!is.na(mean_rt_1) & !is.na(mean_rt_2)) > 2, cor.test(mean_rt_1, mean_rt_2)$estimate, NA),
    pairs = n()
  )

ggplot(rt_sub_corr_5 |> filter(pairs > 9), aes(x = num_samples, y = cor_rt, col = age_bin)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)


ggplot(rt_sub_corr_5 |> filter(pairs>9), aes(x = num_samples, y = cor_rt, col = age_bin)) +
  geom_point(position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)
```
some datasets don't have very many kids left, so capping to dataset-age bins with 10 kids

seems like more helps, but also some datasets are weird? 

```{r}
eligible_10 <- all_wide |>
  filter(rt_trials_1 > 9, rt_trials_2 > 9) |>
  select(dataset_name, subject_id, mean_age, pair_number, administration_id_1, administration_id_2) |>
  pivot_longer(c("administration_id_1", "administration_id_2"), names_to = "session_num", values_to = "administration_id") |>
  select(dataset_name, subject_id, administration_id)

rt_subsample_10 <- expand_grid(num_samples = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)) |>
  mutate(rts = map(num_samples, \(num) {
    rt |>
      group_by(dataset_name, subject_id, administration_id) |>
      inner_join(eligible_10) |>
      group_by(dataset_name, subject_id, administration_id) |>
      slice(1:num) |>
      summarize(rt_trials = n(), mean_rt = mean(rt))
  })) |>
  unnest(rts)


rt_sub_corr_10 <- pairs_long |>
  left_join(rt_subsample_10) |>
  mutate(session_num = ifelse(session_num == "first_admin", 1, 2)) |>
  filter(!is.na(num_samples)) |>
  pivot_wider(values_from = c("administration_id", "rt_trials", "mean_rt"), names_from = session_num) |>
  mutate(age_bin = case_when(
    mean_age < 18 ~ "12-17",
    mean_age < 21 ~ "18-20",
    mean_age < 28 ~ "21-27",
    mean_age < 33 ~ "28-32",
    mean_age >= 33 ~ "33+"
  )) |>
  filter(!is.na(mean_rt_1)) |>
  filter(!is.na(mean_rt_2)) |>
  group_by(dataset_name, age_bin, num_samples) |>
  summarise(
    cor_rt = ifelse(sum(!is.na(mean_rt_1) & !is.na(mean_rt_2)) > 2, cor.test(mean_rt_1, mean_rt_2)$estimate, NA),
    pairs = n()
  )

ggplot(rt_sub_corr_10 |> filter(pairs > 5), aes(x = num_samples, y = cor_rt, col = age_bin)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)


ggplot(rt_sub_corr_10 |> filter(pairs>5), aes(x = num_samples, y = cor_rt, col = age_bin)) +
  geom_point(position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)
```

more RT samples is better, maybe some diminishing returns about like 5 or 7? 



## acc
for now, maybe just use slice (rather than a random sampling), but could reconsider

```{r}
eligible_5 <- all_wide |>
  filter(acc_trials_1 > 4, acc_trials_2 > 4) |>
  select(dataset_name, subject_id, mean_age, pair_number, administration_id_1, administration_id_2) |>
  pivot_longer(c("administration_id_1", "administration_id_2"), names_to = "session_num", values_to = "administration_id") |>
  select(dataset_name, subject_id, administration_id)

acc_subsample_5 <- expand_grid(num_samples = c(1, 2, 3, 4, 5)) |>
  mutate(accs = map(num_samples, \(num) {
    acc |>
      group_by(dataset_name, subject_id, administration_id) |>
      inner_join(eligible_5) |>
      group_by(dataset_name, subject_id, administration_id) |>
      slice(1:num) |>
      summarize(acc_trials = n(), mean_acc = mean(acc))
  })) |>
  unnest(accs)


acc_sub_corr_5 <- pairs_long |>
  left_join(acc_subsample_5) |>
  mutate(session_num = ifelse(session_num == "first_admin", 1, 2)) |>
  filter(!is.na(num_samples)) |>
  pivot_wider(values_from = c("administration_id", "acc_trials", "mean_acc"), names_from = session_num) |>
  mutate(age_bin = case_when(
    mean_age < 18 ~ "12-17",
    mean_age < 21 ~ "18-20",
    mean_age < 28 ~ "21-27",
    mean_age < 33 ~ "28-32",
    mean_age >= 33 ~ "33+"
  )) |>
  filter(!is.na(mean_acc_1)) |>
  filter(!is.na(mean_acc_2)) |>
  group_by(dataset_name, age_bin, num_samples) |>
  summarise(
    cor_acc = ifelse(sum(!is.na(mean_acc_1) & !is.na(mean_acc_2)) > 2, cor.test(mean_acc_1, mean_acc_2)$estimate, NA),
    pairs = n()
  )

ggplot(acc_sub_corr_5 |> filter(pairs > 9), aes(x = num_samples, y = cor_acc, col = age_bin)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)


ggplot(acc_sub_corr_5 |> filter(pairs > 9), aes(x = num_samples, y = cor_acc, col = age_bin)) +
  geom_point(position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)
```
some datasets don't have very many kids left, so capping to dataset-age bins with 10 kids

seems like more helps, but also some datasets are weird? 

```{r}
eligible_10 <- all_wide |>
  filter(acc_trials_1 > 9, acc_trials_2 > 9) |>
  select(dataset_name, subject_id, mean_age, pair_number, administration_id_1, administration_id_2) |>
  pivot_longer(c("administration_id_1", "administration_id_2"), names_to = "session_num", values_to = "administration_id") |>
  select(dataset_name, subject_id, administration_id)

acc_subsample_10 <- expand_grid(num_samples = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)) |>
  mutate(accs = map(num_samples, \(num) {
    acc |>
      group_by(dataset_name, subject_id, administration_id) |>
      inner_join(eligible_10) |>
      group_by(dataset_name, subject_id, administration_id) |>
      slice(1:num) |>
      summarize(acc_trials = n(), mean_acc = mean(acc))
  })) |>
  unnest(accs)


acc_sub_corr_10 <- pairs_long |>
  left_join(acc_subsample_10) |>
  mutate(session_num = ifelse(session_num == "first_admin", 1, 2)) |>
  filter(!is.na(num_samples)) |>
  pivot_wider(values_from = c("administration_id", "acc_trials", "mean_acc"), names_from = session_num) |>
  mutate(age_bin = case_when(
    mean_age < 18 ~ "12-17",
    mean_age < 21 ~ "18-20",
    mean_age < 28 ~ "21-27",
    mean_age < 33 ~ "28-32",
    mean_age >= 33 ~ "33+"
  )) |>
  filter(!is.na(mean_acc_1)) |>
  filter(!is.na(mean_acc_2)) |>
  group_by(dataset_name, age_bin, num_samples) |>
  summarise(
    cor_acc = ifelse(sum(!is.na(mean_acc_1) & !is.na(mean_acc_2)) > 2, cor.test(mean_acc_1, mean_acc_2)$estimate, NA),
    pairs = n()
  )

ggplot(acc_sub_corr_10 |> filter(pairs > 4), aes(x = num_samples, y = cor_acc, col = age_bin)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)


ggplot(acc_sub_corr_10 |> filter(pairs > 4), aes(x = num_samples, y = cor_acc, col = age_bin)) +
  geom_point(position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)
```

accuracy also shows a more is better, with some stabilizing? but we can also check even higher. 

```{r}
eligible_20 <- all_wide |>
  filter(acc_trials_1 > 19, acc_trials_2 > 19) |>
  select(dataset_name, subject_id, mean_age, pair_number, administration_id_1, administration_id_2) |>
  pivot_longer(c("administration_id_1", "administration_id_2"), names_to = "session_num", values_to = "administration_id") |>
  select(dataset_name, subject_id, administration_id)

acc_subsample_20 <- expand_grid(num_samples = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)) |>
  mutate(accs = map(num_samples, \(num) {
    acc |>
      group_by(dataset_name, subject_id, administration_id) |>
      inner_join(eligible_20) |>
      group_by(dataset_name, subject_id, administration_id) |>
      slice(1:num) |>
      summarize(acc_trials = n(), mean_acc = mean(acc))
  })) |>
  unnest(accs)


acc_sub_corr_20 <- pairs_long |>
  left_join(acc_subsample_20) |>
  mutate(session_num = ifelse(session_num == "first_admin", 1, 2)) |>
  filter(!is.na(num_samples)) |>
  pivot_wider(values_from = c("administration_id", "acc_trials", "mean_acc"), names_from = session_num) |>
  mutate(age_bin = case_when(
    mean_age < 18 ~ "12-17",
    mean_age < 21 ~ "18-20",
    mean_age < 28 ~ "21-27",
    mean_age < 33 ~ "28-32",
    mean_age >= 33 ~ "33+"
  )) |>
  filter(!is.na(mean_acc_1)) |>
  filter(!is.na(mean_acc_2)) |>
  group_by(dataset_name, age_bin, num_samples) |>
  summarise(
    cor_acc = ifelse(sum(!is.na(mean_acc_1) & !is.na(mean_acc_2)) > 2, cor.test(mean_acc_1, mean_acc_2)$estimate, NA),
    pairs = n()
  )

ggplot(acc_sub_corr_20 |> filter(pairs > 4), aes(x = num_samples, y = cor_acc, col = age_bin)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)


ggplot(acc_sub_corr_20 |> filter(pairs > 4), aes(x = num_samples, y = cor_acc, col = age_bin)) +
  geom_point(position = position_dodge(.5)) +
  geom_line(position = position_dodge(.5)) +
  scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)
```

# Try up/down sampling with slicing with replacement

```{r}

eligible <- all_wide |>
  select(dataset_name, subject_id, mean_age, pair_number, administration_id_1, administration_id_2) |>
  pivot_longer(c("administration_id_1", "administration_id_2"), names_to = "session_num", values_to = "administration_id") |>
  select(dataset_name, subject_id, administration_id)

acc_resample <- expand_grid(num_samples = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 25, 30), iter=1:10) |>
  mutate(accs = map(num_samples, \(num) {
    acc |>
      group_by(dataset_name, subject_id, administration_id) |>
      inner_join(eligible, by=c("dataset_name", "subject_id", "administration_id")) |>
      group_by(dataset_name, subject_id, administration_id) |>
      slice_sample(n=num,replace=T) |>
      summarize(acc_trials = n(), mean_acc = mean(acc))
  })) |>
  unnest(accs)


acc_corr_resample <- pairs_long |>
  left_join(acc_resample) |>
  mutate(session_num = ifelse(session_num == "first_admin", 1, 2)) |>
  filter(!is.na(num_samples)) |>
  pivot_wider(values_from = c("administration_id", "acc_trials", "mean_acc"), names_from = session_num) |>
  mutate(age_bin = case_when(
    mean_age < 18 ~ "12-17",
    mean_age < 21 ~ "18-20",
    mean_age < 28 ~ "21-27",
    mean_age < 33 ~ "28-32",
    mean_age >= 33 ~ "33+"
  )) |>
  filter(!is.na(mean_acc_1)) |>
  filter(!is.na(mean_acc_2)) |>
  group_by(dataset_name, age_bin, num_samples, iter) |>
  summarise(
    cor_acc = ifelse(sum(!is.na(mean_acc_1) & !is.na(mean_acc_2)) > 2, cor.test(mean_acc_1, mean_acc_2)$estimate, NA)  )

ggplot(acc_corr_resample, aes(x = num_samples, y = cor_acc, col = age_bin)) +
  stat_summary(position = position_dodge(.5))+
  stat_summary(position = position_dodge(.5),geom="line")+

    scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)+geom_vline(xintercept=10, lty="dashed")+geom_vline(xintercept=15, lty="dashed")

ggplot(acc_corr_resample, aes(x = num_samples, y = cor_acc, col = age_bin)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  geom_smooth()+
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)+geom_vline(xintercept=10, lty="dashed")+geom_vline(xintercept=15, lty="dashed")
```
aiming for 10-15 accuracies seems reasonable. 


```{r}

eligible <- all_wide |>
  select(dataset_name, subject_id, mean_age, pair_number, administration_id_1, administration_id_2) |>
  pivot_longer(c("administration_id_1", "administration_id_2"), names_to = "session_num", values_to = "administration_id") |>
  select(dataset_name, subject_id, administration_id)

rt_resample <- expand_grid(num_samples = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), iter=1:10) |>
  mutate(rts = map(num_samples, \(num) {
    rt |>
      group_by(dataset_name, subject_id, administration_id) |>
      inner_join(eligible, by=c("dataset_name", "subject_id", "administration_id")) |>
      group_by(dataset_name, subject_id, administration_id) |>
      slice_sample(n=num,replace=T) |>
      summarize(rt_trials = n(), mean_rt = mean(rt))
  })) |>
  unnest(rts)


rt_corr_resample <- pairs_long |>
  left_join(rt_resample) |>
  mutate(session_num = ifelse(session_num == "first_admin", 1, 2)) |>
  filter(!is.na(num_samples)) |>
  pivot_wider(values_from = c("administration_id", "rt_trials", "mean_rt"), names_from = session_num) |>
  mutate(age_bin = case_when(
    mean_age < 18 ~ "12-17",
    mean_age < 21 ~ "18-20",
    mean_age < 28 ~ "21-27",
    mean_age < 33 ~ "28-32",
    mean_age >= 33 ~ "33+"
  )) |>
  filter(!is.na(mean_rt_1)) |>
  filter(!is.na(mean_rt_2)) |>
  group_by(dataset_name, age_bin, num_samples, iter) |>
  summarise(
    cor_rt = ifelse(sum(!is.na(mean_rt_1) & !is.na(mean_rt_2)) > 2, cor.test(mean_rt_1, mean_rt_2)$estimate, NA)  )

ggplot(rt_corr_resample, aes(x = num_samples, y = cor_rt, col = age_bin)) +
  stat_summary(position = position_dodge(.5))+
  stat_summary(position = position_dodge(.5),geom="line")+
    scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)+geom_vline(xintercept=5, lty="dashed")+geom_vline(xintercept=10, lty="dashed")

ggplot(rt_corr_resample, aes(x = num_samples, y = cor_rt)) +
  stat_summary(position = position_dodge(.5))+
  stat_summary(position = position_dodge(.5),geom="line")+
    scale_color_viridis(discrete = T) +
  facet_wrap(~dataset_name) +
  geom_hline(yintercept = 0)+geom_vline(xintercept=5, lty="dashed")+geom_vline(xintercept=10, lty="dashed")

ggplot(rt_corr_resample, aes(x = num_samples, y = cor_rt, col = age_bin)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  geom_smooth(se=F)+
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)+geom_vline(xintercept=5, lty="dashed")+geom_vline(xintercept=10, lty="dashed")

ggplot(rt_corr_resample, aes(x = num_samples, y = cor_rt)) +
  scale_color_viridis(discrete = T) +
  stat_summary(position = position_dodge(.5)) +
  geom_smooth(se=F)+
  stat_summary(position = position_dodge(.5), geom = "line") +
  geom_hline(yintercept = 0)+geom_vline(xintercept=5, lty="dashed")+geom_vline(xintercept=10, lty="dashed")
```
what is happening wth fmw??

recs: definitely is better to have more than 1 RT. Doing 10 trials total will likely get 2 RTs from nearly all kids. 

Aim for 5-10 RT trials for test-retest reliability. (Meaning 15-30 overall trials presented)

for accuracy probably 10-15 trials is enough.

At least 10 trials which should get decent accuracy and multiple RT's 

10 minimum, reliability (at least for RT) is probably increasing up to 30 total trials. 
```{r}

acc_all <- d_aoi |>
  filter(t_norm >= 500) |>
  filter(t_norm <= 4000) |>
  group_by(dataset_name, subject_id, administration_id, trial_id, trial_order, target_label) |>
  summarize(acc = mean(correct, na.rm = T)) |>
  filter(!is.na(acc))

rt_all <- readRDS(here("cached_intermediates", "4_rt_canonical.rds")) |>
  filter(shift_type == "D-T") |> filter(approach=="trad_launch") |> filter(logged=="raw") |> filter(!is.na(rt))

acc_all |> left_join(rt_all) |> group_by(administration_id, dataset_name) |> 
  summarize(acc_count=sum(!is.na(acc)), rt_count=sum(!is.na(rt))) |> 
  ggplot(aes(x=acc_count, y=rt_count))+
  geom_point(alpha=.1, color="blue")+
  geom_abline(slope=1/3)+
  geom_hline(yintercept=5, lty="dashed")+
    geom_hline(yintercept=2, lty="dashed")+
  geom_hline(yintercept=10, lty="dashed")+
  geom_vline(xintercept=10, lty="dashed")+
  geom_vline(xintercept=15, lty="dashed")+
  facet_wrap(~dataset_name)

acc_all |> left_join(rt_all) |> group_by(administration_id, dataset_name) |> 
  summarize(acc_count=sum(!is.na(acc)), rt_count=sum(!is.na(rt))) |> 
  filter(acc_count>9) |> 
  ggplot(aes(x=acc_count, y=rt_count))+
  geom_point(alpha=.1, color="blue")+
  geom_abline(slope=1/3)+
  geom_hline(yintercept=5, lty="dashed")+
    geom_hline(yintercept=2, lty="dashed")+
  geom_hline(yintercept=10, lty="dashed")+
  geom_vline(xintercept=10, lty="dashed")+
  geom_vline(xintercept=15, lty="dashed")+
  facet_wrap(~dataset_name)
```

