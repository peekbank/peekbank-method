---
title: "Baseline correction"
author: "Mike Frank"
date: "2022-12-15"
output: html_document
---



```{r}
source(here::here("helper/common.R"))

d_aoi <- readRDS(here("cached_intermediates", "1_d_aoi.Rds"))
```


# Baseline-corrected accuracy general approach

Accuracy measures are just about where a child looks after they have heard the stimulus, but this is not necessarily the best measure of children's *response* to the stimulus, as children's looking patterns could also be driven by item-level effects. For instance, children may look more at the more salient, more animate, or more recently referred to object. 

Researchers have tried a few approaches for "correcting" for these baseline preferences. Options include

* a baseline-corrected accuracy where the fraction of looking at target prior to stimulus response is subtracted from the post-stimulus accuracy (thus adjusting for baseline looking preference)

* using paired trials where each was the target to see if during the post-stimulus period an item is looked at more as the target

* (other approaches)

Here we'll just look at whether using the difference between post- and pre- accuracy affects reliability and/or validity compared to plain "post-stimulus" accuracy measures. 

Throughout here, we treat the "normal" window as 500 - 4000ms (which is within the range of reasonable according to the accuracy analysis), and vary the size of the pre-window. 

# What datasets have pre information?

Different datasets have aois for different time periods. 

```{r}
ggplot(d_aoi, aes(x = t_norm)) +
  geom_histogram() +
  facet_wrap(~dataset_name, scales = "free_y") +
  geom_vline(xintercept = 0) +
  geom_vline(xintercept = 400)

baseline_lengths <- d_aoi |>
  group_by(dataset_name) |>
  summarise(t_min = min(t_norm))
```


# Grid search ICC (reliability)

```{r, eval=F}
icc_bc_window_sim <- function(b_start = -2000, b_end = 0,
                              t_start = 500, t_end = 4000,
                              object) {
  # get trials with some baseline
  baseline_lengths <- d_aoi |>
    group_by(dataset_name, trial_id) |>
    summarise(t_min = min(t_norm))

  # get baseline corrected accuracies for all trials with ANY baseline info
  df <- d_aoi |>
    left_join(baseline_lengths) |>
    filter(t_min < 0) |>
    group_by(dataset_name, dataset_id, administration_id, target_label, trial_id) |>
    summarise(
      window_accuracy = mean(correct[t_norm >= t_start & t_norm <= t_end],
        na.rm = TRUE
      ),
      baseline_accuracy = mean(correct[t_norm >= b_start & t_norm <= b_end],
        na.rm = TRUE
      ),
      bc_accuracy = window_accuracy - baseline_accuracy
    ) |>
    filter(!is.na(bc_accuracy)) |>
    group_by(dataset_id, dataset_name, administration_id, target_label) |>
    mutate(repetition = row_number())

  # compute ICCs
  df |>
    group_by(dataset_name) |>
    nest() |>
    mutate(icc = unlist(map(data, ~ get_icc(., "bc_accuracy", object)))) |>
    select(-data) |>
    unnest(cols = c())
}

bc_acc_params <- expand_grid(
  t_start = 500,
  t_end = c(2000, 4000),
  b_start = seq(-4000, -1000, 500),
  b_end = seq(-500, 500, 500),
  object = c("administration")
)

library(multidplyr)
cluster <- new_cluster(16)
cluster_library(cluster, "dplyr")
cluster_library(cluster, "tidyr")
cluster_library(cluster, "purrr")
cluster_library(cluster, "agreement")
cluster_copy(cluster, "get_icc")
cluster_copy(cluster, "d_aoi")
cluster_copy(cluster, "icc_bc_window_sim")

bc_accs <- bc_acc_params |>
  partition(cluster) |>
  mutate(icc = pmap(list(b_start, b_end, t_start, t_end, object), icc_bc_window_sim)) |>
  collect() |>
  unnest(col = icc)

saveRDS(bc_accs, here("cached_intermediates", "bc_accs_icc.rds"))
```

We consider baseline windows starting between -4000 and -1000 ms and ending at -500, 0, or 500 ms. 

As a comparison, we use the 400 ms start times from accuracy (we didn't try 500-2000 saved)

```{r}
bc_accs <- readRDS(here("cached_intermediates", "7_bc_accs_icc.rds")) |>
  bind_rows(readRDS(here("cached_intermediates", "3_acc_icc_finegrain.rds"))) |>
  filter(t_start %in% c(500), t_end %in% c(4000)) |>
  mutate(
    b_start = ifelse(is.na(b_start), 0, b_start),
    b_end = ifelse(is.na(b_end), 0, b_end)
  )
```

```{r}
bc_accs_summary <- bc_accs |>
  group_by(t_start, t_end, b_start, b_end) |>
  mutate(mean_icc = mean(icc, na.rm = T))

ggplot(bc_accs_summary, aes(x = b_start, y = b_end, fill = mean_icc)) +
  geom_tile(color = "white") +
  scale_fill_viridis(name = "Mean ICC", option = "inferno") +
  xlab("Window Start Time (in ms)") +
  ylab("Window End Time (in ms)")
```
overall, the no-base-line-correction has higher ICC than any of the baseline-corrected options.

if we look dataset by dataset, some datasets seem to have numerically higher ICC for some baseline-correciton options than for the no-bc option. 

```{r}
bc_accs |>
  filter(t_end == 4000) |>
  ggplot(aes(x = b_start, y = b_end, fill = icc)) +
  geom_tile(color = "white") +
  scale_fill_viridis(name = "Mean ICC", option = "inferno") +
  scale_x_continuous(breaks = c(-1000, -500, 0, 500, 1000, 1500)) +
  xlab("Window Start Time (in ms)") +
  ylab("Window End Time (in ms)") +
  facet_wrap(~dataset_name)
```
let's subset datasets by how much baseline they have. 

for only datasets that have some data before -1000: no baseline is better
```{r}
bc_accs_summary <- bc_accs |>
  inner_join(baseline_lengths |> filter(t_min <= -1000)) |>
  group_by(t_start, t_end, b_start, b_end) |>
  mutate(mean_icc = mean(icc, na.rm = T))
ggplot(bc_accs_summary, aes(x = b_start, y = b_end, fill = mean_icc)) +
  geom_tile(color = "white") +
  scale_fill_viridis(name = "Mean ICC", option = "inferno") +
  scale_x_continuous(breaks = c(-1000, -500, 0, 500, 1000, 1500)) +
  xlab("Window Start Time (in ms)") +
  ylab("Window End Time (in ms)") +
  facet_wrap(~t_end)
```
for only datasets that have some data before -2000: no baseline is better

```{r}
bc_accs_summary <- bc_accs |>
  inner_join(baseline_lengths |> filter(t_min <= -2000)) |>
  group_by(t_start, t_end, b_start, b_end) |>
  mutate(mean_icc = mean(icc, na.rm = T))
ggplot(bc_accs_summary, aes(x = b_start, y = b_end, fill = mean_icc)) +
  geom_tile(color = "white") +
  scale_fill_viridis(name = "Mean ICC", option = "inferno") +
  scale_x_continuous(breaks = c(-1000, -500, 0, 500, 1000, 1500)) +
  xlab("Window Start Time (in ms)") +
  ylab("Window End Time (in ms)") +
  facet_wrap(~t_end)
```
for only datasets that have some data before -3000: here, we start seeing baseline correction out-performing no-bc, but primarily when we consider really low pre-windows

```{r}
bc_accs_summary <- bc_accs |>
  inner_join(baseline_lengths |> filter(t_min <= -3000)) |>
  group_by(t_start, t_end, b_start, b_end) |>
  mutate(mean_icc = mean(icc, na.rm = T))
ggplot(bc_accs_summary, aes(x = b_start, y = b_end, fill = mean_icc)) +
  geom_tile(color = "white") +
  scale_fill_viridis(name = "Mean ICC", option = "inferno") +
  xlab("Window Start Time (in ms)") +
  ylab("Window End Time (in ms)") +
  facet_wrap(~t_end)

bc_accs |>
  inner_join(baseline_lengths |> filter(t_min <= -3000)) |> ggplot(aes(x = b_start, y = b_end, fill = icc)) +
  geom_tile(color = "white") +
  scale_fill_viridis(name = "Mean ICC", option = "inferno") +
  xlab("Window Start Time (in ms)") +
  ylab("Window End Time (in ms)") +
  facet_wrap(~dataset_name)
```
so, looks like for the datasets with data before -3000 (5 datasets), then you get higher icc for baselining, but you want your baseline windows to start at -3000 or -4000 and go to -500 or 0.  

# Bootstrapped ICC

How consistent are these differences? We'll bootstrap to get some ranges. 

All of these have 500-4000 as the main window.

We try a range of pre-window starts, and either -500 or 0 as the pre-window end. 

```{r, eval=F}
icc_bc_window_bootstrap_sim <- function(b_start = -2000, b_end = 0,
                                        t_start = 500, t_end = 4000,
                                        object) {
  # get trials with some baseline
  baseline_lengths <- d_aoi |>
    group_by(dataset_name, trial_id) |>
    summarise(t_min = min(t_norm))

  # get baseline corrected accuracies for all trials with ANY baseline info
  df <- d_aoi |>
    left_join(baseline_lengths) |>
    filter(t_min < 0) |>
    group_by(dataset_name, dataset_id, administration_id, target_label, trial_id) |>
    summarise(
      window_accuracy = mean(correct[t_norm >= t_start & t_norm <= t_end],
        na.rm = TRUE
      ),
      baseline_accuracy = mean(correct[t_norm >= b_start & t_norm <= b_end],
        na.rm = TRUE
      ),
      bc_accuracy = window_accuracy - baseline_accuracy
    ) |>
    filter(!is.na(bc_accuracy)) |>
    group_by(dataset_id, dataset_name, administration_id, target_label) |>
    mutate(repetition = row_number())

  # compute ICCs
  df |>
    group_by(dataset_name) |>
    nest() |>
    mutate(icc = map(data, \(d) bootstrap_icc(d, "bc_accuracy", 2000))) |>
    select(-data) |>
    unnest(icc)
}


icc_bc_window_age_bootstrap_sim <- function(b_start = -2000, b_end = 0,
                                            t_start = 500, t_end = 4000,
                                            object) {
  # get trials with some baseline
  baseline_lengths <- d_aoi |>
    group_by(dataset_name, trial_id) |>
    summarise(t_min = min(t_norm))

  # get baseline corrected accuracies for all trials with ANY baseline info
  df <- d_aoi |>
    left_join(baseline_lengths) |>
    mutate(younger = age < 24) |>
    filter(t_min < 0) |>
    group_by(dataset_name, dataset_id, administration_id, target_label, trial_id, younger) |>
    summarise(
      window_accuracy = mean(correct[t_norm >= t_start & t_norm <= t_end],
        na.rm = TRUE
      ),
      baseline_accuracy = mean(correct[t_norm >= b_start & t_norm <= b_end],
        na.rm = TRUE
      ),
      bc_accuracy = window_accuracy - baseline_accuracy
    ) |>
    filter(!is.na(bc_accuracy)) |>
    group_by(dataset_id, dataset_name, administration_id, target_label, younger) |>
    mutate(repetition = row_number())

  # compute ICCs
  df |>
    group_by(dataset_name, younger) |>
    nest() |>
    mutate(icc = map(data, \(d) bootstrap_icc(d, "bc_accuracy", 2000))) |>
    select(-data) |>
    unnest(icc)
}

bc_acc_params <- expand_grid(
  t_start = 500,
  t_end = c(4000),
  b_start = seq(-4000, -1000, 1000),
  b_end = c(-500, 0),
  object = c("administration")
)

library(multidplyr)
cluster <- new_cluster(16)
cluster_library(cluster, "dplyr")
cluster_library(cluster, "tidyr")
cluster_library(cluster, "purrr")
cluster_library(cluster, "agreement")
cluster_copy(cluster, "bootstrap_icc")
cluster_copy(cluster, "d_aoi")
cluster_copy(cluster, "icc_bc_window_bootstrap_sim")
cluster_copy(cluster, "icc_bc_window_age_bootstrap_sim")


bc_accs <- bc_acc_params |>
  partition(cluster) |>
  mutate(icc = pmap(list(b_start, b_end, t_start, t_end, object), icc_bc_window_bootstrap_sim)) |>
  collect() |>
  unnest(col = icc)

saveRDS(bc_accs, here("cached_intermediates", "7_bc_accs_icc_boot.rds"))

bc_accs_age <- bc_acc_params |>
  partition(cluster) |>
  mutate(icc = pmap(list(b_start, b_end, t_start, t_end, object), icc_bc_window_age_bootstrap_sim)) |>
  collect() |>
  unnest(col = icc)

saveRDS(bc_accs_age, here("cached_intermediates", "7_bc_accs_icc_boot_age.rds"))
```

```{r}
bc_boot <- readRDS(here("cached_intermediates", "7_bc_accs_icc_boot.rds")) 
no_bc_boot <- readRDS(here("cached_intermediates", "3_acc_icc_boot.rds")) |> filter(t_start == 500, t_end == 4000)

bc_boot_age <- readRDS(here("cached_intermediates", "7_bc_accs_icc_boot_age.rds"))
no_bc_boot_age <- readRDS(here("cached_intermediates", "3_acc_icc_boot_age.rds")) |> filter(t_start == 500, t_end == 4000)
```


```{r, fig.width=10}
boot_graph <- bc_boot |>
  bind_rows(no_bc_boot) |>   inner_join(baseline_lengths |> filter(t_min < 0)) |>
  mutate(b_start = ifelse(is.na(b_start), "none", as.character(b_start)))
```

Across all ages of children, here's the outcome. 
```{r, fig.width=10}
boot_graph |> ggplot(aes(x = b_start, color = as.character(b_end), y = est, ymin = lower, ymax = upper)) +
  geom_pointrange(position = position_dodge(width = .25)) +
  facet_wrap(~dataset_name)
```
In some datasets, the baselines seem to hurt, but in other datasets it seems to not make a difference. 

We can also look split by children's age. 

just for the younger kids (< 24 months)

```{r, fig.width=10}
boot_graph_age <- bc_boot_age|>  
  bind_rows(no_bc_boot_age) |>inner_join(baseline_lengths |> filter(t_min < 0)) |> 
  mutate(b_start = ifelse(is.na(b_start), "none", as.character(b_start))) |> 
  mutate(younger=ifelse(younger, "<24months", ">=24months"))

boot_graph_age |> filter(younger=="<24months")  |> ggplot(aes(x = b_start, color = as.character(b_end), y = est, ymin = lower, ymax = upper)) +
  geom_pointrange(position = position_dodge(width = .25)) +
  facet_wrap(~dataset_name)

```

just for the older kids

```{r, fig.width=10}

boot_graph_age |> filter(younger==">=24months")  |> ggplot(aes(x = b_start, color = as.character(b_end), y = est, ymin = lower, ymax = upper)) +
  geom_pointrange(position = position_dodge(width = .25)) +
  facet_wrap(~dataset_name)

```

what about meta-analytic estimates?

```{r}
baseline_lengths <- d_aoi |>
  group_by(dataset_name) |>
  summarise(t_min = min(t_norm))

library(metafor)
bc_boot_summ <- boot_graph |>
  inner_join(baseline_lengths |> filter(t_min < 0)) |>
  filter(!is.na(lower), !is.na(upper)) |>
  mutate(
    stdev = (upper - lower) / (1.96 * 2),
    var = stdev**2
  ) |>
  group_by(b_start, b_end) |>
  nest() |>
  mutate(icc = map(data, \(d){
    rma(d$est, d$var) |>
      summary() |>
      coef()
  })) |>
  select(-data) |>
  unnest(icc)

bc_boot_summ |> ggplot(aes(x = b_start, color = as.character(b_end), y = estimate, ymin = ci.lb, ymax = ci.ub)) +
  geom_pointrange(position = position_dodge(width = .25))
```
across the whole dataset, baseline-correction hurts reliability. 

what about just for the datasets with long pre-windows?


```{r}
bc_boot_early_summ <- boot_graph |>
  inner_join(baseline_lengths |> filter(t_min <= -3000)) |>
  filter(!is.na(lower), !is.na(upper)) |>
  mutate(
    stdev = (upper - lower) / (1.96 * 2),
    var = stdev**2
  ) |>
  group_by(b_start, b_end) |>
  nest() |>
  mutate(icc = map(data, \(d){
    rma(d$est, d$var) |>
      summary() |>
      coef()
  })) |>
  select(-data) |>
  unnest(icc)

bc_boot_early_summ |> ggplot(aes(x = b_start, color = as.character(b_end), y = estimate, ymin = ci.lb, ymax = ci.ub)) +
  geom_pointrange(position = position_dodge(width = .25))
```
again, we see that if you have data from before -3000ms then, baseline correcting using a long window (so 2-4 seconds worth of pre-window) gets the same ICC as doing no baseline-correction. No sign that it's better, but it's not worse. 

for all the datasets, split by age

```{r}
baseline_lengths <- d_aoi |>
  group_by(dataset_name) |>
  summarise(t_min = min(t_norm))

bc_boot_age_summ <- boot_graph_age |>
  inner_join(baseline_lengths |> filter(t_min <= 0)) |>
  filter(!is.na(lower), !is.na(upper)) |>
  mutate(
    stdev = (upper - lower) / (1.96 * 2),
    var = stdev**2
  ) |>
  group_by(b_start, b_end, younger) |>
  nest() |>
  mutate(icc = map(data, \(d){
    rma(d$est, d$var) |>
      summary() |>
      coef()
  })) |>
  select(-data) |>
  unnest(icc)

bc_boot_age_summ |> ggplot(aes(x = b_start, color = as.character(b_end), y = estimate, ymin = ci.lb, ymax = ci.ub)) + facet_wrap(~younger)+
  geom_pointrange(position = position_dodge(width = .25))
```
baseline correction is more of a mistake for older children (or older children tend to go with datasets with less baseline information)

if we only look at the 5 datasets with early looking information, 
```{r}
bc_boot_age_early_summ <- boot_graph_age |>
  inner_join(baseline_lengths |> filter(t_min <= -3000)) |>
  filter(!is.na(lower), !is.na(upper)) |>
  mutate(
    stdev = (upper - lower) / (1.96 * 2),
    var = stdev**2
  ) |>
  group_by(b_start, b_end, younger) |>
  nest() |>
  mutate(icc = map(data, \(d){
    rma(d$est, d$var) |>
      summary() |>
      coef()
  })) |>
  select(-data) |>
  unnest(icc)

bc_boot_age_early_summ |> ggplot(aes(x = b_start, color = as.character(b_end), y = estimate, ymin = ci.lb, ymax = ci.ub)) +facet_wrap(~younger)+
  geom_pointrange(position = position_dodge(width = .25))
```
we get the same picture -- baseline-correction using a long baseline (roughly as long as the post accuracy window) is ~fine (but doesn't show benefits), baselne correcting on a shorter window just gives you an extra noisy accuracy estimate. 


# Validity -- CDI correlations

Difference measures are going to be noisier than there components (variances add, after all), but do the baseline-corrected accuracies better represent children's word knowledge? 

```{r, eval=F}

source("cl_helper.R")

d_aoi <- readRDS("d_aoi.Rds")

cdi_data <- readRDS("cdi.rds")

do_cdi <- function(data, indices) {
  summ <- data |>
    slice(indices) |>
    left_join(cdi_data) |>
    ungroup() |>
    summarise(
      cor_comp = ifelse(sum(!is.na(comp) & !is.na(mean_var)) > 2, cor.test(mean_var, comp)$estimate, as.numeric(NA)),
      cor_prod = ifelse(sum(!is.na(prod) & !is.na(mean_var)) > 2, cor.test(mean_var, prod)$estimate, as.numeric(NA)),
      cor_age = ifelse(sum(!is.na(age) & !is.na(mean_var)) > 2, cor.test(mean_var, age)$estimate, as.numeric(NA))
    )
  cors <- c(summ$cor_comp[1], summ$cor_prod[1], summ$cor_age[1])
  names(cors) <- c("cor_comp", "cor_prod", "cor_age")

  return(cors)
}

boot_cdi <- function(data) {
  data |>
    group_by(dataset_name) |>
    nest() |>
    mutate(corr = map(data, \(d) {
      b <- boot::boot(d, do_cdi, 2000)
      if (is.na(b$t0[1])) {
        comp_lower <- NA
        comp_upper <- NA
      } else {
        ci_comp <- boot::boot.ci(b, index = 1, type = "basic")
        comp_lower <- ci_comp$basic[4]
        comp_upper <- ci_comp$basic[5]
      }
      if (is.na(b$t0[2])) {
        prod_lower <- NA
        prod_upper <- NA
      } else {
        ci_prod <- boot::boot.ci(b, index = 2, type = "basic")
        prod_lower <- ci_prod$basic[4]
        prod_upper <- ci_prod$basic[5]
      }
      if (is.na(b$t0[3])) {
        age_lower <- NA
        age_upper <- NA
      } else {
        ci_age <- boot::boot.ci(b, index = 3, type = "basic")
        age_lower <- ci_age$basic[4]
        age_upper <- ci_age$basic[5]
      }
      tibble(
        comp_est = b$t0[1], comp_lower = comp_lower, comp_upper = comp_upper,
        prod_est = b$t0[2], prod_lower = prod_lower, prod_upper = prod_upper,
        age_est = b$t0[3], age_lower = age_lower, age_upper = age_upper,
      )
    })) |>
    select(-data) |>
    unnest(corr)
}

bc_acc_cdi <- function(b_start, b_end, t_start, t_end) {
  # get trials with some baseline
  baseline_lengths <- d_aoi |>
    group_by(dataset_name, trial_id) |>
    summarise(t_min = min(t_norm))

  # get baseline corrected accuracies for all trials with ANY baseline info
  d_aoi |>
    left_join(baseline_lengths) |>
    filter(t_min < 0) |>
    group_by(dataset_name, dataset_id, administration_id, target_label, trial_id) |>
    summarise(
      window_accuracy = mean(correct[t_norm >= t_start & t_norm <= t_end],
        na.rm = TRUE
      ),
      baseline_accuracy = mean(correct[t_norm >= b_start & t_norm <= b_end],
        na.rm = TRUE
      ),
      bc_accuracy = window_accuracy - baseline_accuracy
    ) |>
    filter(!is.na(bc_accuracy)) |>
    group_by(dataset_name, administration_id) |>
    summarize(mean_var = mean(bc_accuracy, na.rm = T)) |>
    boot_cdi()
}


cluster <- new_cluster(16)
cluster_library(cluster, "dplyr")
cluster_library(cluster, "stringr")
cluster_library(cluster, "purrr")
cluster_library(cluster, "tidyr")
cluster_library(cluster, "stats")
cluster_library(cluster, "tibble")
cluster_copy(cluster, "do_cdi")
cluster_copy(cluster, "d_aoi")
cluster_copy(cluster, "cdi_data")
cluster_copy(cluster, "boot_cdi")
cluster_copy(cluster, "acc_cdi")
cluster_copy(cluster, "bc_acc_cdi")

bc_acc_params <- expand_grid(
  t_start = 500,
  t_end = c(4000),
  b_start = seq(-4000, -1000, 1000),
  b_end = c(-500, 0),
)

bc_accs_boot_cdi <- bc_acc_params |>
  partition(cluster) |>
  mutate(cdi = pmap(list(b_start, b_end, t_start, t_end), \(b_s, b_e, t_s, t_e) bc_acc_cdi(b_s, b_e, t_s, t_e))) |>
  collect() |>
  unnest(cdi)

saveRDS(bc_accs_boot_cdi, here("cached_intermediates", "7_bc_accs_kid_cdi.rds"))
```


```{r}
no_bc_accs_kid_cdi <- readRDS(here("cached_intermediates", "3_accs_kid_cdi.rds")) |> filter(t_start==500, t_end==4000)

bc_accs_kid_cdi <- readRDS(here("cached_intermediates", "7_bc_accs_kid_cdi.rds")) |>bind_rows(no_bc_accs_kid_cdi) |> 
  mutate(b_start=ifelse(is.na(b_start), "none", as.character(b_start)))

library(metafor)

  baseline_lengths <- d_aoi |>
    group_by(dataset_name) |>
    summarise(t_min = min(t_norm))
  
bc_accs_kid_cdi_summ <-  bc_accs_kid_cdi |>
  left_join(baseline_lengths) |> filter(t_min< 0) |> 
  mutate(
    comp_stdev = (comp_upper - comp_lower) / (1.96 * 2),
    comp_var = comp_stdev**2,
    prod_stdev = (prod_upper - prod_lower) / (1.96 * 2),
    prod_var = prod_stdev**2,
    age_stdev = (age_upper - age_lower) / (1.96 * 2),
    age_var = age_stdev**2
  ) |>
  group_by(t_start, t_end, b_start, b_end) |>
  nest() |>
  mutate(comp= map(data, \(d){
    rma(d$comp_est, d$comp_var) |>
      summary() |>
      coef()
  }),
  prod= map(data, \(d){
    rma(d$prod_est, d$prod_var) |>
      summary() |>
      coef()
  }),
  age= map(data, \(d){
    rma(d$age_est, d$age_var) |>
      summary() |>
      coef()
  })) |>
  select(-data) |>
  unnest(c(comp, prod, age), names_sep="_")

  
  bc_accs_kid_cdi_summ_early <-  bc_accs_kid_cdi |>
    left_join(baseline_lengths) |> filter(t_min< -3000) |> 
  mutate(
    comp_stdev = (comp_upper - comp_lower) / (1.96 * 2),
    comp_var = comp_stdev**2,
    prod_stdev = (prod_upper - prod_lower) / (1.96 * 2),
    prod_var = prod_stdev**2,
    age_stdev = (age_upper - age_lower) / (1.96 * 2),
    age_var = age_stdev**2
  ) |>
  group_by(t_start, t_end, b_start, b_end) |>
  nest() |>
  mutate(comp= map(data, \(d){
    rma(d$comp_est, d$comp_var) |>
      summary() |>
      coef()
  }),
  prod= map(data, \(d){
    rma(d$prod_est, d$prod_var) |>
      summary() |>
      coef()
  }),
  age= map(data, \(d){
    rma(d$age_est, d$age_var) |>
      summary() |>
      coef()
  })) |>
  select(-data) |>
  unnest(c(comp, prod, age), names_sep="_")
```

First we can look at the correlation with production. 

For all datasets
```{r}
bc_accs_kid_cdi_summ |> ggplot(aes(x = b_start, y = prod_estimate, ymin=prod_ci.lb, ymax=prod_ci.ub, color=as.character(b_end))) +geom_pointrange(position=position_dodge(width=.5))+coord_flip()
```


For datasets individually
```{r}
bc_accs_kid_cdi |> left_join(baseline_lengths) |> filter(t_min< 0) |> filter(!is.na(prod_est)) |>  ggplot(aes(x = b_start, y = prod_est, ymin=prod_lower, ymax=prod_upper,  col=as.character(b_end))) +
  geom_pointrange() +
  geom_hline(yintercept=0)+
  coord_flip() +
  theme(legend.position = "none") +
  facet_wrap(~dataset_name)
```


For only the "early" datasets (with data from 3 seconds before onset)
```{r}
bc_accs_kid_cdi_summ_early |> ggplot(aes(x = b_start, y = prod_estimate, ymin=prod_ci.lb, ymax=prod_ci.ub, color=as.character(b_end))) +geom_pointrange(position=position_dodge(width=.5))+coord_flip()
```
well, no benefit on the production data, and some weak signs of worseness, even when there is a lot of baseline. 

what about with comprehension?

across all datasets

```{r}
bc_accs_kid_cdi_summ |> ggplot(aes(x = b_start, y = comp_estimate, ymin=comp_ci.lb, ymax=comp_ci.ub, color=as.character(b_end))) +geom_pointrange(position=position_dodge(width=.5))+coord_flip()
```

for individual datasets

```{r}
bc_accs_kid_cdi |> left_join(baseline_lengths) |> filter(t_min< 0) |> filter(!is.na(comp_est)) |>  ggplot(aes(x = b_start, y = comp_est, ymin=comp_lower, ymax=comp_upper,  col=as.character(b_end))) +
  geom_pointrange() +
  geom_hline(yintercept=0)+
  coord_flip() +
  theme(legend.position = "none") +
  facet_wrap(~dataset_name)
```
for the early datasets

```{r}
bc_accs_kid_cdi_summ_early |> ggplot(aes(x = b_start, y = comp_estimate, ymin=comp_ci.lb, ymax=comp_ci.ub, color=as.character(b_end))) +geom_pointrange(position=position_dodge(width=.5))+coord_flip()
```
again, no evidence of benefit to baseline correcting

correlation with age 

```{r}
bc_accs_kid_cdi_summ |> ggplot(aes(x = b_start, y = age_estimate, ymin=age_ci.lb, ymax=age_ci.ub, color=as.character(b_end))) +geom_pointrange(position=position_dodge(width=.5))+coord_flip()


bc_accs_kid_cdi |> left_join(baseline_lengths) |> filter(t_min< 0) |> filter(!is.na(age_est)) |>  ggplot(aes(x = b_start, y = age_est, ymin=age_lower, ymax=age_upper,  col=as.character(b_end))) +
  geom_pointrange() +
  geom_hline(yintercept=0)+
  coord_flip() +
  theme(legend.position = "none") +
  facet_wrap(~dataset_name)

bc_accs_kid_cdi_summ_early |> ggplot(aes(x = b_start, y = age_estimate, ymin=age_ci.lb, ymax=age_ci.ub, color=as.character(b_end))) +geom_pointrange(position=position_dodge(width=.5))+coord_flip()
```
baseline correcting doesn't change the extent of the "older children know more words" finding

# Test retest validity 

```{r, eval=F}
source("cl_helper.R")

d_aoi <- readRDS("d_aoi.Rds")
library(tibble)
library(multidplyr)

admins <- d_aoi |>
  select(dataset_name, subject_id, administration_id, age) |>
  distinct()
repeated <- admins |>
  group_by(dataset_name, subject_id) |>
  tally() |>
  filter(n > 1)

repeated_subjects <- admins |> inner_join(repeated)

pairs <- repeated_subjects |>
  group_by(dataset_name, subject_id) |>
  mutate(
    forward_age = lead(age),
    forward_diff = forward_age - age,
    test_num = case_when(
      forward_diff < 1.5 ~ 1,
    ),
    mean_age = case_when(
      test_num == 1 ~ (age + forward_age) / 2,
    ),
    second_admin = case_when(
      test_num == 1 ~ lead(administration_id)
    )
  ) |>
  filter(!is.na(test_num)) |>
  rename(first_admin = administration_id) |>
  select(-n, -age) |>
  left_join(repeated_subjects |> select(-age, -n), by = c("dataset_name", "subject_id", "second_admin" = "administration_id")) |>
  ungroup() |>
  mutate(pair_number = row_number()) |>
  select(-forward_age, -forward_diff, -test_num)

pairs_long <- pairs |> pivot_longer(c("first_admin", "second_admin"), names_to = "session_num", values_to = "administration_id")

pairs_aoi_data <- pairs_long |> left_join(d_aoi)


test_retest_corr <- function(data, indices) {
  summ <- data |>
    slice(indices) |>
    summarise(cor_test_retest = ifelse(sum(!is.na(first_admin) & !is.na(second_admin)) > 2, cor.test(first_admin, second_admin)$estimate, NA))
  return(summ$cor_test_retest[1])
}

boot_test_retest <- function(data) {
  data |>
    select(-administration_id) |>
    pivot_wider(names_from = session_num, values_from = mean_var) |>
    group_by(dataset_name) |>
    nest() |>
    # head(1) |>
    mutate(corr = map(data, \(d) {
      b <- boot::boot(d, test_retest_corr, 2000)
      ci <- boot::boot.ci(b, type = "basic")
      print(ci)
      tibble(est = b$t0, lower = ci$basic[4], upper = ci$basic[5])
    })) |>
    select(-data) |>
    unnest(corr)
}

bc_acc_test_retest <- function(b_start, b_end, t_start, t_end) {
  print(paste(t_start, t_end))

  baseline_lengths <- pairs_aoi_data |>
    group_by(dataset_name, trial_id) |>
    summarise(t_min = min(t_norm))

  pairs_aoi_data |>
    left_join(baseline_lengths) |>
    filter(t_min < 0) |>
    group_by(administration_id, dataset_name, subject_id, pair_number, session_num, target_label, trial_id) |>
    summarise(
      window_accuracy = mean(correct[t_norm >= t_start & t_norm <= t_end],
        na.rm = TRUE
      ),
      baseline_accuracy = mean(correct[t_norm >= b_start & t_norm <= b_end],
        na.rm = TRUE
      ),
      bc_accuracy = window_accuracy - baseline_accuracy,
      .groups = "drop"
    ) |>
    filter(!is.na(bc_accuracy)) |>
    group_by(administration_id, dataset_name, subject_id, pair_number, session_num) |>
    summarize(mean_var = mean(bc_accuracy, na.rm = T), .groups = "drop") |>
    boot_test_retest()
}

library(multidplyr)
library(boot)
cluster <- new_cluster(16)
cluster_library(cluster, "dplyr")
cluster_library(cluster, "stringr")
cluster_library(cluster, "purrr")
cluster_library(cluster, "tidyr")
cluster_library(cluster, "stats")
cluster_library(cluster, "tibble")
cluster_library(cluster, "boot")

cluster_copy(cluster, "test_retest_corr")
cluster_copy(cluster, "boot_test_retest")

cluster_copy(cluster, "pairs_aoi_data")
cluster_copy(cluster, "acc_test_retest")
cluster_copy(cluster, "bc_acc_test_retest")


bc_acc_params <- expand_grid(
  t_start = 500,
  t_end = c(4000),
  b_start = seq(-4000, -1000, 1000),
  b_end = c(-500, 0),
)

bc_accs_boot_test_retest <- bc_acc_params |>
  partition(cluster) |>
  # head(2) |>
  mutate(corr = pmap(list(b_start, b_end, t_start, t_end), \(b_s, b_e, t_s, t_e) bc_acc_test_retest(b_s, b_e, t_s, t_e))) |>
  collect() |>
  unnest(corr)

saveRDS(bc_accs_boot_test_retest, here("cached_intermediates", "7_bc_accs_boot_kid_test_retest.rds"))

```

```{r}
no_bc_accs_kid_test_retest <- readRDS(here("cached_intermediates", "3_accs_boot_kid_test_retest.rds")) |> filter(t_start==500, t_end==4000)

bc_accs_kid_test_retest <- readRDS(here("cached_intermediates", "7_bc_accs_boot_kid_test_retest.rds")) |> bind_rows(no_bc_accs_kid_test_retest) |> 
  mutate(b_start=ifelse(is.na(b_start), "none", as.character(b_start)))

library(metafor)

  baseline_lengths <- d_aoi |>
    group_by(dataset_name) |>
    summarise(t_min = min(t_norm))

bc_accs_kid_test_retest_summ <-  bc_accs_kid_test_retest |>
    left_join(baseline_lengths) |> filter(t_min< 0) |> 
  mutate(
    stdev = (upper - lower) / (1.96 * 2),
    var = stdev**2,
  ) |>
  group_by(b_start, b_end) |>
  nest() |>
  mutate(corr= map(data, \(d){
    rma(d$est, d$var) |>
      summary() |>
      coef()
  })) |> 
  unnest(corr)
  

bc_accs_kid_test_retest_summ_early <-  bc_accs_kid_test_retest |>
    left_join(baseline_lengths) |> filter(t_min< -3000) |> 
  mutate(
    stdev = (upper - lower) / (1.96 * 2),
    var = stdev**2,
  ) |>
  group_by(b_start, b_end) |>
  nest() |>
  mutate(corr= map(data, \(d){
    rma(d$est, d$var) |>
      summary() |>
      coef()
  })) |> 
  unnest(corr)
```

test-retest for each of the datasets with test-retest data 
```{r}
bc_accs_kid_test_retest |> ggplot(aes(x=b_start, y=est, ymin=lower, ymax=upper, color=as.character(b_end)))+geom_pointrange(position = position_dodge(width=.5))+facet_wrap(~dataset_name)
```
test-retest is somewhat better for long baselines for potter_remix (which does have a long baseline window); no or anti- benefit in other datasets. 

```{r}
bc_accs_kid_test_retest_summ |> ggplot(aes(x=b_start, y=estimate, ymin=ci.lb, ymax=ci.ub, color=as.character(b_end)))+geom_pointrange(position = position_dodge(width=.5))
```



# Summary

Tl:dr; don't baseline correct. 

If you insist on baseline correcting, you want to use a really long window (2 seconds+), and it probably still won't help, but it probably won't do much harm. There might be trade-offs between reliability and validity, we only have one dataset with both repeated measurements and a long pre-window. 

There's still the separate question of how to incorporate children's looking biases into regression models to better account for item variability. (either just through mixed effects, or through mixed effects + covariate?)


<!--CDI trial level (deprecated)

```{r, eval=F}
do_cdi_bc_acc <- function(data, indices) {
  summ <- data |>
    slice(indices) |>
    group_by(administration_id) |>
    summarize(mean_var = mean(bc_accuracy, na.rm = T)) |>
    left_join(cdi_data) |>
    ungroup() |>
    summarise(
      cor_comp = ifelse(sum(!is.na(comp) & !is.na(mean_var)) > 2, cor.test(mean_var, comp)$estimate, as.numeric(NA)),
      cor_prod = ifelse(sum(!is.na(prod) & !is.na(mean_var)) > 2, cor.test(mean_var, prod)$estimate, as.numeric(NA)),
      cor_age = ifelse(sum(!is.na(age) & !is.na(mean_var)) > 2, cor.test(mean_var, age)$estimate, as.numeric(NA))
    )
  cors <- c(summ$cor_comp[1], summ$cor_prod[1], summ$cor_age[1])
  names(cors) <- c("cor_comp", "cor_prod", "cor_age")

  return(cors)
}

bc_acc_cdi <- function(b_start, b_end, t_start, t_end) {
  # get trials with some baseline
  baseline_lengths <- d_aoi |>
    group_by(dataset_name, trial_id) |>
    summarise(t_min = min(t_norm))

  # get baseline corrected accuracies for all trials with ANY baseline info
  df <- d_aoi |>
    left_join(baseline_lengths) |>
    filter(t_min < 0) |>
    group_by(dataset_name, dataset_id, administration_id, target_label, trial_id) |>
    summarise(
      window_accuracy = mean(correct[t_norm >= t_start & t_norm <= t_end],
        na.rm = TRUE
      ),
      baseline_accuracy = mean(correct[t_norm >= b_start & t_norm <= b_end],
        na.rm = TRUE
      ),
      bc_accuracy = window_accuracy - baseline_accuracy
    ) |>
    filter(!is.na(bc_accuracy)) |>
    group_by(dataset_id, dataset_name, administration_id, target_label)

  # compute ICCs
  df |>
    group_by(dataset_name) |>
    nest() |>
    mutate(corr = map(data, \(d) {
      b <- boot::boot(d, do_cdi_bc_acc, 2000)
      if (is.na(b$t0[1])) {
        comp_lower <- NA
        comp_upper <- NA
      } else {
        ci_comp <- boot::boot.ci(b, index = 1, type = "basic")
        comp_lower <- ci_comp$basic[4]
        comp_upper <- ci_comp$basic[5]
      }
      if (is.na(b$t0[2])) {
        prod_lower <- NA
        prod_upper <- NA
      } else {
        ci_prod <- boot::boot.ci(b, index = 2, type = "basic")
        prod_lower <- ci_prod$basic[4]
        prod_upper <- ci_prod$basic[5]
      }
      if (is.na(b$t0[3])) {
        age_lower <- NA
        age_upper <- NA
      } else {
        ci_age <- boot::boot.ci(b, index = 3, type = "basic")
        age_lower <- ci_age$basic[4]
        age_upper <- ci_age$basic[5]
      }
      tibble(
        comp_est = b$t0[1], comp_lower = comp_lower, comp_upper = comp_upper,
        prod_est = b$t0[2], prod_lower = prod_lower, prod_upper = prod_upper,
        age_est = b$t0[3], age_lower = age_lower, age_upper = age_upper,
      )
    })) |>
    select(-data) |>
    unnest(corr)
}


cluster <- new_cluster(16)
cluster_library(cluster, "dplyr")
cluster_library(cluster, "stringr")
cluster_library(cluster, "purrr")
cluster_library(cluster, "tidyr")
cluster_library(cluster, "stats")
cluster_library(cluster, "tibble")
cluster_copy(cluster, "do_cdi_bc_acc")
cluster_copy(cluster, "d_aoi")
cluster_copy(cluster, "cdi_data")
cluster_copy(cluster, "bc_acc_cdi")

bc_acc_params <- expand_grid(
  t_start = 500,
  t_end = c(4000),
  b_start = seq(-4000, -1000, 1000),
  b_end = c(-500, 0),
)

bc_accs_boot_cdi <- bc_acc_params |>
  partition(cluster) |>
  mutate(cdi = pmap(list(b_start, b_end, t_start, t_end), \(b_s, b_e, t_s, t_e) bc_acc_cdi(b_s, b_e, t_s, t_e))) |>
  collect() |>
  unnest(cdi)

saveRDS(bc_accs_boot_cdi, "7_bc_accs_boot_cdi.rds")



```

```{r, eval=F}
no_bc_accs_boot <- readRDS(here("cached_intermediates", "3_accs_boot_cdi.rds")) |> filter(t_start==500, t_end==4000)

bc_accs_boot_cdi <- readRDS(here("cached_intermediates", "7_bc_accs_boot_cdi.rds")) |>bind_rows(no_bc_accs_boot) |> 
  mutate(b_start=ifelse(is.na(b_start), "none", as.character(b_start)))

library(metafor)

  baseline_lengths <- d_aoi |>
    group_by(dataset_name) |>
    summarise(t_min = min(t_norm))
  
bc_accs_boot_cdi_summ <-  bc_accs_boot_cdi |>
  left_join(baseline_lengths) |> filter(t_min< 0) |> 
  mutate(
    comp_stdev = (comp_upper - comp_lower) / (1.96 * 2),
    comp_var = comp_stdev**2,
    prod_stdev = (prod_upper - prod_lower) / (1.96 * 2),
    prod_var = prod_stdev**2,
    age_stdev = (age_upper - age_lower) / (1.96 * 2),
    age_var = age_stdev**2
  ) |>
  group_by(t_start, t_end, b_start, b_end) |>
  nest() |>
  mutate(comp= map(data, \(d){
    rma(d$comp_est, d$comp_var) |>
      summary() |>
      coef()
  }),
  prod= map(data, \(d){
    rma(d$prod_est, d$prod_var) |>
      summary() |>
      coef()
  }),
  age= map(data, \(d){
    rma(d$age_est, d$age_var) |>
      summary() |>
      coef()
  })) |>
  select(-data) |>
  unnest(c(comp, prod, age), names_sep="_")

  
  bc_accs_boot_cdi_summ_early <-  bc_accs_boot_cdi |>
    left_join(baseline_lengths) |> filter(t_min< -3000) |> 
  mutate(
    comp_stdev = (comp_upper - comp_lower) / (1.96 * 2),
    comp_var = comp_stdev**2,
    prod_stdev = (prod_upper - prod_lower) / (1.96 * 2),
    prod_var = prod_stdev**2,
    age_stdev = (age_upper - age_lower) / (1.96 * 2),
    age_var = age_stdev**2
  ) |>
  group_by(t_start, t_end, b_start, b_end) |>
  nest() |>
  mutate(comp= map(data, \(d){
    rma(d$comp_est, d$comp_var) |>
      summary() |>
      coef()
  }),
  prod= map(data, \(d){
    rma(d$prod_est, d$prod_var) |>
      summary() |>
      coef()
  }),
  age= map(data, \(d){
    rma(d$age_est, d$age_var) |>
      summary() |>
      coef()
  })) |>
  select(-data) |>
  unnest(c(comp, prod, age), names_sep="_")
```
we expect correlations with production to be positive for accuracy data

```{r, eval=F}
bc_accs_boot_cdi_summ |> ggplot(aes(x = b_start, y = prod_estimate, ymin=prod_ci.lb, ymax=prod_ci.ub, color=as.character(b_end))) +geom_pointrange(position=position_dodge(width=.5))+coord_flip()


bc_accs_boot_cdi |> left_join(baseline_lengths) |> filter(t_min< 0) |> filter(!is.na(prod_est)) |>  ggplot(aes(x = b_start, y = prod_est, ymin=prod_lower, ymax=prod_upper,  col=as.character(b_end))) +
  geom_pointrange() +
  geom_hline(yintercept=0)+
  coord_flip() +
  theme(legend.position = "none") +
  facet_wrap(~dataset_name)


bc_accs_boot_cdi_summ_early |> ggplot(aes(x = b_start, y = prod_estimate, ymin=prod_ci.lb, ymax=prod_ci.ub, color=as.character(b_end))) +geom_pointrange(position=position_dodge(width=.5))+coord_flip()
```
well, no benefit on the production data, and some weak signs of worseness.

correlation with comprehension

```{r, eval=F}
bc_accs_boot_cdi_summ |> ggplot(aes(x = b_start, y = comp_estimate, ymin=comp_ci.lb, ymax=comp_ci.ub, color=as.character(b_end))) +geom_pointrange(position=position_dodge(width=.5))+coord_flip()


bc_accs_boot_cdi |> left_join(baseline_lengths) |> filter(t_min< 0) |> filter(!is.na(comp_est)) |>  ggplot(aes(x = b_start, y = comp_est, ymin=comp_lower, ymax=comp_upper,  col=as.character(b_end))) +
  geom_pointrange() +
  geom_hline(yintercept=0)+
  coord_flip() +
  theme(legend.position = "none") +
  facet_wrap(~dataset_name)

bc_accs_boot_cdi_summ_early |> ggplot(aes(x = b_start, y = comp_estimate, ymin=comp_ci.lb, ymax=comp_ci.ub, color=as.character(b_end))) +geom_pointrange(position=position_dodge(width=.5))+coord_flip()
```

correlation with age 

```{r, eval=F}
bc_accs_boot_cdi_summ |> ggplot(aes(x = b_start, y = age_estimate, ymin=age_ci.lb, ymax=age_ci.ub, color=as.character(b_end))) +geom_pointrange(position=position_dodge(width=.5))+coord_flip()


bc_accs_boot_cdi |> left_join(baseline_lengths) |> filter(t_min< 0) |> filter(!is.na(age_est)) |>  ggplot(aes(x = b_start, y = age_est, ymin=age_lower, ymax=age_upper,  col=as.character(b_end))) +
  geom_pointrange() +
  geom_hline(yintercept=0)+
  coord_flip() +
  theme(legend.position = "none") +
  facet_wrap(~dataset_name)

bc_accs_boot_cdi_summ_early |> ggplot(aes(x = b_start, y = age_estimate, ymin=age_ci.lb, ymax=age_ci.ub, color=as.character(b_end))) +geom_pointrange(position=position_dodge(width=.5))+coord_flip()
```

# Test retest trial level (deprecated)

```{r, eval=F}
source("cl_helper.R")

d_aoi <- readRDS("d_aoi.Rds")
library(tibble)
library(multidplyr)

cdi_data <- readRDS("cdi.rds")

admins <- d_aoi |>
  select(dataset_name, subject_id, administration_id, age) |>
  distinct()
repeated <- admins |>
  group_by(dataset_name, subject_id) |>
  tally() |>
  filter(n > 1)

repeated_subjects <- admins |> inner_join(repeated)
# identify pairs
# hmm, sometimes we have times with 3+ 1 month apart,
# for now allow all the pairs that result so like 14-15 and 15-16 for the same kid

pairs <- repeated_subjects |>
  group_by(dataset_name, subject_id) |>
  mutate(
    forward_age = lead(age),
    forward_diff = forward_age - age,
    test_num = case_when(
      forward_diff < 1.5 ~ 1,
    ),
    mean_age = case_when(
      test_num == 1 ~ (age + forward_age) / 2,
    ),
    second_admin = case_when(
      test_num == 1 ~ lead(administration_id)
    )
  ) |>
  filter(!is.na(test_num)) |>
  rename(first_admin = administration_id) |>
  select(-n, -age) |>
  left_join(repeated_subjects |> select(-age, -n), by = c("dataset_name", "subject_id", "second_admin" = "administration_id")) |>
  ungroup() |>
  mutate(pair_number = row_number()) |>
  select(-forward_age, -forward_diff, -test_num)

pairs_long <- pairs |> pivot_longer(c("first_admin", "second_admin"), names_to = "session_num", values_to = "administration_id")

pairs_aoi_data <- pairs_long |> left_join(d_aoi)

test_retest_boot <- function(data, indices) {
  summ <- data |>
    slice(indices) |>
    group_by(administration_id, subject_id, pair_number, session_num) |>
    summarize(mean_var = mean(bc_accuracy, na.rm = T), .groups = "drop") |>
    select(-administration_id) |>
    pivot_wider(names_from = session_num, values_from = mean_var) |>
    summarise(cor_test_retest = ifelse(sum(!is.na(first_admin) & !is.na(second_admin)) > 2, cor.test(first_admin, second_admin)$estimate, NA))
  return(summ$cor_test_retest[1])
}


bc_acc_test_retest <- function(b_start, b_end, t_start, t_end) {
  print(paste(t_start, t_end))

  baseline_lengths <- pairs_aoi_data |>
    group_by(dataset_name, trial_id) |>
    summarise(t_min = min(t_norm))

  df <- pairs_aoi_data |>
    left_join(baseline_lengths) |>
    filter(t_min < 0) |>
    group_by(administration_id, dataset_name, subject_id, pair_number, session_num, target_label, trial_id) |>
    summarise(
      window_accuracy = mean(correct[t_norm >= t_start & t_norm <= t_end],
        na.rm = TRUE
      ),
      baseline_accuracy = mean(correct[t_norm >= b_start & t_norm <= b_end],
        na.rm = TRUE
      ),
      bc_accuracy = window_accuracy - baseline_accuracy,
      .groups = "drop"
    ) |>
    filter(!is.na(bc_accuracy))


  # compute ICCs
  df |>
    group_by(dataset_name) |>
    nest() |>
    mutate(corr = map(data, \(d) {
      b <- boot::boot(d, test_retest_boot, 2000)
      ci <- boot::boot.ci(b, type = "basic")
      print(ci)
      tibble(est = b$t0, lower = ci$basic[4], upper = ci$basic[5])
    })) |>
    select(-data) |>
    unnest(corr)
}

bc_acc_params <- expand_grid(
  t_start = 500,
  t_end = c(4000),
  b_start = seq(-4000, -1000, 1000),
  b_end = c(-500, 0),
)
library(multidplyr)
library(boot)
cluster <- new_cluster(16)
cluster_library(cluster, "dplyr")
cluster_library(cluster, "stringr")
cluster_library(cluster, "purrr")
cluster_library(cluster, "tidyr")
cluster_library(cluster, "stats")
cluster_library(cluster, "tibble")
cluster_library(cluster, "boot")

cluster_copy(cluster, "test_retest_boot")
cluster_copy(cluster, "pairs_aoi_data")
cluster_copy(cluster, "cdi_data")
cluster_copy(cluster, "bc_acc_test_retest")

bc_accs_boot_test_retest <- bc_acc_params |>
  partition(cluster) |>
  mutate(corr = pmap(list(b_start, b_end, t_start, t_end), \(b_s, b_e, t_s, t_e) bc_acc_test_retest(b_s, b_e, t_s, t_e))) |>
  collect() |>
  unnest(corr)

saveRDS(bc_accs_boot_test_retest, "bc_accs_boot_test_retest.rds")

```

```{r, eval=F}
no_bc_accs_boot_test_retest <- readRDS(here("cached_intermediates", "3_accs_boot_test_retest.rds")) |> filter(t_start==500, t_end==4000)

bc_accs_boot_test_retest <- readRDS(here("cached_intermediates", "7_bc_accs_boot_test_retest.rds")) |> bind_rows(no_bc_accs_boot_test_retest) |> 
  mutate(b_start=ifelse(is.na(b_start), "none", as.character(b_start)))

library(metafor)

  baseline_lengths <- d_aoi |>
    group_by(dataset_name) |>
    summarise(t_min = min(t_norm))

bc_accs_boot_test_retest_summ <-  bc_accs_boot_test_retest |>
    left_join(baseline_lengths) |> filter(t_min< 0) |> 
  mutate(
    stdev = (upper - lower) / (1.96 * 2),
    var = stdev**2,
  ) |>
  group_by(b_start, b_end) |>
  nest() |>
  mutate(corr= map(data, \(d){
    rma(d$est, d$var) |>
      summary() |>
      coef()
  })) |> 
  unnest(corr)
  

bc_accs_boot_test_retest_summ_early <-  bc_accs_boot_test_retest |>
    left_join(baseline_lengths) |> filter(t_min< -3000) |> 
  mutate(
    stdev = (upper - lower) / (1.96 * 2),
    var = stdev**2,
  ) |>
  group_by(b_start, b_end) |>
  nest() |>
  mutate(corr= map(data, \(d){
    rma(d$est, d$var) |>
      summary() |>
      coef()
  })) |> 
  unnest(corr)
  
bc_accs_boot_test_retest |> ggplot(aes(x=b_start, y=est, ymin=lower, ymax=upper, color=as.character(b_end)))+geom_pointrange(position = position_dodge(width=.5))+facet_wrap(~dataset_name)

bc_accs_boot_test_retest_summ |> ggplot(aes(x=b_start, y=estimate, ymin=ci.lb, ymax=ci.ub, color=as.character(b_end)))+geom_pointrange(position = position_dodge(width=.5))

bc_accs_boot_test_retest_summ_early |> ggplot(aes(x=b_start, y=estimate, ymin=ci.lb, ymax=ci.ub, color=as.character(b_end)))+geom_pointrange(position = position_dodge(width=.5))

```
