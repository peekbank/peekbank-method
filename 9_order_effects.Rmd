---
title: "Order effects"
author: "Hackathon"
date: "2024-08-27"
output: html_document
---

Goal: understand order effects.

```{r}
source(here::here("helper/common.R"))
d_aoi <- readRDS(here("cached_intermediates", "1_d_aoi_distractor.rds"))
```

We want to know about the effects of
* trial order -- adding more trials necessarily means adding *later* trials, so we might care about practice/boredom etc effects
* repeating the same targets
  * same label
  * counterbalanced so what was a target is now a distractor & v.v.
  * could be with just the type/labels that are repeated, or the images
# 1. Data preparation

## 1.1. Data summary

Create d_trial_summary dataframe which contains pre_accuracy and post_accuracy grouped by: dataset_id, dataset_name, administration_id, trial_id, trial_order, age, target_id, target_label, distractor_label.

Note that some datasets have different exemplars of the same labels which should probably (?) be treated as separate, but we don't have distractor id joined on d_aoi here

We also create some new columns (some of these were created previously but I commented them bc they weren't used: 

-   stimulus_pair: groups stimulus by their paired appearance irrespective of which one appeared as target.

-   first_stimulus: Tells which of the stimulus appeared first as target. The procedude could be improved because it differentiates stimulus by ordering them alphabetically.

-   stimulus_pair_instance: tells the time of appearance of each stimulus_pair

-   is_first_stimulus: is a boolean tells if the stimulus is the 1st or 2nd to appear as a target

-   stimulus_pair_target_instance: tells the time of appearance of each pair with a specific stimulus as target.

-   max_stimulus_pair_instance: tells the maximum number of trials repetitions in the dataset

## 1.2. New columns

note that now label_pair / label_pair_instance etc refers to the repetition of that pair of label/types
and that stimulus_pair is now for those *specific* images/exemplars

```{r}
d_trial_summary <- d_aoi %>%
  group_by(
    dataset_id, dataset_name, administration_id, trial_id, trial_order,
    age, target_id, target_label, distractor_label, distractor_id
  ) %>%
  summarise(
    pre_accuracy = mean(correct[t_norm <= 400], na.rm = TRUE),
    post_accuracy = mean(correct[t_norm > 400], na.rm = TRUE)
  ) |>
  filter(!is.na(post_accuracy)) |> 
  # we put in stimulus pair alphabetically because it needs to be in a consistent order
  # so that we can group by the pairing and not by pairing x target
  mutate(label_pair = paste(sort(c(target_label, distractor_label)), collapse = "_")) %>%
    mutate(stimulus_pair = paste(sort(c(target_id, distractor_id)), collapse = "_")) %>%
  # mutate(first_stimulus = sort(c(target_label, distractor_label))[1]) %>%
  arrange(dataset_id, administration_id, trial_order) %>%
  group_by(dataset_id, administration_id, stimulus_pair) %>%
  mutate(stimulus_pair_instance = seq(1, n())) %>% # stimulus_pair_instance is how many times you've seen this pair of stimuli
    group_by(dataset_id, administration_id, label_pair) %>%
  mutate(label_pair_instance = seq(1, n())) %>% 
  group_by(dataset_id, administration_id, stimulus_pair, target_label) %>%
  mutate(stimulus_pair_target_instance = seq(1, n())) %>% # sttarget instance is how many times you've seen this pair of stimuli with this target as a target
    group_by(dataset_id, administration_id, label_pair, target_label) %>%
  mutate(label_pair_target_instance = seq(1, n())) %>% # sttarget instance is how many times you've seen this pair of stimuli with this target as a target
  group_by(dataset_name, stimulus_pair) |> 
  mutate(max_stimulus_pair_instance=max(stimulus_pair_instance)) |> 
  group_by(dataset_name, label_pair) |> 
    mutate(max_label_pair_instance=max(label_pair_instance)) |> 
  group_by(dataset_name, stimulus_pair, target_label) |> 
  mutate(max_stimulus_pair_target_instance=max(stimulus_pair_target_instance)) |> 
  ungroup() 
```

trying to figure out what the distributions look like here!

```{r}
for_plot <- d_trial_summary |>
  select(dataset_name, target_label, distractor_label, stimulus_pair, label_pair, stimulus_pair_target_instance, stimulus_pair_target_instance, label_pair_instance, stimulus_pair_instance,
         max_stimulus_pair_instance, max_label_pair_instance, max_stimulus_pair_target_instance) |> distinct()
```

I think garrison_bergelson is the "yours or mine" paper, so it has a lot of labels that aren't seen by lots of kids? Filtering it out from the aggregate

```{r}
for_plot |> select(dataset_name, label_pair, max_label_pair_instance) |> distinct() |> ggplot(aes(x = max_label_pair_instance, fill = dataset_name)) +
  geom_histogram()+facet_wrap(~dataset_name, scales="free_y")+theme(legend.position="none")

for_plot |> filter(!dataset_name=="garrison_bergelson_2020") |> select(dataset_name, label_pair, max_label_pair_instance) |> distinct() |> ggplot(aes(x = max_label_pair_instance, fill = dataset_name)) +
  geom_histogram()+theme(legend.position = "none")
```
A number of label-pairs shown only once; but also lots that show up twice, 4 and 8 times are also pretty prevelent. 

Looking at stimulus pairs (images)
```{r}
for_plot |> select(dataset_name, stimulus_pair, max_stimulus_pair_instance) |> distinct() |> ggplot(aes(x = max_stimulus_pair_instance, fill = dataset_name)) +
  geom_histogram()+facet_wrap(~dataset_name, scales="free_y")+theme(legend.position="none")

for_plot |> filter(!dataset_name=="garrison_bergelson_2020") |> select(dataset_name, stimulus_pair, max_stimulus_pair_instance) |> distinct() |> ggplot(aes(x = max_stimulus_pair_instance, fill = dataset_name)) +
  geom_histogram()+theme(legend.position = "none")
```
some shift because for same datasets the label repetitions are with different stimuli!


```{r}
for_plot |> select(dataset_name, target_label, stimulus_pair, max_stimulus_pair_target_instance) |> distinct() |> ggplot(aes(x = max_stimulus_pair_target_instance, fill = dataset_name)) +
  geom_histogram()+facet_wrap(~dataset_name, scales="free_y")+theme(legend.position="none")

for_plot |> filter(!dataset_name=="garrison_bergelson_2020") |> select(dataset_name,target_label, stimulus_pair, max_stimulus_pair_target_instance) |> distinct() |> ggplot(aes(x = max_stimulus_pair_target_instance, fill = dataset_name)) +
  geom_histogram()+theme(legend.position = "none")
```
mostly there aren't direct repeats, but some datasets do!

```{r}
for_plot |>
  select(dataset_name, label_pair) |>
  unique() |>
  group_by(dataset_name) |>
  tally() |>
  arrange(desc(n))

# between 2 and 17 pairs of nouns per dataset (not counting garrison-bergelson's 122) 
```

one question is which datasets contain what kinds of repetition

we want to know for each dataset 
* what label pairs are there
* how many stimulus pairs go with that item pair
* how many targets go with that item pair
* how many admins go with that item pair
* max reps for that label pair

```{r}
 d_trial_summary |> group_by(label_pair, dataset_name, max_label_pair_instance) |> 
  summarize(stimulus_pairs=unique(stimulus_pair) |> length(),
            target_labels = unique(target_label) |> length(),
            admins = unique(administration_id) |> length()) |> 
  filter(max_label_pair_instance>1) |> 
  arrange(dataset_name) |> View()
```

types of things we want to do comparison of:
* initial trial
* different-image different-target
* same-image different-target
* different-image same-target 
* same-image same-target

so, we could label by 
* # of times label pair has occurred
* # of times stimulus pair has occurred
* # of times target-label has occurred
* # of times target-label x stimulus has occurred

which datasets have multiple stimuli with the same label-pair (and label)?

```{r}
d_trial_summary |>   filter(max_label_pair_instance>1) |> group_by(label_pair, dataset_name) |> summarize(stimulus_pairs=unique(stimulus_pair) |> length())|> filter(stimulus_pairs>1) |> ungroup() |> distinct(dataset_name)

```
which datasets have repeats of the same stimulus pair + target label?

```{r}
d_trial_summary |> group_by(stimulus_pair, dataset_name) |> filter(max_stimulus_pair_target_instance>1) |> ungroup() |> distinct(dataset_name)

```
which datasets have repeats of the same stimulus pair + switch target label?

```{r}
d_trial_summary |> group_by(stimulus_pair, dataset_name) |> filter(max_stimulus_pair_instance>1) |> summarize(targets=unique(target_label) |> length()) |>  ungroup() |> filter(targets>1) |>  distinct(dataset_name)

```
are there datasets that have all of these? 

```{r}
all_types <- d_trial_summary |>   filter(max_label_pair_instance>1) |> group_by(label_pair, dataset_name) |> summarize(stimulus_pairs=unique(stimulus_pair) |> length(),                                                                                                  targets=unique(target_label) |> length())|> filter(stimulus_pairs>1, targets>1) |> ungroup()|> inner_join(d_trial_summary |> group_by(label_pair, stimulus_pair, dataset_name) |> filter(max_stimulus_pair_target_instance>1)) |> ungroup() |> distinct(dataset_name)

all_types
```

# Play

let's start by looking just at these datasets and doing some time course visualization by what kids have seen before

(label-pair) (target-label) (stimulus-pair) (target+stimulus)

(looks like sander-montant doesn't actually have different stim for the same target in the same administration)
```{r}
test <- d_aoi |> inner_join(all_types) |> left_join(d_trial_summary) |> 
  filter(max_stimulus_pair_target_instance>1) |> filter(dataset_name!="sander-montant_2022")
```

```{r}
by_first <- test |> mutate(
  first_label = label_pair_instance==1,
  first_stimulus= stimulus_pair_instance==1,
  first_target = label_pair_target_instance==1,
  first_stim_target = stimulus_pair_target_instance ==1
) |> 
  mutate(type=case_when(
  first_label ~ "first_label",
  first_stimulus ~ "first_stimulus",
  first_stim_target ~ "first_stim_target",
  T ~ "repeat_stim_target"
  ))

  by_first |> group_by(dataset_name, type, t_norm) |> 
  summarize(correct=mean(correct, na.rm=T)) |>  ggplot(aes(x=t_norm, y=correct, col=type))+geom_smooth(method="gam")+geom_hline(yintercept=.5, lty="dashed")+geom_vline(xintercept=0, lty="dashed")+facet_wrap(~dataset_name)
```
we are interested in when there are things that don't look like "first label" -- 

let's try limiting to the first or second time this *stimulus pair* is displayed
```{r}
early <- test |> filter(stimulus_pair_instance %in% c(1,2)) |> 
  mutate(prev_label=stimulus_pair_instance!=label_pair_instance,
         type=case_when(
           stimulus_pair_instance==1 ~ "first stim",
           stimulus_pair_target_instance==1 ~ "prev distractor",
           T ~ "prev target"
         ))

 early_summ <-  early |> group_by(dataset_name, type, prev_label, t_norm) |> 
  summarize(correct=mean(correct, na.rm=T), n=unique(trial_id) |> length()) 
 
 early_summ |> filter(n>10) |> filter(prev_label==F)|> ggplot(aes(x=t_norm, y=correct, col=str_c(type, prev_label)))+#geom_smooth(method="gam")+
   geom_hline(yintercept=.5, lty="dashed")+geom_vline(xintercept=0, lty="dashed")+facet_wrap(~dataset_name)+geom_line()
 
  early_summ |> filter(n>10) |> filter(prev_label==T)|> ggplot(aes(x=t_norm, y=correct, col=str_c(type, prev_label)))+#geom_smooth(method="gam")+
   geom_hline(yintercept=.5, lty="dashed")+geom_vline(xintercept=0, lty="dashed")+facet_wrap(~dataset_name)+geom_line()
  
  
    early_summ |> filter(n>10) |> filter(type=="first stim")|> ggplot(aes(x=t_norm, y=correct, col=str_c(type, prev_label)))+#geom_smooth(method="gam")+
   geom_hline(yintercept=.5, lty="dashed")+geom_vline(xintercept=0, lty="dashed")+facet_wrap(~dataset_name)+geom_line()
```
this is all confusing how can we deal with it?

* Do we try to look at time course, or do we just use RT / accuracy numbers? 
* Trial order may have an effect (overall familiarity/fatigue), child age/attention may dictate how many trials they even get through...
* We think the effects we're (theoretically) interested in are about whether the stimuli pair has been seen before and if so whether the target was the same previously for child-pragmatics reasons
* but we also want to check that this is at the stimulus-pair level and not the label-pair level 
* we might expect that more distance between same-stimulus trials & especially intervening same-label different-stimulus trials might diminish the effects of interest by weakening the pragmatic assumptions
* we also think that stimulus saliency is a nuisance factor that could be all over the place 

I don't really want to start by throwing it all into a giant model, would be nice to get some viz first!!


what would this model have to look like 

(simplest version)

DV ~ trial_order + first_stimulus + first_target_stimulus + other_label_stimulus + (1 | dataset)

(complex version)

DV ~ trial_order + stimulus_instance + target_stimulus_instance + other_label_instance + trials_since_last_stimulus (all per dataset?)

this still wouldn't account for kid & item random effects

we could do this within each dataset and then meta-analyse? 

<!-- older stuff below here -->

# 2. Repetitions classification

We could focus in trials with stimulus_pair_instance == 1 \| 2 to make it easier to approach. In that case, we should have these combinations

| Stimulus_pair_instance | Stimulus_target_instance |                                                              |
|------------------------|--------------------------|--------------------------------------------------------------|
| 1                      | 1                        | 1st time pair and target are shown                           |
| 2                      | 1                        | 1st time target was shown even though pair was already shown |
| 2                      | 2                        | 2nd time target is shown along with pair                     |


```{r}
repetitions_data <- d_trial_summary %>%
  filter(max_stimulus_pair_instance >= 2) %>% # I keep all datasets with at least 2 repetitions for each pair

  filter(stimulus_pair_instance <= 2) %>% # I keep all pairs with only two pair repetitions.
  # because it means we'll have pairs which were not repeated
  # trials which only repeated pair OR targets which repeated both pair and targets
  # maybe it could be an option to compare repeated pair AND repeated pair and target

  mutate(type_of_instance = as.factor(case_when(
    stimulus_pair_instance == 1 & stimulus_pair_target_instance == 1 ~ "Not repeated",
    stimulus_pair_instance == 2 & stimulus_pair_target_instance == 1 ~ "Repeated pair",
    stimulus_pair_instance == 2 & stimulus_pair_target_instance == 2 ~ "Repeated pair and target"
  )))
```

# 3. Dataset selection

Now that we have the desired trial classification, we need to see which datasets are fit for inclusion (some might have few trials left for some of the types of instances)

One criteria could be to drop datasets with less that 10% of trials of a type of instance and less than 100 trials of a type of instance. These values should be discussed (this is the one implemented here)

Another option could be to drop only specific types of instances which are poorly represented in some datasets. But its a little weird maybe.

bad_n_datasets contains the to-be-dropped datasets

```{r}
repetitions_data_long <- repetitions_data %>%
  select(
    administration_id, age, dataset_name, stimulus_pair_instance,
    stimulus_pair_target_instance, type_of_instance, post_accuracy, pre_accuracy
  ) %>%
  pivot_longer(
    -c(
      administration_id, age, dataset_name, stimulus_pair_instance,
      stimulus_pair_target_instance, type_of_instance
    ),
    values_to = "Accuracy",
    names_to = "Time"
  )

repetitions_data_long_summary <- repetitions_data_long %>%
  group_by(
    dataset_name, stimulus_pair_instance,
    stimulus_pair_target_instance, type_of_instance
  ) %>%
  summarize(n = n()) %>%
  group_by(dataset_name) %>%
  mutate(
    total_trials = sum(n),
    proportion = n / total_trials
  )


repetitions_data_long_summary %>%
  ggplot(aes(x = dataset_name, y = proportion, fill = (type_of_instance))) +
  geom_bar(stat = "identity", position = "stack") +
  geom_text(aes(label = n),
    position = position_stack(vjust = 0.5),
    size = 3, color = "white"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    legend.position = "top"
  ) +
  coord_flip()

# datasets with less than certain proportion of trials for any type of instance
bad_n_datasets <- repetitions_data_long_summary %>%
  filter(proportion <= 0.10 |
    n < 100) |>
  pull(dataset_name)


repetitions_data_long_summary %>%
  filter(!dataset_name %in% bad_n_datasets) %>%
  ggplot(aes(x = dataset_name, y = proportion, fill = (type_of_instance))) +
  geom_bar(stat = "identity", position = "stack") +
  geom_text(aes(label = n),
    position = position_stack(vjust = 0.5),
    size = 3, color = "white"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    legend.position = "top"
  ) +
  coord_flip()
```

# Check accuracy and RT

```{r}
repetitions_data_long |>
  filter(!dataset_name %in% bad_n_datasets) %>% # filtering datasets. |>
  group_by(dataset_name, type_of_instance, administration_id) |>
  filter(Time == "post_accuracy") |>
  summarize(mean_acc = mean(Accuracy, na.rm = T)) |>
  ggplot(aes(x = type_of_instance, y = mean_acc, col = dataset_name)) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .5))+
    facet_wrap(~dataset_name)+theme(legend.position = "none")

```
there might be something here -- we can't really tell and it could be ordering effects if it's not_repeated versus the other two, but there are datasets where it could matter (and thus be worth investigating further for methods paper)

```{r}
rt <- readRDS(here("cached_intermediates", "4_rt_canonical.rds"))

repetitions_data |> 
  filter(!dataset_name %in% bad_n_datasets) |>
  left_join(rt |> filter(shift_type == "D-T") |>  filter(approach=="trad_land", logged=="raw")) |>
  group_by(dataset_name, type_of_instance, administration_id) |>
  summarize(mean_rt = mean(rt, na.rm = T)) |>
  ggplot(aes(x = type_of_instance, y = mean_rt, col = dataset_name)) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .5))+
    facet_wrap(~dataset_name)+theme(legend.position = "none")

```
again, could be sparsity, could be trial order, but seems like there might be something 

```{r}
repetitions_data |>
  filter(!dataset_name %in% bad_n_datasets) %>% # filtering datasets. |>
  mutate(bc_acc=post_accuracy-pre_accuracy) |> #this is a lazy approach to bc_correction
    group_by(dataset_name, type_of_instance, administration_id) |>
  summarize(mean_bc_acc = mean(bc_acc, na.rm = T)) |>
  ggplot(aes(x = type_of_instance, y = mean_bc_acc, col = dataset_name)) +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .5))+
  facet_wrap(~dataset_name)+theme(legend.position = "none")

```


is there an effect of trial order within these categories?

```{r}
repetitions_data |>
  filter(!dataset_name %in% bad_n_datasets) |>
  left_join(rt |> filter(shift_type == "D-T")) |>
  group_by(dataset_name, type_of_instance, administration_id) |>
  ggplot(aes(x = trial_order, y = rt, col = dataset_name)) +
   # facet_wrap(~type_of_instance)+
  geom_smooth(method = "lm")

repetitions_data |>
  filter(!dataset_name %in% bad_n_datasets) %>% # filtering datasets. |>
  group_by(dataset_name, type_of_instance, administration_id) |>
  ggplot(aes(x = trial_order, y = post_accuracy, col = dataset_name)) +
   # facet_wrap(~type_of_instance)+
  geom_smooth(method = "lm") 
```
so, there's a possibility of trial order effects (of unknown size and direction), so we can't really rule out dealing with combinations of that and familiarity effects. 

# 4. Timecourse plots

Data cleaning (sort of...)

```{r}
rep_timecourse <- d_aoi %>%
  filter(!dataset_name %in% bad_n_datasets) %>% # filtering datasets.
  left_join(repetitions_data) %>%
  filter(!is.na(type_of_instance))
```


## 4.1. Timecourse by type of instance

Here I grouped by dataset prior to making the whole average. But maybe administration_id should be considered

```{r, fig.width= 6, fig.height= 6}
rep_timecourse %>%
  # filter(age < 20) %>%
  # filter(age > 17 & age < 20.5) %>%

  group_by(dataset_name, type_of_instance, t_norm) %>% # Group by dataset? by dataset AND subject?
  # group_by(dataset_name,administration_id, type_of_instance, t_norm) %>%      # Group by dataset AND subject?
  summarize(accuracy = mean(correct, na.rm = TRUE)) %>%
  group_by(type_of_instance, t_norm) %>%
  summarize(accuracy = mean(accuracy, na.rm = TRUE)) %>%
  filter(t_norm > -1000, t_norm < 4000) %>%
  ggplot(aes(x = t_norm, y = accuracy, color = type_of_instance)) +
  geom_smooth(method = "gam") +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  geom_vline(xintercept = 400, linetype = "dashed") +
  theme_minimal() +
  theme(legend.position = "bottom")
```


## 4.2. Timecourse by type of instance and dataset

The previous effect is not consistent in all datasets. Should think what to do with that

```{r, fig.width= 6, fig.width= 10}
rep_timecourse %>%
  # filter(age < 20) %>%
  group_by(type_of_instance, t_norm, dataset_name) %>%
  summarize(accuracy = mean(correct, na.rm = TRUE)) %>%
  filter(t_norm > -3000, t_norm < 4000) %>%
  ggplot(aes(x = t_norm, y = accuracy, color = type_of_instance)) +
  geom_smooth(method = "gam") +
  geom_vline(xintercept = 0) +
  geom_vline(xintercept = 400, linetype = "dashed") +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  # coord_cartesian(ylim = c(0.4,0.7))+
  theme_minimal() +
  theme(legend.position = "bottom") +
  facet_wrap(~dataset_name)
```

# 5. Modelling

Started checking a simple model to see the effect between t_norm = 0 and t_norm = 200 to see if there are any differences controlling by dataset and subject

```{r}
rep_timecourse %>%
  filter(t_norm > 0, t_norm < 200) %>%
  group_by(type_of_instance, t_norm, dataset_name, administration_id) %>%
  summarize(accuracy = mean(correct, na.rm = TRUE)) %>%
  # filter(accuracy < .5) %>%
  group_by(dataset_name, administration_id, type_of_instance) %>%
  summarise(accuracy = mean(accuracy)) %>%
  na.omit() %>%
  # lmer(accuracy ~ type_of_instance + (1 | dataset_name), data = .) %>%
  lmer(accuracy ~ type_of_instance + (1 | administration_id) + (1 | dataset_name), data = .) -> model

summary(model)
```

Notes: The included datasets and ages should be checked. Also, the meaning of the observed effects and the way to assess stastical significance



# Old stuff 

## 2.2. Accuracy by repetitions faceted by dataset_name

```{r, fig.width=10, fig.height=10, fig.fullwidth=TRUE}
repetitions_data_long %>%
  filter(!dataset_name %in% bad_n_datasets) %>%
  group_by(dataset_name, stimulus_pair_instance, stimulus_pair_target_instance, type_of_instance, Time) %>%
  summarize(
    mean_accuracy = mean(Accuracy, na.rm = T),
    se_accuracy = sd(Accuracy, na.rm = T) / sqrt(length(Accuracy)),
    n = n()
  ) %>%
  ggplot(aes(
    x = type_of_instance,
    y = mean_accuracy, color = Time
  )) +
  geom_point(size = 2) +
  geom_errorbar(aes(
    ymin = mean_accuracy - se_accuracy,
    ymax = mean_accuracy + se_accuracy
  ), width = 0.2, size = 1) +
  # geom_smooth(method = "lm")+
  facet_wrap(~dataset_name) +
  theme_minimal() +
  theme(legend.position = "bottom")
```
trial number by repeat type

number of types it's been a distractor vs a  number of times its been a target


## 2.3. Accuracy by repetitions in the whole dataset

Standard errors might be a bit underestimated because of the number of rows


```{r}
repetitions_data_long %>%
  filter(!dataset_name %in% bad_n_datasets) %>%
  group_by(dataset_name, administration_id, type_of_instance, Time) %>%
  summarize(
    mean_administration_accuracy = mean(Accuracy, na.rm = T),
    n = n()
  ) %>%
  ungroup() %>%
  mutate(n_in_dataset = n(), .by = c("dataset_name", "type_of_instance", "Time")) %>%
  filter(n_in_dataset > 10) %>%
  group_by(type_of_instance, Time) %>%
  summarise(
    mean_accuracy = mean(mean_administration_accuracy, na.rm = T),
    se_accuracy = sd(mean_administration_accuracy, na.rm = T) / sqrt(length(mean_administration_accuracy)),
    n = n()
  ) %>%
  ggplot(aes(
    x = type_of_instance,
    y = mean_accuracy, color = Time
  )) +
  geom_errorbar(aes(
    ymin = mean_accuracy - se_accuracy,
    ymax = mean_accuracy + se_accuracy
  ), width = 0.3, size = 1) +
  geom_point(aes(fill = Time), size = 5, color = "black", shape = 21) +
  coord_cartesian(ylim = c(0.2, 0.8)) +
  theme_minimal()
```

## 2.5. Accuracy by repetitions and age

Same plot that before, but looking at age differences in children between 12 and 24 months


```{r}
# ADD AGE.

repetitions_data_long %>%
  filter(!dataset_name %in% bad_n_datasets) %>%
  ungroup() %>%
  mutate(n_in_dataset = n(), .by = c("dataset_name", "type_of_instance", "Time")) %>%
  filter(n_in_dataset > 10) %>%
  filter(age >= 12) %>%
  filter(age <= 24) %>%
  mutate(age_bin = factor(cut(age, breaks = 3))) %>%
  mutate(Time = factor(Time, levels = c("pre_accuracy", "post_accuracy"))) %>%
  group_by(administration_id, type_of_instance, Time, age_bin) %>%
  summarize(
    mean_administration_accuracy = mean(Accuracy, na.rm = T),
    n = n()
  ) %>%
  group_by(type_of_instance, Time, age_bin) %>%
  summarise(
    mean_accuracy = mean(mean_administration_accuracy, na.rm = T),
    se_accuracy = sd(mean_administration_accuracy, na.rm = T) / sqrt(length(mean_administration_accuracy)),
    n = n()
  ) %>%
  ggplot(aes(
    x = factor(age_bin),
    y = mean_accuracy, color = type_of_instance
  )) +
  geom_errorbar(aes(
    ymin = mean_accuracy - se_accuracy,
    ymax = mean_accuracy + se_accuracy
  ), width = 0.3, size = 1) +
  geom_point(aes(fill = type_of_instance), size = 5, color = "black", shape = 21) +
  # coord_cartesian(ylim = c(0.4,0.66))+

  theme_minimal() +
  theme(legend.position = "bottom") +
  facet_wrap(~Time)
```










## 3.2. timecourse by type of instance and age


```{r}
filt_rep_data <- repetitions_data %>%
  mutate(n_in_dataset = n(), .by = c("dataset_name", "type_of_instance")) %>%
  filter(n_in_dataset > 10)


rep_timecourse <- d_aoi %>%
  left_join(filt_rep_data) %>%
  filter(!is.na(type_of_instance)) %>%
  # mutate(n_in_dataset = n(), .by = c("dataset_name","type_of_instance", "Time")) %>%
  filter(n_in_dataset > 10) %>%
  filter(age >= 12) %>%
  filter(age <= 24) %>%
  mutate(age_bin = factor(cut(age, breaks = 3)))



# do you look more to target after having seen this target as a target in this stimulus pair before?
rep_timecourse %>%
  group_by(type_of_instance, t_norm, age_bin) %>%
  summarize(accuracy = mean(correct, na.rm = TRUE)) %>%
  filter(t_norm > -3000, t_norm < 4000) %>%
  ggplot(aes(x = t_norm, y = accuracy, color = as.factor(type_of_instance))) +
  geom_smooth(method = "gam") +
  # geom_point()+
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  theme_minimal() +
  facet_wrap(~age_bin)
```


```{r}
options(scipen = 999)

repetitions_data %>%
  filter(!dataset_name %in% bad_n_datasets) %>%
  # filter(age > 16 & age < 18) %>%
  ggplot(aes(x = age, fill = type_of_instance)) +
  geom_histogram()
```

# 4. Stuff for further exploration

We could focus in trials with stimulus_pair_instance == 1 \| 2 to make it easier to approach. In that case, we should have these combinations

| Stimulus_pair_instance | Stimulus_target_instance |                                                              |
|------------------------|--------------------------|--------------------------------------------------------------|
| 1                      | 1                        | 1st time pair and target are shown                           |
| 2                      | 1                        | 1st time target was shown even though pair was already shown |
| 2                      | 2                        | 2nd time target is shown along with pair                     |
| 3                      | 1                        | 1st time target is shown (was distractor 2 times before)
  3                        2                          2st time target is show (was distractor 1 times before)
  3                        3                          3rd time target is show (never was distractor before)
 


```{r}
repetitions_data <- d_trial_summary %>%
  filter(max_stimulus_pair_instance >= 3) %>%
  filter(stimulus_pair_instance <= 3) %>%
  mutate(type_of_instance = case_when(
    stimulus_pair_instance == 1 & stimulus_pair_target_instance == 1 ~ "0 tgt | 0 dist",
    stimulus_pair_instance == 2 & stimulus_pair_target_instance == 1 ~ "0 tgt | 1 dist",
    stimulus_pair_instance == 2 & stimulus_pair_target_instance == 2 ~ "1 tgt | 0 dist",
    stimulus_pair_instance == 3 & stimulus_pair_target_instance == 1 ~ "0 tgt | 2 dist",
    stimulus_pair_instance == 3 & stimulus_pair_target_instance == 2 ~ "1 tgt | 1 dist",
    stimulus_pair_instance == 3 & stimulus_pair_target_instance == 3 ~ "2 tgt | 0 dist",
  )) %>%
  mutate(type_of_instance = factor(type_of_instance, levels = c("0 tgt | 0 dist", "1 tgt | 1 dist", "0 tgt | 2 dist", "2 tgt | 0 dist", "0 tgt | 1 dist", "1 tgt | 0 dist")))


repetitions_data_long <- repetitions_data %>%
  # filter(type_of_instance != "Repeated pair and target") %>%
  select(dataset_name, stimulus_pair_instance, stimulus_pair_target_instance, type_of_instance, post_accuracy, pre_accuracy) %>%
  pivot_longer(-c(dataset_name, stimulus_pair_instance, stimulus_pair_target_instance, type_of_instance),
    values_to = "Accuracy",
    names_to = "Time"
  )

repetitions_data_long %>%
  group_by(dataset_name, stimulus_pair_instance, stimulus_pair_target_instance, type_of_instance, Time) %>%
  summarize(n = n()) %>%
  group_by(dataset_name) %>%
  mutate(total_trials = sum(n)) %>%
  ggplot(aes(x = dataset_name, y = n / total_trials, fill = (type_of_instance))) +
  geom_bar(stat = "identity", position = "stack") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    legend.position = "top"
  ) +
  coord_flip()

c
```







# 5. Prior materials

```{r}
rep_timecourse %>%
  group_by(dataset_name, stimulus_pair_instance, trial_id) %>%
  summarize(n = n()) %>%
  group_by(dataset_name, stimulus_pair_instance) %>%
  summarise(n = n())
```

```{r boxplot}
d_trial_summary %>%
  group_by(dataset_name, stimulus_pair, stimulus_pair_instance, stimulus_pair_target_instance, is_first_stimulus) %>%
  summarise(
    avg = mean(post_accuracy),
    n()
  )
```



```{r}
# number of kids per instance by dataset will help us find datasets that have
# repetition by-design vs by-chance or error
kids_per_instance_table <- d_trial_summary %>%
  distinct(dataset_name, stimulus_pair_instance, administration_id) %>%
  group_by(dataset_name, stimulus_pair_instance) %>%
  summarise(n = n()) %>%
  group_by(dataset_name) %>%
  mutate(total = sum(n)) %>%
  ungroup()

# Stacked barplot with proportions

kids_per_instance_table %>%
  ggplot(aes(x = dataset_name, y = n / total, fill = (stimulus_pair_instance))) +
  geom_bar(stat = "identity", position = "stack") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    legend.position = "top"
  ) +
  coord_flip()


# filtered stacked barplot with proportions

kids_per_instance_table %>%
  mutate(max_instances = max(stimulus_pair_instance), .by = c("dataset_name")) %>%
  filter(max_instances > 2) %>%
  filter(max_instances < 5) %>%
  filter(dataset_name != "baumgartner_2014") %>%
  filter(dataset_name != "swingley_aslin_2002") %>%
  ggplot(aes(x = dataset_name, y = n / total, fill = (stimulus_pair_instance))) +
  geom_bar(stat = "identity", position = "stack") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    legend.position = "top"
  ) +
  coord_flip()




d_trial_summary %>%
  group_by(dataset_name) %>%
  summarize(n_kids = n_distinct(administration_id))
```


```{r}
# Keep only "valid" datasets

rep_valid <- d_trial_summary
# filter(dataset_name != "baumgartner_2014") %>%
# filter(dataset_name != "swingley_aslin_2002")

# get trials that have more than one instance and less than 5
rep_trials <- d_trial_summary %>%
  group_by(dataset_id, administration_id, stimulus_pair) %>%
  mutate(max_instances = max(stimulus_pair_instance)) %>%
  ungroup() %>%
  filter(max_instances > 2) %>%
  filter(max_instances < 5)

# get datasets with repeated trials
rep_datasets <- rep_trials %>%
  distinct(dataset_id)

# just the second time seeing this stimulus pair
rep_timecourse <- d_trial %>%
  left_join(rep_trials) %>%
  filter(max_instances > 1)




# do you look more to target after having seen this target as a target in this stimulus pair before?
rep_timecourse %>%
  group_by(stimulus_pair_instance, t_norm) %>%
  summarize(accuracy = mean(correct, na.rm = TRUE)) %>%
  filter(t_norm > -3000, t_norm < 4000) %>%
  ggplot(aes(x = t_norm, y = accuracy, color = as.factor(stimulus_pair_instance))) +
  geom_smooth(method = "gam") +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0.5, linetype = "dashed") # +
# facet_wrap(~stimulus_pair_instance)

# The same as the previous, faceted by study

rep_timecourse %>%
  group_by(stimulus_pair_instance, t_norm, dataset_name) %>%
  summarize(accuracy = mean(correct, na.rm = TRUE)) %>%
  filter(t_norm > -3000, t_norm < 4000) %>%
  ggplot(aes(x = t_norm, y = accuracy, color = as.factor(stimulus_pair_instance))) +
  geom_smooth(method = "gam") +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  facet_wrap(~dataset_name) +
  theme(legend.position = "bottom")



# do you look more to target after having seen this target as a target in this stimulus pair before? faceted by age
# rep_timecourse %>%
#   mutate(age_bin = cut(age, breaks = 4)) %>%
#   group_by(age_bin, stimulus_pair_instance, t_norm) %>%
#   summarize(accuracy = mean(correct, na.rm=TRUE)) %>%
#   filter(t_norm > -2000, t_norm < 4000) %>%
#   ggplot(aes(x = t_norm, y = accuracy, color = as.factor(stimulus_pair_instance)), group = age_bin) +
#   geom_smooth(method="gam")+
#   facet_wrap(~age_bin) +
#   geom_vline(xintercept=0)+
#   geom_hline(yintercept=0.5,linetype="dashed")

# get all the repeated stimulus pairs (up to 5 repeats)
# rep_timecourse <- d_trial %>%
#   filter(trial_id %in% rep_trials$trial_id) %>%
#   left_join(rep_trials) %>%
#   filter(instance < 5, max_instances > 1)

# how does looking change depending on # times you've seen this target as a target in this stim pair?
# rep_timecourse %>%
#   group_by(instance, target_instance, t_norm) %>%
#   summarize(accuracy = mean(correct, na.rm=TRUE), weight = n()) %>%
#   ungroup() %>%
#   filter(weight > 100) %>%
#   filter(t_norm > -2000, t_norm < 4000) %>%
#   ggplot(aes(x = t_norm, y = accuracy, color = as.factor(target_instance))) +
#   geom_point(aes(size = log(weight)), shape = 21, alpha = 0.4, fill = NA) +
#   geom_smooth(method="gam", aes(weight = weight, fill = as.factor(target_instance))) +
#   facet_wrap(~instance) +
#   geom_vline(xintercept=0)+
#   geom_hline(yintercept=0.5,linetype="dashed") +
#   theme_bw()
```


